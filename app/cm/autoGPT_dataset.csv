Commit Message,Code Changes,type
"fix(rnd): Fix JS event-loop freeze caused by websocket connection retry (#7861)

### Background

Websocket connection retry has no backoff period which causes event-loop freeze.

### Changes üèóÔ∏è

Add a back-off period on retry.","--- rnd/autogpt_builder/src/lib/autogpt-server-api/client.ts ---
@@ -227,13 +227,21 @@ export default class AutoGPTServerAPI {
   sendWebSocketMessage<M extends keyof WebsocketMessageTypeMap>(
     method: M,
     data: WebsocketMessageTypeMap[M],
+    callCount = 0,
   ) {
     if (this.webSocket && this.webSocket.readyState === WebSocket.OPEN) {
       this.webSocket.send(JSON.stringify({ method, data }));
     } else {
-      this.connectWebSocket().then(() =>
-        this.sendWebSocketMessage(method, data),
-      );
+      this.connectWebSocket().then(() => {
+        callCount == 0
+          ? this.sendWebSocketMessage(method, data, callCount + 1)
+          : setTimeout(
+              () => {
+                this.sendWebSocketMessage(method, data, callCount + 1);
+              },
+              2 ** (callCount - 1) * 1000,
+            );
+      });
     }
   }",fix
"build(deps): bump sentry-sdk from 2.17.0 to 2.18.0 in /autogpt_platform/market in the production-dependencies group (#8544)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/market/poetry.lock ---
@@ -1085,13 +1085,13 @@ files = [
 
 [[package]]
 name = ""sentry-sdk""
-version = ""2.17.0""
+version = ""2.18.0""
 description = ""Python client for Sentry (https://sentry.io)""
 optional = false
 python-versions = "">=3.6""
 files = [
-    {file = ""sentry_sdk-2.17.0-py2.py3-none-any.whl"", hash = ""sha256:625955884b862cc58748920f9e21efdfb8e0d4f98cca4ab0d3918576d5b606ad""},
-    {file = ""sentry_sdk-2.17.0.tar.gz"", hash = ""sha256:dd0a05352b78ffeacced73a94e86f38b32e2eae15fff5f30ca5abb568a72eacf""},
+    {file = ""sentry_sdk-2.18.0-py2.py3-none-any.whl"", hash = ""sha256:ee70e27d1bbe4cd52a38e1bd28a5fadb9b17bc29d91b5f2b97ae29c0a7610442""},
+    {file = ""sentry_sdk-2.18.0.tar.gz"", hash = ""sha256:0dc21febd1ab35c648391c664df96f5f79fb0d92d7d4225cd9832e53a617cafd""},
 ]
 
 [package.dependencies]
@@ -1120,9 +1120,11 @@ httpx = [""httpx (>=0.16.0)""]
 huey = [""huey (>=2)""]
 huggingface-hub = [""huggingface-hub (>=0.22)""]
 langchain = [""langchain (>=0.0.210)""]
+launchdarkly = [""launchdarkly-server-sdk (>=9.8.0)""]
 litestar = [""litestar (>=2.0.0)""]
 loguru = [""loguru (>=0.5)""]
 openai = [""openai (>=1.0.0)"", ""tiktoken (>=0.3.0)""]
+openfeature = [""openfeature-sdk (>=0.7.1)""]
 opentelemetry = [""opentelemetry-distro (>=0.35b0)""]
 opentelemetry-experimental = [""opentelemetry-distro""]
 pure-eval = [""asttokens"", ""executing"", ""pure-eval""]
@@ -1296,4 +1298,4 @@ watchmedo = [""PyYAML (>=3.10)""]
 [metadata]
 lock-version = ""2.0""
 python-versions = ""^3.10""
-content-hash = ""f94a7651b3ddc7819bafdc75384cb8ad34f7a5415e652ecb5bd82d632d26e693""
+content-hash = ""1f2ca308f9e61ee83e9db201c1af9742c93cf348f32fe78f633d67dc93334b8f""

--- autogpt_platform/market/pyproject.toml ---
@@ -14,7 +14,7 @@ prisma = ""^0.15.0""
 python-dotenv = ""^1.0.1""
 uvicorn = ""^0.32.0""
 fastapi = ""^0.115.4""
-sentry-sdk = { extras = [""fastapi""], version = ""^2.17.0"" }
+sentry-sdk = { extras = [""fastapi""], version = ""^2.18.0"" }
 fuzzywuzzy = ""^0.18.0""
 python-levenshtein = ""^0.26.1""
 # autogpt-platform-backend = { path = ""../backend"", develop = true }",build
"build(deps-dev): bump the development-dependencies group in /autogpt_platform/market with 2 updates (#8706)

build(deps-dev): bump the development-dependencies group

Bumps the development-dependencies group in /autogpt_platform/market with 2 updates: [ruff](https://github.com/astral-sh/ruff) and [pyright](https://github.com/RobertCraigie/pyright-python).


Updates `ruff` from 0.7.3 to 0.7.4
- [Release notes](https://github.com/astral-sh/ruff/releases)
- [Changelog](https://github.com/astral-sh/ruff/blob/main/CHANGELOG.md)
- [Commits](https://github.com/astral-sh/ruff/compare/0.7.3...0.7.4)

Updates `pyright` from 1.1.388 to 1.1.389
- [Release notes](https://github.com/RobertCraigie/pyright-python/releases)
- [Commits](https://github.com/RobertCraigie/pyright-python/compare/v1.1.388...v1.1.389)

---
updated-dependencies:
- dependency-name: ruff
  dependency-type: direct:development
  update-type: version-update:semver-patch
  dependency-group: development-dependencies
- dependency-name: pyright
  dependency-type: direct:development
  update-type: version-update:semver-patch
  dependency-group: development-dependencies
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/market/poetry.lock ---
@@ -829,13 +829,13 @@ tests = [""coverage[toml] (==5.0.4)"", ""pytest (>=6.0.0,<7.0.0)""]
 
 [[package]]
 name = ""pyright""
-version = ""1.1.388""
+version = ""1.1.389""
 description = ""Command line wrapper for pyright""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""pyright-1.1.388-py3-none-any.whl"", hash = ""sha256:c7068e9f2c23539c6ac35fc9efac6c6c1b9aa5a0ce97a9a8a6cf0090d7cbf84c""},
-    {file = ""pyright-1.1.388.tar.gz"", hash = ""sha256:0166d19b716b77fd2d9055de29f71d844874dbc6b9d3472ccd22df91db3dfa34""},
+    {file = ""pyright-1.1.389-py3-none-any.whl"", hash = ""sha256:41e9620bba9254406dc1f621a88ceab5a88af4c826feb4f614d95691ed243a60""},
+    {file = ""pyright-1.1.389.tar.gz"", hash = ""sha256:716bf8cc174ab8b4dcf6828c3298cac05c5ed775dda9910106a5dcfe4c7fe220""},
 ]
 
 [package.dependencies]
@@ -1058,29 +1058,29 @@ use-chardet-on-py3 = [""chardet (>=3.0.2,<6)""]
 
 [[package]]
 name = ""ruff""
-version = ""0.7.3""
+version = ""0.7.4""
 description = ""An extremely fast Python linter and code formatter, written in Rust.""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""ruff-0.7.3-py3-none-linux_armv6l.whl"", hash = ""sha256:34f2339dc22687ec7e7002792d1f50712bf84a13d5152e75712ac08be565d344""},
-    {file = ""ruff-0.7.3-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:fb397332a1879b9764a3455a0bb1087bda876c2db8aca3a3cbb67b3dbce8cda0""},
-    {file = ""ruff-0.7.3-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:37d0b619546103274e7f62643d14e1adcbccb242efda4e4bdb9544d7764782e9""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:5d59f0c3ee4d1a6787614e7135b72e21024875266101142a09a61439cb6e38a5""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:44eb93c2499a169d49fafd07bc62ac89b1bc800b197e50ff4633aed212569299""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:6d0242ce53f3a576c35ee32d907475a8d569944c0407f91d207c8af5be5dae4e""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:6b6224af8b5e09772c2ecb8dc9f3f344c1aa48201c7f07e7315367f6dd90ac29""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:c50f95a82b94421c964fae4c27c0242890a20fe67d203d127e84fbb8013855f5""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7f3eff9961b5d2644bcf1616c606e93baa2d6b349e8aa8b035f654df252c8c67""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:b8963cab06d130c4df2fd52c84e9f10d297826d2e8169ae0c798b6221be1d1d2""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:61b46049d6edc0e4317fb14b33bd693245281a3007288b68a3f5b74a22a0746d""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:10ebce7696afe4644e8c1a23b3cf8c0f2193a310c18387c06e583ae9ef284de2""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:3f36d56326b3aef8eeee150b700e519880d1aab92f471eefdef656fd57492aa2""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:5d024301109a0007b78d57ab0ba190087b43dce852e552734ebf0b0b85e4fb16""},
-    {file = ""ruff-0.7.3-py3-none-win32.whl"", hash = ""sha256:4ba81a5f0c5478aa61674c5a2194de8b02652f17addf8dfc40c8937e6e7d79fc""},
-    {file = ""ruff-0.7.3-py3-none-win_amd64.whl"", hash = ""sha256:588a9ff2fecf01025ed065fe28809cd5a53b43505f48b69a1ac7707b1b7e4088""},
-    {file = ""ruff-0.7.3-py3-none-win_arm64.whl"", hash = ""sha256:1713e2c5545863cdbfe2cbce21f69ffaf37b813bfd1fb3b90dc9a6f1963f5a8c""},
-    {file = ""ruff-0.7.3.tar.gz"", hash = ""sha256:e1d1ba2e40b6e71a61b063354d04be669ab0d39c352461f3d789cac68b54a313""},
+    {file = ""ruff-0.7.4-py3-none-linux_armv6l.whl"", hash = ""sha256:a4919925e7684a3f18e18243cd6bea7cfb8e968a6eaa8437971f681b7ec51478""},
+    {file = ""ruff-0.7.4-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:cfb365c135b830778dda8c04fb7d4280ed0b984e1aec27f574445231e20d6c63""},
+    {file = ""ruff-0.7.4-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:63a569b36bc66fbadec5beaa539dd81e0527cb258b94e29e0531ce41bacc1f20""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:0d06218747d361d06fd2fdac734e7fa92df36df93035db3dc2ad7aa9852cb109""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:e0cea28d0944f74ebc33e9f934238f15c758841f9f5edd180b5315c203293452""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:80094ecd4793c68b2571b128f91754d60f692d64bc0d7272ec9197fdd09bf9ea""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:997512325c6620d1c4c2b15db49ef59543ef9cd0f4aa8065ec2ae5103cedc7e7""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:00b4cf3a6b5fad6d1a66e7574d78956bbd09abfd6c8a997798f01f5da3d46a05""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7dbdc7d8274e1422722933d1edddfdc65b4336abf0b16dfcb9dedd6e6a517d06""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:0e92dfb5f00eaedb1501b2f906ccabfd67b2355bdf117fea9719fc99ac2145bc""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:3bd726099f277d735dc38900b6a8d6cf070f80828877941983a57bca1cd92172""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:2e32829c429dd081ee5ba39aef436603e5b22335c3d3fff013cd585806a6486a""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:662a63b4971807623f6f90c1fb664613f67cc182dc4d991471c23c541fee62dd""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:876f5e09eaae3eb76814c1d3b68879891d6fde4824c015d48e7a7da4cf066a3a""},
+    {file = ""ruff-0.7.4-py3-none-win32.whl"", hash = ""sha256:75c53f54904be42dd52a548728a5b572344b50d9b2873d13a3f8c5e3b91f5cac""},
+    {file = ""ruff-0.7.4-py3-none-win_amd64.whl"", hash = ""sha256:745775c7b39f914238ed1f1b0bebed0b9155a17cd8bc0b08d3c87e4703b990d6""},
+    {file = ""ruff-0.7.4-py3-none-win_arm64.whl"", hash = ""sha256:11bff065102c3ae9d3ea4dc9ecdfe5a5171349cdd0787c1fc64761212fc9cf1f""},
+    {file = ""ruff-0.7.4.tar.gz"", hash = ""sha256:cd12e35031f5af6b9b93715d8c4f40360070b2041f81273d0527683d5708fce2""},
 ]
 
 [[package]]
@@ -1298,4 +1298,4 @@ watchmedo = [""PyYAML (>=3.10)""]
 [metadata]
 lock-version = ""2.0""
 python-versions = ""^3.10""
-content-hash = ""cc73969e4aca097fb0832e02387d823095f06c7cd8516e56e8bc9026671ac9aa""
+content-hash = ""4f7e4bbed535e40688e953dd0bfab80f704ba6017fc01360941f5cf858ef5f4c""

--- autogpt_platform/market/pyproject.toml ---
@@ -28,8 +28,8 @@ pytest-asyncio = ""^0.24.0""
 
 pytest-watcher = ""^0.4.3""
 requests = ""^2.32.3""
-ruff = ""^0.7.3""
-pyright = ""^1.1.388""
+ruff = ""^0.7.4""
+pyright = ""^1.1.389""
 isort = ""^5.13.2""
 black = ""^24.10.0""",build
feat(platform): Add coin icon on block cost & current credits (#8124),"--- autogpt_platform/frontend/src/components/CreditButton.tsx ---
@@ -2,7 +2,7 @@
 
 import { useState, useEffect } from ""react"";
 import { Button } from ""@/components/ui/button"";
-import { IconRefresh } from ""@/components/ui/icons"";
+import { IconRefresh, IconCoin } from ""@/components/ui/icons"";
 import AutoGPTServerAPI from ""@/lib/autogpt-server-api"";
 
 export default function CreditButton() {
@@ -24,7 +24,9 @@ export default function CreditButton() {
         variant=""outline""
         className=""flex items-center space-x-2 text-muted-foreground""
       >
-        <span>Credits: {credit}</span>
+        <span className=""flex items-center"">
+          <IconCoin /> {credit}
+        </span>
         <IconRefresh />
       </Button>
     )

--- autogpt_platform/frontend/src/components/CustomNode.tsx ---
@@ -33,6 +33,7 @@ import { getPrimaryCategoryColor } from ""@/lib/utils"";
 import { FlowContext } from ""./Flow"";
 import { Badge } from ""./ui/badge"";
 import DataTable from ""./DataTable"";
+import { IconCoin } from ""./ui/icons"";
 
 type ParsedKey = { key: string; index?: number };
 
@@ -577,8 +578,10 @@ export function CustomNode({ data, id, width, height }: NodeProps<CustomNode>) {
         </div>
       </div>
       {blockCost && (
-        <div className=""p-3 text-right font-semibold"">
-          Cost: {blockCost.cost_amount} / {blockCost.cost_type}
+        <div className=""p-3 font-semibold"">
+          <span className=""ml-auto flex items-center"">
+            <IconCoin /> {blockCost.cost_amount} per {blockCost.cost_type}
+          </span>
         </div>
       )}
       {data.uiType !== BlockUIType.NOTE ? (

--- autogpt_platform/frontend/src/components/ui/icons.tsx ---
@@ -301,6 +301,34 @@ export const IconRefresh = createIcon((props) => (
   </svg>
 ));
 
+/**
+ * Coin icon component.
+ *
+ * @component IconCoin
+ * @param {IconProps} props - The props object containing additional attributes and event handlers for the icon.
+ * @returns {JSX.Element} - The coins icon.
+ *
+ */
+export const IconCoin = createIcon((props) => (
+  <svg
+    xmlns=""http://www.w3.org/2000/svg""
+    width=""24""
+    height=""24""
+    viewBox=""0 0 24 24""
+    fill=""none""
+    stroke=""currentColor""
+    strokeWidth=""2""
+    strokeLinecap=""round""
+    strokeLinejoin=""round""
+    {...props}
+  >
+    <circle cx=""8"" cy=""8"" r=""6"" />
+    <path d=""M18.09 10.37A6 6 0 1 1 10.34 18"" />
+    <path d=""M7 6h1v4"" />
+    <path d=""m16.71 13.88.7.71-2.82 2.82"" />
+  </svg>
+));
+
 /**
  * Menu icon component.
  *",feat
"feat(blocks): Add Open Router integration with a large selection of new models (#8653)

* feat: Add Open Router integration credentials

- Added support for Open Router integration credentials in the Supabase integration credentials store.
- Updated the LLM provider field to include ""open_router"" as a valid provider option.
- Added Open Router API key field to the backend settings.
- Updated the profile page to display the Open Router integration credentials.
- Updated the credentials input and provider components to include Open Router as a provider option.
- Updated the autogpt-server-api types to include ""open_router"" as a provider name.
- Updated the LLM provider schema to include ""open_router"" as a valid provider name.

- Added GEMINI_FLASH_1_5_8B as the first Open Router LLM

* Add type ignore to new llm prompt to match the rest of them.

* Update LlmModel with a selection of new OpenRouter models

* format","--- autogpt_platform/autogpt_libs/autogpt_libs/supabase_integration_credentials_store/store.py ---
@@ -79,13 +79,20 @@
     title=""Use Credits for Jina"",
     expires_at=None,
 )
-unreal_credentials = APIKeyCredentials(#
+unreal_credentials = APIKeyCredentials(
     id=""66f20754-1b81-48e4-91d0-f4f0dd82145f"",
     provider=""unreal"",
     api_key=SecretStr(settings.secrets.unreal_speech_api_key),
     title=""Use Credits for Unreal"",
     expires_at=None,
 )
+open_router_credentials = APIKeyCredentials(
+    id=""b5a0e27d-0c98-4df3-a4b9-10193e1f3c40"",
+    provider=""open_router"",
+    api_key=SecretStr(settings.secrets.open_router_api_key),
+    title=""Use Credits for Open Router"",
+    expires_at=None,
+)
 
 
 DEFAULT_CREDENTIALS = [
@@ -98,6 +105,7 @@
     did_credentials,
     jina_credentials,
     unreal_credentials,
+    open_router_credentials,
 ]
 
 
@@ -145,6 +153,8 @@ def get_all_creds(self, user_id: str) -> list[Credentials]:
             all_credentials.append(jina_credentials)
         if settings.secrets.unreal_speech_api_key:
             all_credentials.append(unreal_credentials)
+        if settings.secrets.open_router_api_key:
+            all_credentials.append(open_router_credentials)
         return all_credentials
 
     def get_creds_by_id(self, user_id: str, credentials_id: str) -> Credentials | None:

--- autogpt_platform/backend/.env.example ---
@@ -57,6 +57,7 @@ GOOGLE_CLIENT_SECRET=
 OPENAI_API_KEY=
 ANTHROPIC_API_KEY=
 GROQ_API_KEY=
+OPEN_ROUTER_API_KEY=
 
 # Reddit
 REDDIT_CLIENT_ID=

--- autogpt_platform/backend/backend/blocks/llm.py ---
@@ -30,7 +30,7 @@
 #     ""ollama"": BlockSecret(value=""""),
 # }
 
-LLMProviderName = Literal[""anthropic"", ""groq"", ""openai"", ""ollama""]
+LLMProviderName = Literal[""anthropic"", ""groq"", ""openai"", ""ollama"", ""open_router""]
 AICredentials = CredentialsMetaInput[LLMProviderName, Literal[""api_key""]]
 
 TEST_CREDENTIALS = APIKeyCredentials(
@@ -51,7 +51,7 @@
 def AICredentialsField() -> AICredentials:
     return CredentialsField(
         description=""API key for the LLM provider."",
-        provider=[""anthropic"", ""groq"", ""openai"", ""ollama""],
+        provider=[""anthropic"", ""groq"", ""openai"", ""ollama"", ""open_router""],
         supported_credential_types={""api_key""},
         discriminator=""model"",
         discriminator_mapping={
@@ -108,6 +108,18 @@ class LlmModel(str, Enum, metaclass=LlmModelMeta):
     # Ollama models
     OLLAMA_LLAMA3_8B = ""llama3""
     OLLAMA_LLAMA3_405B = ""llama3.1:405b""
+    # OpenRouter models
+    GEMINI_FLASH_1_5_8B = ""google/gemini-flash-1.5""
+    GEMINI_FLASH_1_5_EXP = ""google/gemini-flash-1.5-exp""
+    GROK_BETA = ""x-ai/grok-beta""
+    MISTRAL_NEMO = ""mistralai/mistral-nemo""
+    COHERE_COMMAND_R_08_2024 = ""cohere/command-r-08-2024""
+    COHERE_COMMAND_R_PLUS_08_2024 = ""cohere/command-r-plus-08-2024""
+    EVA_QWEN_2_5_32B = ""eva-unit-01/eva-qwen-2.5-32b""
+    DEEPSEEK_CHAT = ""deepseek/deepseek-chat""
+    PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE = (
+        ""perplexity/llama-3.1-sonar-large-128k-online""
+    )
 
     @property
     def metadata(self) -> ModelMetadata:
@@ -142,6 +154,17 @@ def context_window(self) -> int:
     LlmModel.LLAMA3_1_8B: ModelMetadata(""groq"", 131072),
     LlmModel.OLLAMA_LLAMA3_8B: ModelMetadata(""ollama"", 8192),
     LlmModel.OLLAMA_LLAMA3_405B: ModelMetadata(""ollama"", 8192),
+    LlmModel.GEMINI_FLASH_1_5_8B: ModelMetadata(""open_router"", 8192),
+    LlmModel.GEMINI_FLASH_1_5_EXP: ModelMetadata(""open_router"", 8192),
+    LlmModel.GROK_BETA: ModelMetadata(""open_router"", 8192),
+    LlmModel.MISTRAL_NEMO: ModelMetadata(""open_router"", 4000),
+    LlmModel.COHERE_COMMAND_R_08_2024: ModelMetadata(""open_router"", 4000),
+    LlmModel.COHERE_COMMAND_R_PLUS_08_2024: ModelMetadata(""open_router"", 4000),
+    LlmModel.EVA_QWEN_2_5_32B: ModelMetadata(""open_router"", 4000),
+    LlmModel.DEEPSEEK_CHAT: ModelMetadata(""open_router"", 8192),
+    LlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE: ModelMetadata(
+        ""open_router"", 8192
+    ),
 }
 
 for model in LlmModel:
@@ -354,6 +377,34 @@ def llm_call(
                 response.get(""prompt_eval_count"") or 0,
                 response.get(""eval_count"") or 0,
             )
+        elif provider == ""open_router"":
+            client = openai.OpenAI(
+                base_url=""https://openrouter.ai/api/v1"",
+                api_key=credentials.api_key.get_secret_value(),
+            )
+
+            response = client.chat.completions.create(
+                extra_headers={
+                    ""HTTP-Referer"": ""https://agpt.co"",
+                    ""X-Title"": ""AutoGPT"",
+                },
+                model=llm_model.value,
+                messages=prompt,  # type: ignore
+                max_tokens=max_tokens,
+            )
+
+            # If there's no response, raise an error
+            if not response.choices:
+                if response:
+                    raise ValueError(f""OpenRouter error: {response}"")
+                else:
+                    raise ValueError(""No response from OpenRouter."")
+
+            return (
+                response.choices[0].message.content or """",
+                response.usage.prompt_tokens if response.usage else 0,
+                response.usage.completion_tokens if response.usage else 0,
+            )
         else:
             raise ValueError(f""Unsupported LLM provider: {provider}"")
 

--- autogpt_platform/backend/backend/data/block_cost_config.py ---
@@ -6,6 +6,7 @@
     groq_credentials,
     ideogram_credentials,
     jina_credentials,
+    open_router_credentials,
     openai_credentials,
     replicate_credentials,
     revid_credentials,
@@ -54,6 +55,15 @@
     LlmModel.LLAMA3_1_8B: 1,
     LlmModel.OLLAMA_LLAMA3_8B: 1,
     LlmModel.OLLAMA_LLAMA3_405B: 1,
+    LlmModel.GEMINI_FLASH_1_5_8B: 1,
+    LlmModel.GEMINI_FLASH_1_5_EXP: 1,
+    LlmModel.GROK_BETA: 5,
+    LlmModel.MISTRAL_NEMO: 1,
+    LlmModel.COHERE_COMMAND_R_08_2024: 1,
+    LlmModel.COHERE_COMMAND_R_PLUS_08_2024: 3,
+    LlmModel.EVA_QWEN_2_5_32B: 1,
+    LlmModel.DEEPSEEK_CHAT: 2,
+    LlmModel.PERPLEXITY_LLAMA_3_1_SONAR_LARGE_128K_ONLINE: 1,
 }
 
 for model in LlmModel:
@@ -124,6 +134,23 @@
             cost_filter={""api_key"": None},
         ),
     ]
+    # Open Router Models
+    + [
+        BlockCost(
+            cost_type=BlockCostType.RUN,
+            cost_filter={
+                ""model"": model,
+                ""credentials"": {
+                    ""id"": open_router_credentials.id,
+                    ""provider"": open_router_credentials.provider,
+                    ""type"": open_router_credentials.type,
+                },
+            },
+            cost_amount=cost,
+        )
+        for model, cost in MODEL_COST.items()
+        if MODEL_METADATA[model].provider == ""open_router""
+    ]
 )
 
 # =============== This is the exhaustive list of cost for each Block =============== #

--- autogpt_platform/backend/backend/util/settings.py ---
@@ -238,6 +238,7 @@ class Secrets(UpdateTrackingModel[""Secrets""], BaseSettings):
     openai_api_key: str = Field(default="""", description=""OpenAI API key"")
     anthropic_api_key: str = Field(default="""", description=""Anthropic API key"")
     groq_api_key: str = Field(default="""", description=""Groq API key"")
+    open_router_api_key: str = Field(default="""", description=""Open Router API Key"")
 
     reddit_client_id: str = Field(default="""", description=""Reddit client ID"")
     reddit_client_secret: str = Field(default="""", description=""Reddit client secret"")

--- autogpt_platform/frontend/src/app/profile/page.tsx ---
@@ -73,6 +73,7 @@ export default function PrivatePage() {
       ""7f7b0654-c36b-4565-8fa7-9a52575dfae2"", // D-ID
       ""7f26de70-ba0d-494e-ba76-238e65e7b45f"", // Jina
       ""66f20754-1b81-48e4-91d0-f4f0dd82145f"", // Unreal Speech
+      ""b5a0e27d-0c98-4df3-a4b9-10193e1f3c40"", // Open Router
     ],
     [],
   );

--- autogpt_platform/frontend/src/components/integrations/credentials-input.tsx ---
@@ -60,6 +60,7 @@ export const providerIcons: Record<
   ollama: fallbackIcon,
   openai: fallbackIcon,
   openweathermap: fallbackIcon,
+  open_router: fallbackIcon,
   pinecone: fallbackIcon,
   replicate: fallbackIcon,
   revid: fallbackIcon,

--- autogpt_platform/frontend/src/components/integrations/credentials-provider.tsx ---
@@ -34,6 +34,7 @@ const providerDisplayNames: Record<CredentialsProviderName, string> = {
   ollama: ""Ollama"",
   openai: ""OpenAI"",
   openweathermap: ""OpenWeatherMap"",
+  open_router: ""Open Router"",
   pinecone: ""Pinecone"",
   replicate: ""Replicate"",
   revid: ""Rev.ID"",

--- autogpt_platform/frontend/src/lib/autogpt-server-api/types.ts ---
@@ -112,6 +112,7 @@ export const PROVIDER_NAMES = {
   OLLAMA: ""ollama"",
   OPENAI: ""openai"",
   OPENWEATHERMAP: ""openweathermap"",
+  OPEN_ROUTER: ""open_router"",
   PINECONE: ""pinecone"",
   REPLICATE: ""replicate"",
   REVID: ""revid"",",feat
"feat(builder, server): Add advanced block inputs (#7934)

- Add `advanced` to `SchemaField` and pass it to `json_extra`
- Add `advanced` to `BlockIOSubSchemaMeta` type
- Update `CustomNode`, so that:
  - non-required advanced inputs are hidden
  - non-advanced and required inputs are always shown","--- rnd/autogpt_builder/src/components/CustomNode.tsx ---
@@ -118,12 +118,6 @@ export function CustomNode({ data, id, width, height }: NodeProps<CustomNode>) {
     setIsAdvancedOpen(checked);
   };
 
-  const hasOptionalFields =
-    data.inputSchema &&
-    Object.keys(data.inputSchema.properties).some((key) => {
-      return !data.inputSchema.required?.includes(key);
-    });
-
   const generateOutputHandles = (schema: BlockIORootSchema) => {
     if (!schema?.properties) return null;
     const keys = Object.keys(schema.properties);
@@ -368,11 +362,20 @@ export function CustomNode({ data, id, width, height }: NodeProps<CustomNode>) {
 
   const errorClass =
     hasConfigErrors || hasOutputError ? ""border-red-500 border-2"" : """";
+
   const statusClass =
     hasConfigErrors || hasOutputError
       ? ""failed""
       : (data.status?.toLowerCase() ?? """");
 
+  const hasAdvancedFields =
+    data.inputSchema &&
+    Object.entries(data.inputSchema.properties).some(([key, value]) => {
+      return (
+        value.advanced === true && !data.inputSchema.required?.includes(key)
+      );
+    });
+
   return (
     <div
       className={`${blockClasses} ${errorClass} ${statusClass}`}
@@ -421,8 +424,12 @@ export function CustomNode({ data, id, width, height }: NodeProps<CustomNode>) {
               ([propKey, propSchema]) => {
                 const isRequired = data.inputSchema.required?.includes(propKey);
                 const isConnected = isHandleConnected(propKey);
+                const isAdvanced = propSchema.advanced;
                 return (
-                  (isRequired || isAdvancedOpen || isConnected) && (
+                  (isRequired ||
+                    isAdvancedOpen ||
+                    isConnected ||
+                    !isAdvanced) && (
                     <div key={propKey} onMouseOver={() => {}}>
                       <NodeHandle
                         keyName={propKey}
@@ -479,7 +486,7 @@ export function CustomNode({ data, id, width, height }: NodeProps<CustomNode>) {
       <div className=""mt-2.5 flex items-center pb-4 pl-4"">
         <Switch checked={isOutputOpen} onCheckedChange={toggleOutput} />
         <span className=""m-1 mr-4"">Output</span>
-        {hasOptionalFields && (
+        {hasAdvancedFields && (
           <>
             <Switch onCheckedChange={toggleAdvancedSettings} />
             <span className=""m-1"">Advanced</span>

--- rnd/autogpt_builder/src/lib/autogpt-server-api/types.ts ---
@@ -39,6 +39,7 @@ export type BlockIOSubSchemaMeta = {
   title?: string;
   description?: string;
   placeholder?: string;
+  advanced?: boolean;
 };
 
 export type BlockIOObjectSubSchema = BlockIOSubSchemaMeta & {

--- rnd/autogpt_server/autogpt_server/data/model.py ---
@@ -109,6 +109,7 @@ def SchemaField(
     title: Optional[str] = None,
     description: Optional[str] = None,
     placeholder: Optional[str] = None,
+    advanced: Optional[bool] = None,
     secret: bool = False,
     exclude: bool = False,
     **kwargs,
@@ -118,6 +119,8 @@ def SchemaField(
         json_extra[""placeholder""] = placeholder
     if secret:
         json_extra[""secret""] = True
+    if advanced:
+        json_extra[""advanced""] = True
 
     return Field(
         default,",feat
"fix(backend): Add migrations to fix credentials inputs with invalid provider ""llm"" (vol. 5)

Five times the charm","--- autogpt_platform/backend/backend/data/graph.py ---
@@ -550,10 +550,10 @@ async def fix_llm_provider_credentials():
         SELECT    ""User"".id            user_id,
                   node.id              node_id,
                   node.""constantInput"" node_preset_input
-        FROM      ""AgentNode""  node
-        LEFT JOIN ""AgentGraph"" graph
+        FROM      platform.""AgentNode""  node
+        LEFT JOIN platform.""AgentGraph"" graph
         ON        node.""agentGraphId"" = graph.id
-        LEFT JOIN ""User""
+        LEFT JOIN platform.""User""       ""User""
         ON        graph.""userId"" = ""User"".id
         WHERE     node.""constantInput""::jsonb->'credentials'->>'provider' = 'llm'
         ORDER BY  user_id;",fix
fix(builder): update tutorial routing to work on safari (#7992),"--- rnd/autogpt_builder/src/components/Flow.tsx ---
@@ -38,6 +38,7 @@ import { IconPlay, IconRedo2, IconUndo2 } from ""@/components/ui/icons"";
 import { startTutorial } from ""./tutorial"";
 import useAgentGraph from ""@/hooks/useAgentGraph"";
 import { v4 as uuidv4 } from ""uuid"";
+import { useRouter, usePathname, useSearchParams } from ""next/navigation"";
 
 // This is for the history, this is the minimum distance a block must move before it is logged
 // It helps to prevent spamming the history with small movements especially when pressing on a input in a block
@@ -81,6 +82,8 @@ const FlowEditor: React.FC<{
     setEdges,
   } = useAgentGraph(flowID, template, visualizeBeads !== ""no"");
 
+  const router = useRouter();
+  const pathname = usePathname();
   const initialPositionRef = useRef<{
     [key: string]: { x: number; y: number };
   }>({});
@@ -97,7 +100,7 @@ const FlowEditor: React.FC<{
     // If resetting tutorial
     if (params.get(""resetTutorial"") === ""true"") {
       localStorage.removeItem(""shepherd-tour""); // Clear tutorial flag
-      window.location.href = window.location.pathname; // Redirect to clear URL parameters
+      router.push(pathname);
     } else {
       // Otherwise, start tutorial if conditions are met
       const shouldStartTutorial = !localStorage.getItem(""shepherd-tour"");",fix
"build(prod): Set up prod values infra (#8201)

updated prod vars","--- autogpt_platform/infra/terraform/environments/prod.tfvars ---
@@ -0,0 +1,100 @@
+project_id      = ""agpt-prod""
+region          = ""us-central1""
+zone            = ""us-central1-a""
+network_name    = ""prod-gke-network""
+subnet_name     = ""prod-gke-subnet""
+subnet_cidr     = ""10.0.0.0/24""
+cluster_name    = ""prod-gke-cluster""
+node_count      = 4
+node_pool_name  = ""prod-main-pool""
+machine_type    = ""e2-highmem-4""
+disk_size_gb    = 100
+static_ip_names = [""agpt-backend-ip"", ""agpt-frontend-ip"", ""agpt-ws-backend-ip"", ""agpt-market-ip""]
+
+
+service_accounts = {
+  ""prod-agpt-backend-sa"" = {
+    display_name = ""AutoGPT prod backend Account""
+    description  = ""Service account for agpt prod backend""
+  },
+  ""prod-agpt-frontend-sa"" = {
+    display_name = ""AutoGPT prod frontend Account""
+    description  = ""Service account for agpt prod frontend""
+  },
+   ""prod-agpt-ws-backend-sa"" = {
+    display_name = ""AutoGPT prod WebSocket backend Account""
+    description  = ""Service account for agpt prod websocket backend""
+  },
+   ""prod-agpt-market-sa"" = {
+    display_name = ""AutoGPT prod Market backend Account""
+    description  = ""Service account for agpt prod market backend""
+  }
+}
+
+workload_identity_bindings = {
+  ""prod-agpt-backend-workload-identity"" = {
+    service_account_name = ""prod-agpt-backend-sa""
+    namespace            = ""prod-agpt""
+    ksa_name             = ""prod-agpt-backend-sa""
+  },
+  ""prod-agpt-frontend-workload-identity"" = {
+    service_account_name = ""prod-agpt-frontend-sa""
+    namespace            = ""prod-agpt""
+    ksa_name             = ""prod-agpt-frontend-sa""
+  },
+  ""prod-agpt-ws-backend-workload-identity"" = {
+    service_account_name = ""prod-agpt-ws-backend-sa""
+    namespace            = ""prod-agpt""
+    ksa_name             = ""prod-agpt-ws-backend-sa""
+  },
+  ""prod-agpt-market-workload-identity"" = {
+    service_account_name = ""prod-agpt-market-sa""
+    namespace            = ""prod-agpt""
+    ksa_name             = ""prod-agpt-market-sa""
+  }
+}
+
+role_bindings = {
+  ""roles/container.developer"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/cloudsql.client"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/cloudsql.editor"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/cloudsql.instanceUser"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/iam.workloadIdentityUser"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ]
+  ""roles/compute.networkUser"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/container.hostServiceAgentUser"" = [
+    ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ]
+}
+
+pods_ip_cidr_range     = ""10.1.0.0/16""
+services_ip_cidr_range = ""10.2.0.0/20""
\ No newline at end of file",build
"fix(market): Reseal Market URL (#8363)

reseal market url","--- autogpt_platform/infra/helm/autogpt-market/values.dev.yaml ---
@@ -95,6 +95,6 @@ env:
 
 secrets:
   SUPABASE_JWT_SECRET: ""AgBL6H6byPKXVN0nYWgqyoZBHJJJqk8S3rNYSu3JvwOsNn3Sw94SrJcXuE48fxcojcbKvYcDshetFhrSNEsfUwvbSFoaIj+MItPIZ8FGHyfXnmeZJ5j/sdvcjaMmWS7CiL2jhzI+nc8rL2ATV2TgA7E6FA9MvhWqkAyZu04pCd1c9DsAlpcfQ3pxywXjOV+BU0+1+++Z+fTnaugt+hRbhHrKTddaPhi72KrIyJPOUlqfht0JcgflT1f5frvmNnDwkiP862knhJsqg7XyrSy4msCN7eH4BvV01pO3KhAEnMG4Lk/5FeE/2t05+HqgB4mvPbkqfY6g8Lvf6qmd5g+stB10wRmr+TxzokOom36r7sYd3tyXZMgemJOi3BZjYk7774zf/TI081pJx1FPvM6dDPQdrgnU1nhshq/gLyKB5tTTCkPQHW+YhUtApWgrC5mq8ezMqfuwrUuR+NvyO59K56ERJJFAw1fDKHIVl4TYmftet42lkVOchml30cje9gjBtpOrTkFf8lMv5DLQ/ygdwsAYmVrpYtXbT+GAaRI9QIv/rZVuckfz4uIhTp7IjAtRXJreMH2V8GZ22h6Of/BQG+XA42lMA2huIyLwsqmtL0qxNmIu5EGjcXBvlOt5eNquzts68jgNqEfE6fEuqS9lDepvtTSxGp7wmcmWwOBbIgbCnxl8t4IW/e1qvOPuvxMldH+YtVIvfHMf3DnvbehhCIYuLmRM+E6139/qdGKreRyCi4PA4PKTMEG962rSu/7z0X5wu+UYY+kESrs7HhksL3PhB3dpbZ0HF+b6lchziTI0atG+UNX05ysL""
-  DATABASE_URL: ""AgAWMrGQg5ON4uR4ZBWZWvt47nuT57L+D63i9vnfSMH9IGAthi+Z056Om4sBfyjpIOT4uowECnznRWQOZLXMrNeIk3Hwc2cBqFuO2LpnN4UnaRQHYNzp2gn8onwq54XhOhQF/aw0sSMBcXWJKfBOY44wZI0vebFaOE1h615tXVvTz9g8OFavj2Wky25ydHZiukpUs7M9eu7FE5RSGiG8saHL8+VLQRWqODf4dcykFiFcp0hNbaNSmYpAWyI8oe44SkzVb2AWbEZEUjkNLVxV95iMeTi0SRNaJ/hW6wcN7O2ZByb2jwRKiXXRa1l9b5Uy9hcueY1VU5ZCDuX5XNtM9BnfbO+Ez0FCc9J8DhfSi6woG4WceWksZ7unEUspPFKVRTFlKqn5MPR/ppfNwatlCpgf9q+zDybrMRoiD8aOcn7QSLNcs+dRRmFNDtu2+2RMBhoYSuENyOxZZRfjg+xYOL29BGx0SOQ46Jk7W/ZC706+T91SHfvTFMqStWFrYQOBxUcoDSK3XidJ/CYcXw3xzXpM4DTSbKVTwKVkPy72DeQf+eTxk0vS0xnbz3SHZVBMrRAcCfvS1HwZGc9TuV6dMfH6i4WKpPt2PxyuDL/sqt0RdHCKjPL8dC+XozqPTv0tTMQ9Xof2bllXWCN5QDWuC4Gam9M8aWKvALqtxwjDJmeqfqImPe045gsIUEX3pGYvB4PHfRPaocPe9sutjfa5EVk1md0m2yBpBcxouJBwV72sqK3yMVFJ+UYu+1nasiNkG828/hFYhHxlV+oUrGHpDV+p2c4faFUMEyo6FC+fBvM1h8JgM+Bk8kaf8YSUuop6Xwc4s/yF46dB6CdCaVJPvI9m3elj6Cg9EAXq7GY=""
+  DATABASE_URL: ""AgACJkybaNon1X7ZkvtyM0mJ3Gfbjh1LWSJdWGC3ny6QU/8yERomTjvDylHuFoaoGeEs5ewYtgH87G/t1q3LF35cjmipGTSJbxFKfyoRcGBZSajen2Ijs+satVD7T6bmCNsurEsUD16QDLoV5lx+THXdEjv4VrBtFwY0HO2BIP15X/vMie9Mk91Uk1eze5dj8WoQ5OywH8O8Ugh7/iOleEyiPaMzxdRAfwvYHgX5QYqDno0ktZFyKnDOpCnegIwcUei4tt+EiTAG1SxESk48DQQokNrZc+lqlPwozX6FOYkgcQiZZqIN+9qOy5hB+1wKggS8zcd7/YAlSpSd8LMeAokflxOabN5Ctyvx3k5tGgstKQabW1TErwL8RjB3WYClLvJl8bfc4qILr4jpfA4all59f8oinATiyeqJ3Hx267FdHH2aywnXnNdEmycGhKkuH0vAa74oYsUiD9BrjkxmMdxCwmEjl47ob5fwcraKOc7hNF+hPi2C61/z1T6yoIeu4ediMTk0m1ZPIOotlbj/nKkmrKDfD+WMia/YvBpUtlM/SaEyX66gmO03kxW92cmXVCjK65oGh0ueCyK84J9e/2y+qO6yFXh7991+wTQyAedBBoc2myNcebKzuAmFNwanCs+FMOktPZsMMzfFy3oHJQxgFkPEp+jKennODqTe0A3LBhJC3ddwCYgd1TAABC2+DqFGaCRiyaSZ4BZIitEPFzpJwITIFZoRyxrCibrGKKnILVjGNaiV/KdIzfj70AAdzG/7GFdA9SKzRQimnVw99YTjNouCYzt7iLBV/8KrcMvyyeHZle1A6zg0gjjj4Yp6p0ssIOvhuDLjec4NMi/E5EbgYzKQFr7jN2u9%""
   SENTRY_DSN: ""AgB9i02k9BgaIXF0p9Qyyeo0PRa9bd3UiPBWQ3V4Jn19Vy5XAzKfYvqP8t+vafN2ffY+wCk1FlhYzdIuFjh3oRvdKvtwGEBZk6nLFiUrw/GSum0ueR2OzEy+AwGFXA9FstD0KCMJvyehSv9xRm9kqLOC4Xb/5lOWwTNF3AKqkEMEeKrOWx4OLXG6MLdR7OicY45BCE5WvcV2PizDaN5w3J72eUxFP0HjXit/aW/gK32IJME0RxeuQZ5TnPKTNrooYPR0eWXd2PgYshFjQ2ARy/OsvOrD10y8tQ3M5qx/HNWLC/r0lEu2np+9iUIAE1ufSwjmNSyi4V8usdZWq7xnf3vuKlSgmveqKkLbwQUWj1BpLNIjUvyY+1Rk1rxup/WCgaw+xOZd6sR/qTIjILv5GuzpU0AiwEm7sgl2pmpFXq6n6QjNOfZoPBTL73f4bpXNJ3EyMYDbPxOtGDz91B+bDtOsMr1DNWQslKkk3EIilm/l0+NuLKxf/e2HwM3sB15mkQqVZBdbiVOr7B27cR9xAnr296KE/BU6E9dp/fl+IgcaonMpTsE61pCLHWxQXNBO5X078/zhmaXBQyEBNQ5SPDr9u3pHWrrLkBtXwldZvgmLMMVFMAzrVVkJB4lC9sZj0pXPhda0/BsA4xcGRELj/PizwSr+kb3lDumNMqzEap5ZjEGCBpeeIVSo19v+RoEDw0AFmyxfYx2+91HsgiEqjEUg+J6yDmjAoRpOD1wRZOnnpR8ufMiqdBteCG8B5SXkhgto1WtDyOMVlX2wbmBFVetv2nAbMIA/l4E/Yv8HXiJsTqAkeYc5Qak6/SMGnZTw7Q==""
   SUPABASE_SERVICE_ROLE_KEY: ""AgCrHCd2AdIv++sX7AAf0YoV+qDFhPuErd/Q9Jgj8/1wDJklqv0giI/M7TRUV6j2Gqa/yLP90Hoiy2BboE0V3FrTtHzasxtSK0hd93+bxvZ34FEfKQyAiddBR8OxzlPwaplzaJ+/Tu+yHf1EesgXrUdydk38D4AQqkrC30FRKJcCxJNTHHzsZiHGQLZNP2l0cEsmqtMXMk8TqbcqHvJZRpr8jP1dSJ7bxEdU9mH/zB4HV+EsPLDFWFAnFjbEQwv8FEGgqpy81ifch4Hz7S0wjwk0x/QsagKavBTvI579K6Sx7uJyMyilpzm5Ct8kDXTEGUWv7pFINXM5cAbcBNzuvwvtXmshMwRsl9e/5Y2/T2VgS7/wPTJA4AmyyrSK976SOjo7imb4XfMwc6Cc/2GE0BRW9jiKvzjQ1TC2ovQpNujTYYgPzIq8sFXEVss31DIcfwbRAzgKTTQZKl+H+i9AS0q6iYHtKORwTQ2bv2XwQwxogXMHTUq1oC3MkzjKfV9DcoTHU2o/+gTyOBW5i3BRatuublA1x0EwDoEVmWA1+i1h2bpkl4QYuyeNlhJnRHzuQU3RdFLWn3MkDM8Q4Y9n0/XXwwTCgqtdAExqNh3YJYumWiGiWfdBpEUqlUtOUurNMXy6rHH4odnNKeLQfMOa9406x5H5xiwNkl3mzGjNiPDMS7JMTptlsoL8DshE2TM0PqZVrQy81OsGNpdiU8MVeUdHO6/bDBe7j9v0FipqpeehX1AZEYb/4CWosTJACWpaTnLYRh+w12bk3x6Sj0kriDKMOuJLBRh1fveZXUC9C0FsEPhq2rBLQDVh78DkBIeKVGUzuxDP/6mT3OSBPe4aCye0vTmwtEOEvB+A7rcMkOl+j90bKAveE9H+f7UVU6Og40Nc3sSuMolKHbQyB9TNd4+jOfmySSN675riL6BpFFCSuWqjrqWFr0yI1h/xAg+YMg8WzWarwSeWr3ykXrbhQvu7Oj27ffLXEIvS0gU=""
\ No newline at end of file",fix
"build(rnd): Add missing libs folder (#7887)

add missing libs folder","--- rnd/autogpt_server/Dockerfile ---
@@ -26,6 +26,7 @@ ENV POETRY_VERSION=1.8.3 \
 RUN pip3 install poetry
 
 COPY rnd/autogpt_server /app/rnd/autogpt_server
+COPY rnd/autogpt_libs /app/rnd/autogpt_libs
 COPY autogpt /app/autogpt
 COPY forge /app/forge",build
"refactor(frontend): Update buttons to edit agents in Monitor (#8687)

Update Monitor buttons

Co-authored-by: Aarushi <50577581+aarushik93@users.noreply.github.com>","--- autogpt_platform/frontend/src/components/monitor/FlowInfo.tsx ---
@@ -105,10 +105,11 @@ export const FlowInfo: React.FC<
             </DropdownMenu>
           )}
           <Link
-            className={buttonVariants({ variant: ""outline"" })}
+            className={buttonVariants({ variant: ""default"" })}
             href={`/build?flowID=${flow.id}`}
           >
-            <Pencil2Icon />
+            <Pencil2Icon className=""mr-2"" />
+            Open in Builder
           </Link>
           <Button
             variant=""outline""
@@ -126,7 +127,7 @@ export const FlowInfo: React.FC<
               )
             }
           >
-            <ExitIcon />
+            <ExitIcon className=""mr-2"" /> Export
           </Button>
           <Button variant=""outline"" onClick={() => setIsDeleteModalOpen(true)}>
             <Trash2Icon className=""h-full"" />

--- autogpt_platform/frontend/src/components/monitor/FlowRunInfo.tsx ---
@@ -47,10 +47,10 @@ export const FlowRunInfo: React.FC<
             </Button>
           )}
           <Link
-            className={buttonVariants({ variant: ""outline"" })}
+            className={buttonVariants({ variant: ""default"" })}
             href={`/build?flowID=${flow.id}`}
           >
-            <Pencil2Icon className=""mr-2"" /> Edit Agent
+            <Pencil2Icon className=""mr-2"" /> Open in Builder
           </Link>
         </div>
       </CardHeader>",refactor
fix(backend): Avoid long synchronous call to block FastAPI event-loop (#8429),"--- autogpt_platform/autogpt_libs/autogpt_libs/supabase_integration_credentials_store/store.py ---
@@ -6,7 +6,7 @@
     from redis import Redis
     from backend.executor.database import DatabaseManager
 
-from autogpt_libs.utils.cache import thread_cached_property
+from autogpt_libs.utils.cache import thread_cached
 from autogpt_libs.utils.synchronize import RedisKeyedMutex
 
 from .types import (
@@ -21,8 +21,9 @@
 class SupabaseIntegrationCredentialsStore:
     def __init__(self, redis: ""Redis""):
         self.locks = RedisKeyedMutex(redis)
-        
-    @thread_cached_property
+
+    @property
+    @thread_cached
     def db_manager(self) -> ""DatabaseManager"":
         from backend.executor.database import DatabaseManager
         from backend.util.service import get_service_client

--- autogpt_platform/autogpt_libs/autogpt_libs/utils/cache.py ---
@@ -1,16 +1,13 @@
+from typing import Callable, TypeVar, ParamSpec
 import threading
-from functools import wraps
-from typing import Callable, ParamSpec, TypeVar
 
-T = TypeVar(""T"")
 P = ParamSpec(""P"")
 R = TypeVar(""R"")
 
 
 def thread_cached(func: Callable[P, R]) -> Callable[P, R]:
     thread_local = threading.local()
 
-    @wraps(func)
     def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
         cache = getattr(thread_local, ""cache"", None)
         if cache is None:
@@ -21,7 +18,3 @@ def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
         return cache[key]
 
     return wrapper
-
-
-def thread_cached_property(func: Callable[[T], R]) -> property:
-    return property(thread_cached(func))

--- autogpt_platform/backend/backend/executor/scheduler.py ---
@@ -4,7 +4,7 @@
 
 from apscheduler.schedulers.background import BackgroundScheduler
 from apscheduler.triggers.cron import CronTrigger
-from autogpt_libs.utils.cache import thread_cached_property
+from autogpt_libs.utils.cache import thread_cached
 
 from backend.data.block import BlockInput
 from backend.data.schedule import (
@@ -37,7 +37,8 @@ def __init__(self, refresh_interval=10):
     def get_port(cls) -> int:
         return Config().execution_scheduler_port
 
-    @thread_cached_property
+    @property
+    @thread_cached
     def execution_client(self) -> ExecutionManager:
         return get_service_client(ExecutionManager)
 

--- autogpt_platform/backend/backend/server/integrations/router.py ---
@@ -29,7 +29,7 @@ class LoginResponse(BaseModel):
 
 
 @router.get(""/{provider}/login"")
-async def login(
+def login(
     provider: Annotated[str, Path(title=""The provider to initiate an OAuth flow for"")],
     user_id: Annotated[str, Depends(get_user_id)],
     request: Request,
@@ -60,7 +60,7 @@ class CredentialsMetaResponse(BaseModel):
 
 
 @router.post(""/{provider}/callback"")
-async def callback(
+def callback(
     provider: Annotated[str, Path(title=""The target provider for this OAuth exchange"")],
     code: Annotated[str, Body(title=""Authorization code acquired by user login"")],
     state_token: Annotated[str, Body(title=""Anti-CSRF nonce"")],
@@ -115,7 +115,7 @@ async def callback(
 
 
 @router.get(""/{provider}/credentials"")
-async def list_credentials(
+def list_credentials(
     provider: Annotated[str, Path(title=""The provider to list credentials for"")],
     user_id: Annotated[str, Depends(get_user_id)],
 ) -> list[CredentialsMetaResponse]:
@@ -133,7 +133,7 @@ async def list_credentials(
 
 
 @router.get(""/{provider}/credentials/{cred_id}"")
-async def get_credential(
+def get_credential(
     provider: Annotated[str, Path(title=""The provider to retrieve credentials for"")],
     cred_id: Annotated[str, Path(title=""The ID of the credentials to retrieve"")],
     user_id: Annotated[str, Depends(get_user_id)],
@@ -149,7 +149,7 @@ async def get_credential(
 
 
 @router.post(""/{provider}/credentials"", status_code=201)
-async def create_api_key_credentials(
+def create_api_key_credentials(
     user_id: Annotated[str, Depends(get_user_id)],
     provider: Annotated[str, Path(title=""The provider to create credentials for"")],
     api_key: Annotated[str, Body(title=""The API key to store"")],
@@ -184,7 +184,7 @@ class CredentialsDeletionResponse(BaseModel):
 
 
 @router.delete(""/{provider}/credentials/{cred_id}"")
-async def delete_credentials(
+def delete_credentials(
     request: Request,
     provider: Annotated[str, Path(title=""The provider to delete credentials for"")],
     cred_id: Annotated[str, Path(title=""The ID of the credentials to delete"")],

--- autogpt_platform/backend/backend/server/rest_api.py ---
@@ -1,3 +1,4 @@
+import asyncio
 import inspect
 import logging
 from collections import defaultdict
@@ -7,7 +8,7 @@
 
 import uvicorn
 from autogpt_libs.auth.middleware import auth_middleware
-from autogpt_libs.utils.cache import thread_cached_property
+from autogpt_libs.utils.cache import thread_cached
 from fastapi import APIRouter, Body, Depends, FastAPI, HTTPException, Request
 from fastapi.middleware.cors import CORSMiddleware
 from fastapi.responses import JSONResponse
@@ -307,11 +308,13 @@ async def wrapper(*args, **kwargs):
 
         return wrapper
 
-    @thread_cached_property
+    @property
+    @thread_cached
     def execution_manager_client(self) -> ExecutionManager:
         return get_service_client(ExecutionManager)
 
-    @thread_cached_property
+    @property
+    @thread_cached
     def execution_scheduler_client(self) -> ExecutionScheduler:
         return get_service_client(ExecutionScheduler)
 
@@ -516,7 +519,7 @@ async def set_graph_active_version(
             user_id=user_id,
         )
 
-    async def execute_graph(
+    def execute_graph(
         self,
         graph_id: str,
         node_input: dict[Any, Any],
@@ -539,7 +542,9 @@ async def stop_graph_run(
                 404, detail=f""Agent execution #{graph_exec_id} not found""
             )
 
-        self.execution_manager_client.cancel_execution(graph_exec_id)
+        await asyncio.to_thread(
+            lambda: self.execution_manager_client.cancel_execution(graph_exec_id)
+        )
 
         # Retrieve & return canceled graph execution in its final state
         return await execution_db.get_execution_results(graph_exec_id)
@@ -614,10 +619,16 @@ async def create_schedule(
         graph = await graph_db.get_graph(graph_id, user_id=user_id)
         if not graph:
             raise HTTPException(status_code=404, detail=f""Graph #{graph_id} not found."")
-        execution_scheduler = self.execution_scheduler_client
+
         return {
-            ""id"": execution_scheduler.add_execution_schedule(
-                graph_id, graph.version, cron, input_data, user_id=user_id
+            ""id"": await asyncio.to_thread(
+                lambda: self.execution_scheduler_client.add_execution_schedule(
+                    graph_id=graph_id,
+                    graph_version=graph.version,
+                    cron=cron,
+                    input_data=input_data,
+                    user_id=user_id,
+                )
             )
         }
 

--- autogpt_platform/backend/backend/usecases/block_autogen.py ---
@@ -252,7 +252,7 @@ async def block_autogen_agent():
         test_user = await create_test_user()
         test_graph = await create_graph(create_test_graph(), user_id=test_user.id)
         input_data = {""input"": ""Write me a block that writes a string into a file.""}
-        response = await server.agent_server.execute_graph(
+        response = server.agent_server.execute_graph(
             test_graph.id, input_data, test_user.id
         )
         print(response)

--- autogpt_platform/backend/backend/usecases/reddit_marketing.py ---
@@ -156,7 +156,7 @@ async def reddit_marketing_agent():
         test_user = await create_test_user()
         test_graph = await create_graph(create_test_graph(), user_id=test_user.id)
         input_data = {""subreddit"": ""AutoGPT""}
-        response = await server.agent_server.execute_graph(
+        response = server.agent_server.execute_graph(
             test_graph.id, input_data, test_user.id
         )
         print(response)

--- autogpt_platform/backend/backend/usecases/sample.py ---
@@ -78,7 +78,7 @@ async def sample_agent():
         test_user = await create_test_user()
         test_graph = await create_graph(create_test_graph(), test_user.id)
         input_data = {""input_1"": ""Hello"", ""input_2"": ""World""}
-        response = await server.agent_server.execute_graph(
+        response = server.agent_server.execute_graph(
             test_graph.id, input_data, test_user.id
         )
         print(response)

--- autogpt_platform/backend/test/executor/test_manager.py ---
@@ -22,7 +22,7 @@ async def execute_graph(
     num_execs: int = 4,
 ) -> str:
     # --- Test adding new executions --- #
-    response = await agent_server.execute_graph(test_graph.id, input_data, test_user.id)
+    response = agent_server.execute_graph(test_graph.id, input_data, test_user.id)
     graph_exec_id = response[""id""]
 
     # Execution queue should be empty",fix
"build(rnd): incorrect docker image for migrate (#8086)

fix incorrect docker image for migrate","--- rnd/docker-compose.yml ---
@@ -16,7 +16,10 @@ services:
       - app-network
 
   migrate:
-    image: autogpt_server:latest
+    build:
+      context: ../
+      dockerfile: rnd/autogpt_server/Dockerfile
+      target: server
     command: [""sh"", ""-c"", ""poetry run prisma migrate deploy""]
     develop:
       watch:",build
fix(rnd): Fix broken list input pin execution ordering & unlinked dynamic pins on save (#8108),"--- autogpt_platform/backend/backend/blocks/time_blocks.py ---
@@ -23,7 +23,7 @@ def __init__(self):
                 {""trigger"": ""Hello"", ""format"": ""{time}""},
             ],
             test_output=[
-                (""time"", time.strftime(""%H:%M:%S"")),
+                (""time"", lambda _: time.strftime(""%H:%M:%S"")),
             ],
         )
 

--- autogpt_platform/backend/backend/data/execution.py ---
@@ -396,19 +396,19 @@ def merge_execution_input(data: BlockInput) -> BlockInput:
 
     # Merge all input with <input_name>_$_<index> into a single list.
     items = list(data.items())
-    list_input: list[Any] = []
+
     for key, value in items:
         if LIST_SPLIT not in key:
             continue
         name, index = key.split(LIST_SPLIT)
         if not index.isdigit():
-            list_input.append((name, value, 0))
-        else:
-            list_input.append((name, value, int(index)))
+            raise ValueError(f""Invalid key: {key}, #{index} index must be an integer."")
 
-    for name, value, _ in sorted(list_input, key=lambda x: x[2]):
         data[name] = data.get(name, [])
-        data[name].append(value)
+        if int(index) >= len(data[name]):
+            # Pad list with empty string on missing indices.
+            data[name].extend([""""] * (int(index) - len(data[name]) + 1))
+        data[name][int(index)] = value
 
     # Merge all input with <input_name>_#_<index> into a single dict.
     for key, value in items:

--- autogpt_platform/frontend/src/lib/utils.ts ---
@@ -152,21 +152,22 @@ export function setNestedProperty(obj: any, path: string, value: any) {
 
 export function removeEmptyStringsAndNulls(obj: any): any {
   if (Array.isArray(obj)) {
-    // If obj is an array, recursively remove empty strings and nulls from its elements
-    return obj
-      .map((item) => removeEmptyStringsAndNulls(item))
-      .filter(
-        (item) =>
-          item !== null && (typeof item !== ""string"" || item.trim() !== """"),
-      );
+    // If obj is an array, recursively check each element,
+    // but element removal is avoided to prevent index changes.
+    return obj.map((item) =>
+      item === undefined || item === null
+        ? """"
+        : removeEmptyStringsAndNulls(item),
+    );
   } else if (typeof obj === ""object"" && obj !== null) {
     // If obj is an object, recursively remove empty strings and nulls from its properties
     for (const key in obj) {
       if (obj.hasOwnProperty(key)) {
         const value = obj[key];
         if (
           value === null ||
-          (typeof value === ""string"" && value.trim() === """")
+          value === undefined ||
+          (typeof value === ""string"" && value === """")
         ) {
           delete obj[key];
         } else {",fix
"fix(platform): Update deletion of secret values to not do it in place (#8284)

update deletion of secret values to not do it in place","--- autogpt_platform/backend/backend/data/graph.py ---
@@ -360,20 +360,25 @@ def _process_node(node: AgentNode, hide_credentials: bool) -> Node:
         node_dict = node.model_dump()
         if hide_credentials and ""constantInput"" in node_dict:
             constant_input = json.loads(node_dict[""constantInput""])
-            Graph._hide_credentials_in_input(constant_input)
+            constant_input = Graph._hide_credentials_in_input(constant_input)
             node_dict[""constantInput""] = json.dumps(constant_input)
         return Node.from_db(AgentNode(**node_dict))
 
     @staticmethod
-    def _hide_credentials_in_input(input_data: dict[str, Any]):
+    def _hide_credentials_in_input(input_data: dict[str, Any]) -> dict[str, Any]:
         sensitive_keys = [""credentials"", ""api_key"", ""password"", ""token"", ""secret""]
+        result = {}
         for key, value in input_data.items():
             if isinstance(value, dict):
-                Graph._hide_credentials_in_input(value)
+                result[key] = Graph._hide_credentials_in_input(value)
             elif isinstance(value, str) and any(
                 sensitive_key in key.lower() for sensitive_key in sensitive_keys
             ):
-                del input_data[key]
+                # Skip this key-value pair in the result
+                continue
+            else:
+                result[key] = value
+        return result
 
 
 AGENT_NODE_INCLUDE: prisma.types.AgentNodeInclude = {",fix
refactor(platform): Add implicit typing conversion of nested data-structure (#8231),"--- autogpt_platform/backend/backend/util/type.py ---
@@ -1,5 +1,5 @@
 import json
-from typing import Any, Type, TypeVar, get_origin
+from typing import Any, Type, TypeVar, get_args, get_origin
 
 
 class ConversionError(Exception):
@@ -103,26 +103,75 @@ def __convert_bool(value: Any) -> bool:
 
 
 def convert(value: Any, target_type: Type):
-    target_type = get_origin(target_type) or target_type
-    if target_type not in [list, dict, tuple, str, set, int, float, bool]:
+    origin = get_origin(target_type)
+    args = get_args(target_type)
+    if origin is None:
+        origin = target_type
+    if origin not in [list, dict, tuple, str, set, int, float, bool]:
         return value
-    if isinstance(value, target_type):
-        return value
-    if target_type is list:
-        return __convert_list(value)
-    elif target_type is dict:
-        return __convert_dict(value)
-    elif target_type is tuple:
-        return __convert_tuple(value)
-    elif target_type is str:
-        return __convert_str(value)
-    elif target_type is set:
-        return __convert_set(value)
-    elif target_type is int:
-        return __convert_num(value, int)
-    elif target_type is float:
-        return __convert_num(value, float)
-    elif target_type is bool:
-        return __convert_bool(value)
+
+    # Handle the case when value is already of the target type
+    if isinstance(value, origin):
+        if not args:
+            return value
+        else:
+            # Need to convert elements
+            if origin is list:
+                return [convert(v, args[0]) for v in value]
+            elif origin is tuple:
+                # Tuples can have multiple types
+                if len(args) == 1:
+                    return tuple(convert(v, args[0]) for v in value)
+                else:
+                    return tuple(convert(v, t) for v, t in zip(value, args))
+            elif origin is dict:
+                key_type, val_type = args
+                return {
+                    convert(k, key_type): convert(v, val_type) for k, v in value.items()
+                }
+            elif origin is set:
+                return {convert(v, args[0]) for v in value}
+            else:
+                return value
     else:
-        return value
+        # Need to convert value to the origin type
+        if origin is list:
+            value = __convert_list(value)
+            if args:
+                return [convert(v, args[0]) for v in value]
+            else:
+                return value
+        elif origin is dict:
+            value = __convert_dict(value)
+            if args:
+                key_type, val_type = args
+                return {
+                    convert(k, key_type): convert(v, val_type) for k, v in value.items()
+                }
+            else:
+                return value
+        elif origin is tuple:
+            value = __convert_tuple(value)
+            if args:
+                if len(args) == 1:
+                    return tuple(convert(v, args[0]) for v in value)
+                else:
+                    return tuple(convert(v, t) for v, t in zip(value, args))
+            else:
+                return value
+        elif origin is str:
+            return __convert_str(value)
+        elif origin is set:
+            value = __convert_set(value)
+            if args:
+                return {convert(v, args[0]) for v in value}
+            else:
+                return value
+        elif origin is int:
+            return __convert_num(value, int)
+        elif origin is float:
+            return __convert_num(value, float)
+        elif origin is bool:
+            return __convert_bool(value)
+        else:
+            return value

--- autogpt_platform/backend/test/util/test_type.py ---
@@ -27,5 +27,6 @@ def test_type_conversion():
 
     from typing import List
 
-    # assert convert(""5"", List[int]) == [5]
+    assert convert(""5"", List[int]) == [5]
     assert convert(""[5,4,2]"", List[int]) == [5, 4, 2]
+    assert convert([5, 4, 2], List[str]) == [""5"", ""4"", ""2""]",refactor
feat(backend): Enable json parsing with typing & conversion (#8578),"--- autogpt_platform/backend/backend/data/execution.py ---
@@ -97,7 +97,7 @@ def from_graph(graph: AgentGraphExecution):
     def from_db(execution: AgentNodeExecution):
         if execution.executionData:
             # Execution that has been queued for execution will persist its data.
-            input_data = json.loads(execution.executionData)
+            input_data = json.loads(execution.executionData, target_type=dict[str, Any])
         else:
             # For incomplete execution, executionData will not be yet available.
             input_data: BlockInput = defaultdict()

--- autogpt_platform/backend/backend/data/graph.py ---
@@ -56,8 +56,8 @@ def from_db(node: AgentNode):
         obj = Node(
             id=node.id,
             block_id=node.AgentBlock.id,
-            input_default=json.loads(node.constantInput),
-            metadata=json.loads(node.metadata),
+            input_default=json.loads(node.constantInput, target_type=dict[str, Any]),
+            metadata=json.loads(node.metadata, target_type=dict[str, Any]),
         )
         obj.input_links = [Link.from_db(link) for link in node.Input or []]
         obj.output_links = [Link.from_db(link) for link in node.Output or []]
@@ -80,10 +80,13 @@ def from_db(execution: AgentGraphExecution):
         duration = (end_time - start_time).total_seconds()
         total_run_time = duration
 
-        if execution.stats:
-            stats = json.loads(execution.stats)
-            duration = stats.get(""walltime"", duration)
-            total_run_time = stats.get(""nodes_walltime"", total_run_time)
+        try:
+            stats = json.loads(execution.stats or ""{}"", target_type=dict[str, Any])
+        except ValueError:
+            stats = {}
+
+        duration = stats.get(""walltime"", duration)
+        total_run_time = stats.get(""nodes_walltime"", total_run_time)
 
         return GraphExecution(
             id=execution.id,
@@ -311,7 +314,9 @@ def from_db(graph: AgentGraph, hide_credentials: bool = False):
     def _process_node(node: AgentNode, hide_credentials: bool) -> Node:
         node_dict = node.model_dump()
         if hide_credentials and ""constantInput"" in node_dict:
-            constant_input = json.loads(node_dict[""constantInput""])
+            constant_input = json.loads(
+                node_dict[""constantInput""], target_type=dict[str, Any]
+            )
             constant_input = Graph._hide_credentials_in_input(constant_input)
             node_dict[""constantInput""] = json.dumps(constant_input)
         return Node.from_db(AgentNode(**node_dict))

--- autogpt_platform/backend/backend/util/json.py ---
@@ -1,7 +1,10 @@
 import json
+from typing import Any, Type, TypeVar, overload
 
 from fastapi.encoders import jsonable_encoder
 
+from .type import type_match
+
 
 def to_dict(data) -> dict:
     return jsonable_encoder(data)
@@ -11,4 +14,19 @@ def dumps(data) -> str:
     return json.dumps(jsonable_encoder(data))
 
 
-loads = json.loads
+T = TypeVar(""T"")
+
+
+@overload
+def loads(data: str, *args, target_type: Type[T], **kwargs) -> T: ...
+
+
+@overload
+def loads(data: str, *args, **kwargs) -> Any: ...
+
+
+def loads(data: str, *args, target_type: Type[T] | None = None, **kwargs) -> Any:
+    parsed = json.loads(data, *args, **kwargs)
+    if target_type:
+        return type_match(parsed, target_type)
+    return parsed

--- autogpt_platform/backend/backend/util/type.py ---
@@ -1,8 +1,8 @@
 import json
-from typing import Any, Type, TypeVar, get_args, get_origin
+from typing import Any, Type, TypeVar, cast, get_args, get_origin
 
 
-class ConversionError(Exception):
+class ConversionError(ValueError):
     pass
 
 
@@ -102,7 +102,7 @@ def __convert_bool(value: Any) -> bool:
         return bool(value)
 
 
-def convert(value: Any, target_type: Type):
+def _try_convert(value: Any, target_type: Type, raise_on_mismatch: bool) -> Any:
     origin = get_origin(target_type)
     args = get_args(target_type)
     if origin is None:
@@ -133,6 +133,8 @@ def convert(value: Any, target_type: Type):
                 return {convert(v, args[0]) for v in value}
             else:
                 return value
+    elif raise_on_mismatch:
+        raise TypeError(f""Value {value} is not of expected type {target_type}"")
     else:
         # Need to convert value to the origin type
         if origin is list:
@@ -175,3 +177,17 @@ def convert(value: Any, target_type: Type):
             return __convert_bool(value)
         else:
             return value
+
+
+T = TypeVar(""T"")
+
+
+def type_match(value: Any, target_type: Type[T]) -> T:
+    return cast(T, _try_convert(value, target_type, raise_on_mismatch=True))
+
+
+def convert(value: Any, target_type: Type[T]) -> T:
+    try:
+        return cast(T, _try_convert(value, target_type, raise_on_mismatch=False))
+    except Exception as e:
+        raise ConversionError(f""Failed to convert {value} to {target_type}"") from e",feat
"feat(builder): Updated Block Categories and colouring (#7794)

* Updated Block Categories

* formatting

* Added category coloring","--- rnd/autogpt_builder/src/components/CustomNode.tsx ---
@@ -24,13 +24,15 @@ import NodeHandle from ""./NodeHandle"";
 import { CustomEdgeData } from ""./CustomEdge"";
 import { NodeGenericInputField } from ""./node-input-components"";
 import SchemaTooltip from ""./SchemaTooltip"";
+import { getPrimaryCategoryColor } from ""@/lib/utils"";
 
 type ParsedKey = { key: string; index?: number };
 
 export type CustomNodeData = {
   blockType: string;
   title: string;
   description: string;
+  categories: string[];
   inputSchema: BlockIORootSchema;
   outputSchema: BlockIORootSchema;
   hardcodedValues: { [key: string]: any };
@@ -283,7 +285,9 @@ const CustomNode: FC<NodeProps<CustomNodeData>> = ({ data, id }) => {
       onMouseEnter={handleHovered}
       onMouseLeave={handleMouseLeave}
     >
-      <div className=""mb-2 p-3 bg-gray-300/[.7] rounded-t-xl"">
+      <div
+        className={`mb-2 p-3 ${getPrimaryCategoryColor(data.categories)} rounded-t-xl`}
+      >
         <div className=""flex items-center justify-between"">
           <div className=""p-3 text-lg font-semibold font-roboto"">
             {beautifyString(

--- rnd/autogpt_builder/src/components/Flow.tsx ---
@@ -381,6 +381,7 @@ const FlowEditor: React.FC<{
           blockType: nodeType,
           title: `${nodeType} ${nodeId}`,
           description: nodeSchema.description,
+          categories: nodeSchema.categories,
           inputSchema: nodeSchema.inputSchema,
           outputSchema: nodeSchema.outputSchema,
           hardcodedValues: {},
@@ -460,6 +461,7 @@ const FlowEditor: React.FC<{
           data: {
             block_id: block.id,
             blockType: block.name,
+            categories: block.categories,
             description: block.description,
             title: `${block.name} ${node.id}`,
             inputSchema: block.inputSchema,

--- rnd/autogpt_builder/src/components/edit/control/BlocksControl.tsx ---
@@ -15,7 +15,7 @@ import { Block } from ""@/lib/autogpt-server-api"";
 import { PlusIcon } from ""@radix-ui/react-icons"";
 import { IconToyBrick } from ""@/components/ui/icons"";
 import SchemaTooltip from ""@/components/SchemaTooltip"";
-
+import { getPrimaryCategoryColor } from ""@/lib/utils"";
 interface BlocksControlProps {
   blocks: Block[];
   addBlock: (id: string, name: string) => void;
@@ -74,7 +74,10 @@ export const BlocksControl: React.FC<BlocksControlProps> = ({
           <CardContent className=""p-1"">
             <ScrollArea className=""h-[60vh]"">
               {filteredBlocks.map((block) => (
-                <Card key={block.id} className=""m-2"">
+                <Card
+                  key={block.id}
+                  className={`m-2 ${getPrimaryCategoryColor(block.categories)}`}
+                >
                   <div className=""flex items-center justify-between m-3"">
                     <div className=""flex-1 min-w-0 mr-2"">
                       <span className=""font-medium truncate block"">

--- rnd/autogpt_builder/src/lib/autogpt-server-api/types.ts ---
@@ -1,8 +1,15 @@
 /* Mirror of autogpt_server/data/block.py:Block */
+
+export type Category = {
+  category: string;
+  description: string;
+};
+
 export type Block = {
   id: string;
   name: string;
   description: string;
+  categories: Category[];
   inputSchema: BlockIORootSchema;
   outputSchema: BlockIORootSchema;
 };

--- rnd/autogpt_builder/src/lib/utils.ts ---
@@ -1,5 +1,6 @@
 import { type ClassValue, clsx } from ""clsx"";
 import { twMerge } from ""tailwind-merge"";
+import { Category } from ""./autogpt-server-api/types"";
 
 export function cn(...inputs: ClassValue[]) {
   return twMerge(clsx(inputs));
@@ -175,3 +176,21 @@ export function removeEmptyStringsAndNulls(obj: any): any {
   }
   return obj;
 }
+
+export const categoryColorMap: Record<string, string> = {
+  AI: ""bg-orange-300/[.7]"",
+  SOCIAL: ""bg-yellow-300/[.7]"",
+  TEXT: ""bg-green-300/[.7]"",
+  SEARCH: ""bg-blue-300/[.7]"",
+  BASIC: ""bg-purple-300/[.7]"",
+  INPUT: ""bg-cyan-300/[.7]"",
+  OUTPUT: ""bg-brown-300/[.7]"",
+  LOGIC: ""bg-teal-300/[.7]"",
+};
+
+export function getPrimaryCategoryColor(categories: Category[]): string {
+  if (categories.length === 0) {
+    return ""bg-gray-300/[.7]"";
+  }
+  return categoryColorMap[categories[0].category] || ""bg-gray-300/[.7]"";
+}

--- rnd/autogpt_server/autogpt_server/blocks/agent.py ---
@@ -108,7 +108,7 @@ def __init__(self):
         super().__init__(
             id=""d2e2ecd2-9ae6-422d-8dfe-ceca500ce6a6"",
             description=""AutoGPT agent, it utilizes a Large Language Model and enabled components/tools to perform a task."",
-            categories={BlockCategory.LLM},
+            categories={BlockCategory.AI},
             input_schema=AutoGPTAgentBlock.Input,
             output_schema=AutoGPTAgentBlock.Output,
             test_input={

--- rnd/autogpt_server/autogpt_server/blocks/basic.py ---
@@ -158,7 +158,6 @@ def run(self, input_data: ObjectLookupBaseInput[T]) -> BlockOutput:
 
 
 class ObjectLookupBlock(ObjectLookupBase[Any]):
-
     def __init__(self):
         super().__init__(categories={BlockCategory.BASIC})
 
@@ -167,18 +166,16 @@ def block_id(self) -> str:
 
 
 class InputBlock(ObjectLookupBase[Any]):
-
     def __init__(self):
-        super().__init__(categories={BlockCategory.BASIC, BlockCategory.INPUT_OUTPUT})
+        super().__init__(categories={BlockCategory.BASIC, BlockCategory.INPUT})
 
     def block_id(self) -> str:
         return ""c0a8e994-ebf1-4a9c-a4d8-89d09c86741b""
 
 
 class OutputBlock(ObjectLookupBase[Any]):
-
     def __init__(self):
-        super().__init__(categories={BlockCategory.BASIC, BlockCategory.INPUT_OUTPUT})
+        super().__init__(categories={BlockCategory.BASIC, BlockCategory.OUTPUT})
 
     def block_id(self) -> str:
         return ""363ae599-353e-4804-937e-b2ee3cef3da4""

--- rnd/autogpt_server/autogpt_server/blocks/llm.py ---
@@ -93,7 +93,7 @@ def __init__(self):
         super().__init__(
             id=""ed55ac19-356e-4243-a6cb-bc599e9b716f"",
             description=""Call a Large Language Model (LLM) to generate formatted object based on the given prompt."",
-            categories={BlockCategory.LLM},
+            categories={BlockCategory.AI},
             input_schema=ObjectLlmCallBlock.Input,
             output_schema=ObjectLlmCallBlock.Output,
             test_input={
@@ -261,7 +261,7 @@ def __init__(self):
         super().__init__(
             id=""1f292d4a-41a4-4977-9684-7c8d560b9f91"",
             description=""Call a Large Language Model (LLM) to generate a string based on the given prompt."",
-            categories={BlockCategory.LLM},
+            categories={BlockCategory.AI},
             input_schema=TextLlmCallBlock.Input,
             output_schema=TextLlmCallBlock.Output,
             test_input={""prompt"": ""User prompt""},
@@ -307,7 +307,7 @@ def __init__(self):
         super().__init__(
             id=""c3d4e5f6-7g8h-9i0j-1k2l-m3n4o5p6q7r8"",
             description=""Utilize a Large Language Model (LLM) to summarize a long text."",
-            categories={BlockCategory.LLM, BlockCategory.TEXT},
+            categories={BlockCategory.AI, BlockCategory.TEXT},
             input_schema=TextSummarizerBlock.Input,
             output_schema=TextSummarizerBlock.Output,
             test_input={""text"": ""Lorem ipsum..."" * 100},
@@ -450,7 +450,7 @@ def __init__(self):
         super().__init__(
             id=""c3d4e5f6-g7h8-i9j0-k1l2-m3n4o5p6q7r8"",
             description=""Advanced LLM call that takes a list of messages and sends them to the language model."",
-            categories={BlockCategory.LLM},
+            categories={BlockCategory.AI},
             input_schema=AdvancedLlmCallBlock.Input,
             output_schema=AdvancedLlmCallBlock.Output,
             test_input={
@@ -495,7 +495,9 @@ def llm_call(
         elif provider == ""anthropic"":
             client = anthropic.Anthropic(api_key=api_key)
             response = client.messages.create(
-                model=model.value, max_tokens=max_tokens or 4096, messages=messages  # type: ignore
+                model=model.value,
+                max_tokens=max_tokens or 4096,
+                messages=messages,  # type: ignore
             )
             return response.content[0].text if response.content else """"
         elif provider == ""groq"":
@@ -508,7 +510,9 @@ def llm_call(
             return response.choices[0].message.content or """"
         elif provider == ""ollama"":
             response = ollama.chat(
-                model=model.value, messages=messages, stream=False  # type: ignore
+                model=model.value,
+                messages=messages,
+                stream=False,  # type: ignore
             )
             return response[""message""][""content""]
         else:

--- rnd/autogpt_server/autogpt_server/data/block.py ---
@@ -17,12 +17,14 @@
 
 
 class BlockCategory(Enum):
-    LLM = ""Block that leverages the Large Language Model to perform a task.""
+    AI = ""Block that leverages AI to perform a task.""
     SOCIAL = ""Block that interacts with social media platforms.""
     TEXT = ""Block that processes text data.""
     SEARCH = ""Block that searches or extracts information from the internet.""
     BASIC = ""Block that performs basic operations.""
-    INPUT_OUTPUT = ""Block that interacts with input/output of the graph.""
+    INPUT = ""Block that interacts with input of the graph.""
+    OUTPUT = ""Block that interacts with output of the graph.""
+    LOGIC = ""Programming logic to control the flow of your agent""
 
     def dict(self) -> dict[str, str]:
         return {""category"": self.name, ""description"": self.value}
@@ -113,7 +115,6 @@ class EmptySchema(BlockSchema):
 
 
 class Block(ABC, Generic[BlockSchemaInputType, BlockSchemaOutputType]):
-
     def __init__(
         self,
         id: str = """",",feat
"feat(rnd): Add k8s default health check (#8037)

add k8s default health check","--- rnd/market/market/app.py ---
@@ -87,5 +87,11 @@ def health():
         content=""<h1>Marketplace API</h1>"", status_code=200
     )
 
+@app.get(""/"")
+def default():
+    return fastapi.responses.HTMLResponse(
+        content=""<h1>Marketplace API</h1>"", status_code=200
+    )
+
 
 prometheus_fastapi_instrumentator.Instrumentator().instrument(app).expose(app)",feat
"fix(market): Handle empty agents response (#8393)

* Fix issue where marketplace breaks if no agents are returned

* Fix issue where marketplace breaks if no agents are returned

* Remove supabase folder from tracking

* adding supabase submodule

---------

Co-authored-by: Aarushi <50577581+aarushik93@users.noreply.github.com>","--- autogpt_platform/frontend/src/app/marketplace/page.tsx ---
@@ -118,7 +118,7 @@ const AgentCard: React.FC<{ agent: Agent; featured?: boolean }> = ({
           {agent.description}
         </p>
         <div className=""mb-2 text-xs text-gray-400"">
-          Categories: {agent.categories.join("", "")}
+          Categories: {agent.categories?.join("", "")}
         </div>
       </div>
       <div className=""flex items-end justify-between"">
@@ -315,14 +315,27 @@ const Marketplace: React.FC = () => {
           )
         ) : (
           <>
-            {featuredAgents.length > 0 && (
+            {featuredAgents?.length > 0 ? (
               <AgentGrid
                 agents={featuredAgents}
                 title=""Featured Agents""
                 featured={true}
               />
+            ) : (
+              <div className=""py-12 text-center"">
+                <p className=""text-gray-600"">No Featured Agents found</p>
+              </div>
+            )}
+
+            <hr />
+
+            {topAgents?.length > 0 ? (
+              <AgentGrid agents={topAgents} title=""Top Downloaded Agents"" />
+            ) : (
+              <div className=""py-12 text-center"">
+                <p className=""text-gray-600"">No Top Downloaded Agents found</p>
+              </div>
             )}
-            <AgentGrid agents={topAgents} title=""Top Downloaded Agents"" />
             <Pagination
               page={topAgentsPage}
               totalPages={topAgentsTotalPages}

--- autogpt_platform/market/.env.example ---
@@ -9,4 +9,4 @@ ENABLE_AUTH=true
 SUPABASE_JWT_SECRET=our-super-secret-jwt-token-with-at-least-32-characters-long
 BACKEND_CORS_ALLOW_ORIGINS=""http://localhost:3000,http://127.0.0.1:3000""
 
-APP_ENV=local
\ No newline at end of file
+APP_ENV=local",fix
chore(platform): Add missing mandatory environment variable (#8183),"--- autogpt_platform/backend/.env.example ---
@@ -18,9 +18,9 @@ SENTRY_DSN=
 
 ## User auth with Supabase is required for any of the 3rd party integrations with auth to work.
 ENABLE_AUTH=false
-SUPABASE_URL=
-SUPABASE_SERVICE_ROLE_KEY=
-SUPABASE_JWT_SECRET=
+SUPABASE_URL=http://localhost:8000
+SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJzZXJ2aWNlX3JvbGUiLAogICAgImlzcyI6ICJzdXBhYmFzZS1kZW1vIiwKICAgICJpYXQiOiAxNjQxNzY5MjAwLAogICAgImV4cCI6IDE3OTk1MzU2MDAKfQ.DaYlNEoUrrEn2Ig7tqibS-PHK5vgusbcbo7X36XVt4Q
+SUPABASE_JWT_SECRET=your-super-secret-jwt-token-with-at-least-32-characters-long
 
 # For local development, you may need to set FRONTEND_BASE_URL for the OAuth flow for integrations to work.
 # FRONTEND_BASE_URL=http://localhost:3000",chore
"fix(builder): Turn block border red on error (#7910)

* Turn block border red on error

* prettier","--- rnd/autogpt_builder/src/components/CustomNode.tsx ---
@@ -320,9 +320,60 @@ export function CustomNode({ data, id, width, height }: NodeProps<CustomNode>) {
     });
   }, [id, data, height, addNodes, deleteElements, getNode, getNextNodeId]);
 
+  const hasConfigErrors =
+    data.errors &&
+    Object.entries(data.errors).some(([_, value]) => value !== null);
+  const outputData = data.output_data;
+  const hasOutputError =
+    typeof outputData === ""object"" &&
+    outputData !== null &&
+    ""error"" in outputData;
+
+  useEffect(() => {
+    if (hasConfigErrors) {
+      const filteredErrors = Object.fromEntries(
+        Object.entries(data.errors || {}).filter(
+          ([_, value]) => value !== null,
+        ),
+      );
+      console.error(
+        ""Block configuration errors for"",
+        data.title,
+        "":"",
+        filteredErrors,
+      );
+    }
+    if (hasOutputError) {
+      console.error(
+        ""Block output contains error for"",
+        data.title,
+        "":"",
+        outputData.error,
+      );
+    }
+  }, [hasConfigErrors, hasOutputError, data.errors, outputData, data.title]);
+
+  const blockClasses = [
+    ""custom-node"",
+    ""dark-theme"",
+    ""rounded-xl"",
+    ""border"",
+    ""bg-white/[.9]"",
+    ""shadow-md"",
+  ]
+    .filter(Boolean)
+    .join("" "");
+
+  const errorClass =
+    hasConfigErrors || hasOutputError ? ""border-red-500 border-2"" : """";
+  const statusClass =
+    hasConfigErrors || hasOutputError
+      ? ""failed""
+      : (data.status?.toLowerCase() ?? """");
+
   return (
     <div
-      className={`custom-node dark-theme rounded-xl border bg-white/[.9] shadow-md ${data.status?.toLowerCase() ?? """"}`}
+      className={`${blockClasses} ${errorClass} ${statusClass}`}
       onMouseEnter={handleHovered}
       onMouseLeave={handleMouseLeave}
       data-id={`custom-node-${id}`}",fix
fix(rnd): Fix broken save feature on Agent Builder (#8052),"--- rnd/autogpt_builder/src/components/Flow.tsx ---
@@ -588,7 +588,9 @@ const FlowEditor: React.FC<{
             <SaveControl
               agentMeta={savedAgent}
               onSave={(isTemplate) => requestSave(isTemplate ?? false)}
+              agentDescription={agentDescription}
               onDescriptionChange={setAgentDescription}
+              agentName={agentName}
               onNameChange={setAgentName}
             />
           </ControlPanel>

--- rnd/autogpt_builder/src/components/edit/control/SaveControl.tsx ---
@@ -18,6 +18,8 @@ import {
 
 interface SaveControlProps {
   agentMeta: GraphMeta | null;
+  agentName: string;
+  agentDescription: string;
   onSave: (isTemplate: boolean | undefined) => void;
   onNameChange: (name: string) => void;
   onDescriptionChange: (description: string) => void;
@@ -35,7 +37,9 @@ interface SaveControlProps {
 export const SaveControl = ({
   agentMeta,
   onSave,
+  agentName,
   onNameChange,
+  agentDescription,
   onDescriptionChange,
 }: SaveControlProps) => {
   /**
@@ -75,17 +79,29 @@ export const SaveControl = ({
                 id=""name""
                 placeholder=""Enter your agent name""
                 className=""col-span-3""
-                defaultValue={agentMeta?.name || """"}
+                value={agentName}
                 onChange={(e) => onNameChange(e.target.value)}
               />
               <Label htmlFor=""description"">Description</Label>
               <Input
                 id=""description""
                 placeholder=""Your agent description""
                 className=""col-span-3""
-                defaultValue={agentMeta?.description || """"}
+                value={agentDescription}
                 onChange={(e) => onDescriptionChange(e.target.value)}
               />
+              {agentMeta?.version && (
+                <>
+                  <Label htmlFor=""version"">Version</Label>
+                  <Input
+                    id=""version""
+                    placeholder=""Version""
+                    className=""col-span-3""
+                    value={agentMeta?.version || ""-""}
+                    disabled
+                  />
+                </>
+              )}
             </div>
           </CardContent>
           <CardFooter className=""flex flex-col items-stretch gap-2"">

--- rnd/autogpt_builder/src/hooks/useAgentGraph.ts ---
@@ -16,6 +16,7 @@ import {
 import { Connection, MarkerType } from ""@xyflow/react"";
 import Ajv from ""ajv"";
 import { useCallback, useEffect, useMemo, useRef, useState } from ""react"";
+import { useRouter, useSearchParams, usePathname } from ""next/navigation"";
 
 const ajv = new Ajv({ strict: false, allErrors: true });
 
@@ -24,6 +25,11 @@ export default function useAgentGraph(
   template?: boolean,
   passDataToBeads?: boolean,
 ) {
+  const [router, searchParams, pathname] = [
+    useRouter(),
+    useSearchParams(),
+    usePathname(),
+  ];
   const [savedAgent, setSavedAgent] = useState<Graph | null>(null);
   const [agentDescription, setAgentDescription] = useState<string>("""");
   const [agentName, setAgentName] = useState<string>("""");
@@ -307,7 +313,7 @@ export default function useAgentGraph(
 
     (template ? api.getTemplate(flowID) : api.getGraph(flowID)).then(
       (graph) => {
-        console.log(""Loading graph"");
+        console.debug(""Loading graph"");
         loadGraph(graph);
       },
     );
@@ -608,7 +614,7 @@ export default function useAgentGraph(
           }));
 
         return {
-          id: node.id,
+          id: node.data.backend_id,
           block_id: node.data.block_id,
           input_default: inputDefault,
           input_nodes: inputNodes,
@@ -637,11 +643,8 @@ export default function useAgentGraph(
         nodes: formattedNodes,
         links: links,
       };
-
-      if (savedAgent && deepEquals(payload, savedAgent)) {
-        console.debug(
-          ""No need to save: Graph is the same as version on server"",
-        );
+      if (savedAgent && deepEquals(payload, savedAgent, true)) {
+        console.warn(""No need to save: Graph is the same as version on server"");
         // Trigger state change
         setSavedAgent(savedAgent);
         return;
@@ -664,6 +667,13 @@ export default function useAgentGraph(
             : api.createGraph(payload));
       console.debug(""Response from the API:"", newSavedAgent);
 
+      // Route the URL to the new flow ID if it's a new agent.
+      if (!savedAgent) {
+        const path = new URLSearchParams(searchParams);
+        path.set(""flowID"", newSavedAgent.id);
+        router.replace(`${pathname}?${path.toString()}`);
+      }
+
       // Update the node IDs on the frontend
       setSavedAgent(newSavedAgent);
       setNodes((prev) => {

--- rnd/autogpt_builder/src/lib/utils.ts ---
@@ -20,19 +20,23 @@ export function hashString(str: string): number {
 }
 
 /** Derived from https://stackoverflow.com/a/32922084 */
-export function deepEquals(x: any, y: any): boolean {
+export function deepEquals(x: any, y: any, allowMissingKeys = false): boolean {
   const ok = Object.keys,
     tx = typeof x,
     ty = typeof y;
-  return (
+
+  const sk = (a: object, b: object) => ok(a).filter((k) => k in b);
+  const skipLengthCheck = allowMissingKeys && !Array.isArray(x);
+
+  const res =
     x &&
     y &&
     tx === ty &&
     (tx === ""object""
-      ? ok(x).length === ok(y).length &&
-        ok(x).every((key) => deepEquals(x[key], y[key]))
-      : x === y)
-  );
+      ? (skipLengthCheck || ok(x).length === ok(y).length) &&
+        sk(x, y).every((key) => deepEquals(x[key], y[key], allowMissingKeys))
+      : x === y);
+  return res;
 }
 
 /** Get tailwind text color class from type name */",fix
"chore(platform/frontend): Add behave as var (#8365)

add behave as variable","--- autogpt_platform/infra/helm/autogpt-builder/values.dev.yaml ---
@@ -66,4 +66,5 @@ env:
   SENTRY_AUTH_TOKEN: """"
   NEXT_PUBLIC_AUTH_CALLBACK_URL: ""https://dev-server.agpt.co/auth/callback""
   NEXT_PUBLIC_AGPT_WS_SERVER_URL: ""wss://dev-ws-server.agpt.co/ws""
-  NEXT_PUBLIC_AGPT_MARKETPLACE_URL: ""https://dev-market.agpt.co/api/v1/market""
\ No newline at end of file
+  NEXT_PUBLIC_AGPT_MARKETPLACE_URL: ""https://dev-market.agpt.co/api/v1/market""
+  NEXT_PUBLIC_BEHAVE_AS: ""CLOUD""
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-builder/values.prod.yaml ---
@@ -85,4 +85,5 @@ env:
   NEXT_PUBLIC_SUPABASE_URL: ""https://bgwpwdsxblryihinutbx.supabase.co""
   GOOGLE_CLIENT_ID: """"
   GOOGLE_CLIENT_SECRET: """"
-  SENTRY_AUTH_TOKEN: """"
\ No newline at end of file
+  SENTRY_AUTH_TOKEN: """"
+  NEXT_PUBLIC_BEHAVE_AS: ""CLOUD""
\ No newline at end of file",chore
fix(backend): Avoid falling back to default user unless ENABLED_AUTH is set to False (#8691),"--- autogpt_platform/autogpt_libs/autogpt_libs/auth/depends.py ---
@@ -1,7 +1,8 @@
 import fastapi
 
 from .middleware import auth_middleware
-from .models import User
+from .models import User, DEFAULT_USER_ID, DEFAULT_EMAIL
+from .config import Settings
 
 
 def requires_user(payload: dict = fastapi.Depends(auth_middleware)) -> User:
@@ -16,8 +17,12 @@ def requires_admin_user(
 
 def verify_user(payload: dict | None, admin_only: bool) -> User:
     if not payload:
+        if Settings.ENABLE_AUTH:
+            raise fastapi.HTTPException(
+                status_code=401, detail=""Authorization header is missing""
+            )
         # This handles the case when authentication is disabled
-        payload = {""sub"": ""3e53486c-cf57-477e-ba2a-cb02dc828e1a"", ""role"": ""admin""}
+        payload = {""sub"": DEFAULT_USER_ID, ""role"": ""admin""}
 
     user_id = payload.get(""sub"")
 

--- autogpt_platform/autogpt_libs/autogpt_libs/auth/models.py ---
@@ -1,5 +1,8 @@
 from dataclasses import dataclass
 
+DEFAULT_USER_ID = ""3e53486c-cf57-477e-ba2a-cb02dc828e1a""
+DEFAULT_EMAIL = ""default@example.com""
+
 
 # Using dataclass here to avoid adding dependency on pydantic
 @dataclass(frozen=True)

--- autogpt_platform/backend/backend/data/user.py ---
@@ -1,6 +1,7 @@
 import logging
 from typing import Optional, cast
 
+from autogpt_libs.auth.models import DEFAULT_USER_ID
 from autogpt_libs.supabase_integration_credentials_store.types import (
     UserIntegrations,
     UserMetadata,
@@ -15,9 +16,6 @@
 
 logger = logging.getLogger(__name__)
 
-DEFAULT_USER_ID = ""3e53486c-cf57-477e-ba2a-cb02dc828e1a""
-DEFAULT_EMAIL = ""default@example.com""
-
 
 async def get_or_create_user(user_data: dict) -> User:
     user_id = user_data.get(""sub"")

--- autogpt_platform/backend/backend/server/utils.py ---
@@ -1,18 +1,11 @@
-from autogpt_libs.auth.middleware import auth_middleware
-from fastapi import Depends, HTTPException
+from autogpt_libs.auth.depends import requires_user
+from autogpt_libs.auth.models import User
+from fastapi import Depends
 
-from backend.data.user import DEFAULT_USER_ID
 from backend.util.settings import Settings
 
 settings = Settings()
 
 
-def get_user_id(payload: dict = Depends(auth_middleware)) -> str:
-    if not payload:
-        # This handles the case when authentication is disabled
-        return DEFAULT_USER_ID
-
-    user_id = payload.get(""sub"")
-    if not user_id:
-        raise HTTPException(status_code=401, detail=""User ID not found in token"")
-    return user_id
+def get_user_id(user: User = Depends(requires_user)) -> str:
+    return user.user_id

--- autogpt_platform/backend/backend/server/ws_api.py ---
@@ -53,24 +53,24 @@ async def event_broadcaster(manager: ConnectionManager):
 
 
 async def authenticate_websocket(websocket: WebSocket) -> str:
-    if settings.config.enable_auth:
-        token = websocket.query_params.get(""token"")
-        if not token:
-            await websocket.close(code=4001, reason=""Missing authentication token"")
-            return """"
+    if not settings.config.enable_auth:
+        return DEFAULT_USER_ID
+
+    token = websocket.query_params.get(""token"")
+    if not token:
+        await websocket.close(code=4001, reason=""Missing authentication token"")
+        return """"
 
-        try:
-            payload = parse_jwt_token(token)
-            user_id = payload.get(""sub"")
-            if not user_id:
-                await websocket.close(code=4002, reason=""Invalid token"")
-                return """"
-            return user_id
-        except ValueError:
-            await websocket.close(code=4003, reason=""Invalid token"")
+    try:
+        payload = parse_jwt_token(token)
+        user_id = payload.get(""sub"")
+        if not user_id:
+            await websocket.close(code=4002, reason=""Invalid token"")
             return """"
-    else:
-        return DEFAULT_USER_ID
+        return user_id
+    except ValueError:
+        await websocket.close(code=4003, reason=""Invalid token"")
+        return """"
 
 
 async def handle_subscribe(",fix
"feat(blocks): Add text decoder block (#8248)

* Refactor search.py: Add option for raw content scraping in ExtractWebsiteContentBlock

* Add TextDecoderBlock for decoding escape sequences in text","--- autogpt_platform/backend/backend/blocks/decoder_block.py ---
@@ -0,0 +1,42 @@
+import codecs
+
+from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema
+from backend.data.model import SchemaField
+
+
+class TextDecoderBlock(Block):
+    class Input(BlockSchema):
+        text: str = SchemaField(
+            description=""A string containing escaped characters to be decoded"",
+            placeholder='Your entire text block with \\n and \\"" escaped characters',
+        )
+
+    class Output(BlockSchema):
+        decoded_text: str = SchemaField(
+            description=""The decoded text with escape sequences processed""
+        )
+
+    def __init__(self):
+        super().__init__(
+            id=""2570e8fe-8447-43ed-84c7-70d657923231"",
+            description=""Decodes a string containing escape sequences into actual text"",
+            categories={BlockCategory.TEXT},
+            input_schema=TextDecoderBlock.Input,
+            output_schema=TextDecoderBlock.Output,
+            test_input={""text"": """"""Hello\nWorld!\nThis is a \""quoted\"" string.""""""},
+            test_output=[
+                (
+                    ""decoded_text"",
+                    """"""Hello
+World!
+This is a ""quoted"" string."""""",
+                )
+            ],
+        )
+
+    def run(self, input_data: Input, **kwargs) -> BlockOutput:
+        try:
+            decoded_text = codecs.decode(input_data.text, ""unicode_escape"")
+            yield ""decoded_text"", decoded_text
+        except Exception as e:
+            yield ""error"", f""Error decoding text: {str(e)}""",feat
"build(deps): bump actions/setup-python from 4 to 5 (#8438)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- .github/workflows/platform-autgpt-deploy-prod.yml ---
@@ -25,7 +25,7 @@ jobs:
         uses: actions/checkout@v2
 
       - name: Set up Python
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: '3.11'
 

--- .github/workflows/platform-autogpt-deploy.yaml ---
@@ -29,7 +29,7 @@ jobs:
         uses: actions/checkout@v2
 
       - name: Set up Python
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: '3.11'",build
"chore(infra): Update variable names (#8447)

update variable names","--- autogpt_platform/infra/terraform/environments/prod.tfvars ---
@@ -29,10 +29,9 @@ service_accounts = {
     display_name = ""AutoGPT prod Market backend Account""
     description  = ""Service account for agpt prod market backend""
   },
-  ""prod-github-actions-workload-identity"" = {
-    service_account_name = ""prod-github-actions-sa""
-    namespace            = ""prod-agpt""
-    ksa_name             = ""prod-github-actions-sa""
+  ""prod-github-actions-sa"" = {
+    display_name = ""GitHub Actions Prod Service Account""
+    description  = ""Service account for GitHub Actions deployments to prod""
   }
 }
 
@@ -108,7 +107,7 @@ role_bindings = {
     ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
   ],
   ""roles/iam.serviceAccountTokenCreator"" = [
-    ""principalSet://iam.googleapis.com/projects/638488734936/locations/global/workloadIdentityPools/prod-pool/*"",
+    ""principalSet://iam.googleapis.com/projects/1021527134101/locations/global/workloadIdentityPools/prod-pool/*"",
     ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
   ]
 }
@@ -121,7 +120,7 @@ standard_bucket_names = []
 bucket_admins = [""gcp-devops-agpt@agpt.co"", ""gcp-developers@agpt.co""]
 
 workload_identity_pools = {
-  ""dev-pool"" = {
+  ""prod-pool"" = {
     display_name = ""Production Identity Pool""
     providers = {
       ""github"" = {",chore
"feat(secrets): Rotate secrets (#8505)

* reseal secrets

* update DB url

* rotate prod db

* rotate prod

* rotate server

* builder valuse

* public env vars in env files

* public env vars in env files","--- autogpt_platform/frontend/.env.development ---
@@ -0,0 +1,7 @@
+NEXT_PUBLIC_AUTH_CALLBACK_URL=https://dev-server.agpt.co/auth/callback
+NEXT_PUBLIC_AGPT_SERVER_URL=https://dev-server.agpt.co/api
+NEXT_PUBLIC_AGPT_WS_SERVER_URL=wss://dev-ws-server.agpt.co/ws
+NEXT_PUBLIC_AGPT_MARKETPLACE_URL=https://dev-market.agpt.co/api/v1/market
+NEXT_PUBLIC_SUPABASE_ANON_KEY=""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImFkZmp0ZXh0a3VpbHd1aHpkanBmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzAyNTE3MDIsImV4cCI6MjA0NTgyNzcwMn0.IuQNXsHEKJNxtS9nyFeqO0BGMYN8sPiObQhuJLSK9xk""
+NEXT_PUBLIC_SUPABASE_URL=""https://adfjtextkuilwuhzdjpf.supabase.co""
+NEXT_PUBLIC_BEHAVE_AS=CLOUD
\ No newline at end of file

--- autogpt_platform/frontend/.env.production ---
@@ -0,0 +1,8 @@
+APP_ENV=production
+NEXT_PUBLIC_AGPT_MARKETPLACE_URL=https://market.agpt.co/api/v1/market
+NEXT_PUBLIC_AGPT_SERVER_URL=https://backend.agpt.co/api
+NEXT_PUBLIC_AGPT_WS_SERVER_URL=wss://ws-backend.agpt.co/ws
+NEXT_PUBLIC_AUTH_CALLBACK_URL=https://backend.agpt.co/auth/callback
+NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImJnd3B3ZHN4YmxyeWloaW51dGJ4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzAyODYzMDUsImV4cCI6MjA0NTg2MjMwNX0.ISa2IofTdQIJmmX5JwKGGNajqjsD8bjaGBzK90SubE0
+NEXT_PUBLIC_SUPABASE_URL=https://bgwpwdsxblryihinutbx.supabase.co
+NEXT_PUBLIC_BEHAVE_AS=CLOUD
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-builder/values.dev.yaml ---
@@ -58,13 +58,7 @@ wwwDomain: ""www.dev-builder.agpt.co""
 
 env:
   APP_ENV: ""dev""
-  NEXT_PUBLIC_AGPT_SERVER_URL: ""https://dev-server.agpt.co/api""
+
+secrets:
   GOOGLE_CLIENT_ID: """"
   GOOGLE_CLIENT_SECRET: """"
-  NEXT_PUBLIC_SUPABASE_URL: ""https://adfjtextkuilwuhzdjpf.supabase.co""
-  NEXT_PUBLIC_SUPABASE_ANON_KEY: """"
-  SENTRY_AUTH_TOKEN: """"
-  NEXT_PUBLIC_AUTH_CALLBACK_URL: ""https://dev-server.agpt.co/auth/callback""
-  NEXT_PUBLIC_AGPT_WS_SERVER_URL: ""wss://dev-ws-server.agpt.co/ws""
-  NEXT_PUBLIC_AGPT_MARKETPLACE_URL: ""https://dev-market.agpt.co/api/v1/market""
-  NEXT_PUBLIC_BEHAVE_AS: ""CLOUD""
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-builder/values.prod.yaml ---
@@ -77,13 +77,7 @@ volumeMounts:
 
 env:
   APP_ENV: ""prod""
-  NEXT_PUBLIC_AUTH_CALLBACK_URL: ""https://backend.agpt.co/auth/callback""
-  NEXT_PUBLIC_AGPT_SERVER_URL: ""https://backend.agpt.co/api""
-  NEXT_PUBLIC_AGPT_WS_SERVER_URL: ""wss://ws-backend.agpt.co/ws""
-  NEXT_PUBLIC_AGPT_MARKETPLACE_URL: ""https://market.agpt.co/api/v1/market""
-  NEXT_PUBLIC_SUPABASE_ANON_KEY: """"
-  NEXT_PUBLIC_SUPABASE_URL: ""https://bgwpwdsxblryihinutbx.supabase.co""
+
+secrets:
   GOOGLE_CLIENT_ID: """"
-  GOOGLE_CLIENT_SECRET: """"
-  SENTRY_AUTH_TOKEN: """"
-  NEXT_PUBLIC_BEHAVE_AS: ""CLOUD""
\ No newline at end of file
+  GOOGLE_CLIENT_SECRET: """"
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-market/values.dev.yaml ---
@@ -94,7 +94,7 @@ env:
 
 
 secrets:
-  SUPABASE_JWT_SECRET: ""AgBL6H6byPKXVN0nYWgqyoZBHJJJqk8S3rNYSu3JvwOsNn3Sw94SrJcXuE48fxcojcbKvYcDshetFhrSNEsfUwvbSFoaIj+MItPIZ8FGHyfXnmeZJ5j/sdvcjaMmWS7CiL2jhzI+nc8rL2ATV2TgA7E6FA9MvhWqkAyZu04pCd1c9DsAlpcfQ3pxywXjOV+BU0+1+++Z+fTnaugt+hRbhHrKTddaPhi72KrIyJPOUlqfht0JcgflT1f5frvmNnDwkiP862knhJsqg7XyrSy4msCN7eH4BvV01pO3KhAEnMG4Lk/5FeE/2t05+HqgB4mvPbkqfY6g8Lvf6qmd5g+stB10wRmr+TxzokOom36r7sYd3tyXZMgemJOi3BZjYk7774zf/TI081pJx1FPvM6dDPQdrgnU1nhshq/gLyKB5tTTCkPQHW+YhUtApWgrC5mq8ezMqfuwrUuR+NvyO59K56ERJJFAw1fDKHIVl4TYmftet42lkVOchml30cje9gjBtpOrTkFf8lMv5DLQ/ygdwsAYmVrpYtXbT+GAaRI9QIv/rZVuckfz4uIhTp7IjAtRXJreMH2V8GZ22h6Of/BQG+XA42lMA2huIyLwsqmtL0qxNmIu5EGjcXBvlOt5eNquzts68jgNqEfE6fEuqS9lDepvtTSxGp7wmcmWwOBbIgbCnxl8t4IW/e1qvOPuvxMldH+YtVIvfHMf3DnvbehhCIYuLmRM+E6139/qdGKreRyCi4PA4PKTMEG962rSu/7z0X5wu+UYY+kESrs7HhksL3PhB3dpbZ0HF+b6lchziTI0atG+UNX05ysL""
-  DATABASE_URL: ""AgACJkybaNon1X7ZkvtyM0mJ3Gfbjh1LWSJdWGC3ny6QU/8yERomTjvDylHuFoaoGeEs5ewYtgH87G/t1q3LF35cjmipGTSJbxFKfyoRcGBZSajen2Ijs+satVD7T6bmCNsurEsUD16QDLoV5lx+THXdEjv4VrBtFwY0HO2BIP15X/vMie9Mk91Uk1eze5dj8WoQ5OywH8O8Ugh7/iOleEyiPaMzxdRAfwvYHgX5QYqDno0ktZFyKnDOpCnegIwcUei4tt+EiTAG1SxESk48DQQokNrZc+lqlPwozX6FOYkgcQiZZqIN+9qOy5hB+1wKggS8zcd7/YAlSpSd8LMeAokflxOabN5Ctyvx3k5tGgstKQabW1TErwL8RjB3WYClLvJl8bfc4qILr4jpfA4all59f8oinATiyeqJ3Hx267FdHH2aywnXnNdEmycGhKkuH0vAa74oYsUiD9BrjkxmMdxCwmEjl47ob5fwcraKOc7hNF+hPi2C61/z1T6yoIeu4ediMTk0m1ZPIOotlbj/nKkmrKDfD+WMia/YvBpUtlM/SaEyX66gmO03kxW92cmXVCjK65oGh0ueCyK84J9e/2y+qO6yFXh7991+wTQyAedBBoc2myNcebKzuAmFNwanCs+FMOktPZsMMzfFy3oHJQxgFkPEp+jKennODqTe0A3LBhJC3ddwCYgd1TAABC2+DqFGaCRiyaSZ4BZIitEPFzpJwITIFZoRyxrCibrGKKnILVjGNaiV/KdIzfj70AAdzG/7GFdA9SKzRQimnVw99YTjNouCYzt7iLBV/8KrcMvyyeHZle1A6zg0gjjj4Yp6p0ssIOvhuDLjec4NMi/E5EbgYzKQFr7jN2u9""
+  SUPABASE_JWT_SECRET: ""AgCXWGuGOPbdUZsn1G+amfHxm1CZAmuiULAml7sDJ+SUXUBlBWOf/wb0Gf9vnjPrpS5QqeYUQDzVPIXRqs1BkL7m51zAYt4U5K1XGgF4VmUv5Jqm/99iLB/biuVBuGj32wuYzGNEfuPPz6sfg51AfPfuOCDE/bX9xD+M5E++wVQChulm0Lqab5GdBgZC2M90Cb57EjNbwkCnNhO1HY2etwMKJ5q4J6N8gW1nxdWemUFEtQuHRBwEhCA+XRVf4MHQPwixb0Kn7cA+D6OthxWaxsXgg0li/kY7tF4xed2XXkfhARFbATryExcnAXLOucWS1+NKjLSUCZdqeqR/+C6uKyAYQNj60WU9ikDG5LJrLgnB2dXVBDNFHWbVtWtHABdyIVENZlXCBYtIJUpDBVFVIZp/GOyR9mhwPil0qZOiLE6HXiRENyMcZxNk1E9BHQZHS6WKExsi7RP3kJVFcWknBvH8IydkoINRfGO+LNy+H8EK51ml60iq6pvNVRwcxfZBuNcdJQrWflsLbi2dT6u9tWM27COnV2UCWqJuslVhdEAdpeB/nErgnBcSWXl4vtApasxYw7l5QWTU2597TvMidqm9ardvFOiuj9SxRdLZ/H3x3rsn8yn3C22E8Ism4ciEA9wxjwL3pgWiSsRsIsTpI0++lHSSY7hZvsarwFWcgwzjZhufqjVTbRJiHGOeXijiAqj+b5haCkdYmJCFeJuph11GABtORqnVh2xkPfzB3iWpfshX+udtjr7vdJCcpQyRbq972I8sTqFJXQc5hXQYu8/JWApKnpYMFq7MtrCKGurYxLPx7pYaf1sA""
+  DATABASE_URL: ""AgB2qSmnSLX5mVx+kIhbD2Mb8mKFHSyTD/DlhaNLo00tl+O4ix155S8Ec9voSFwuDhsjuQC9vND9cNSDIMUakjKIu4SmKfyi1zq2dHkToq0N5jxOO04N9XbZtXRIUaw6/ME8NGodw0hF4kPMaKBcC3Vt4dvnZw4YOnk2l39W5Cf3GR2Jm5V2s4g90HLy+JexQjxf5YiPQdDUQPu2bRxJ+ELuaEH113QrbLJVQZtd18+0p+89pBP9Rw98YqO+Lbf8u2MPGXOYQpjpT+bIIQE3c42Wd7lpHd+S8YBfHOjJKipLK2L1JsN30nte+xHEC3Vk1re9T3Qa7Nmb4fuwnJXcXBxwyaOucsPS9o/beNGYZtvpR3e9TedcjxCe4DQpJiMmkhK3Z8eVYmxNUviccN21mf2yMsZ/9KNuULnlz+EFVW1vwmnuGRD4yHUK4HKmGyrKEdmnEOMv1W2yoRbyy9kjj3lTSO4jKDxAgs+9zkVUD1cIL/bFjJZVqOnXZs5I6gJWM5dGtLTqZe8IyxbKj9fORHLzl0kZqjfjiIVvJkLpV/okjaITVueuGljROt89ZDSVKCcHDiMMXF4qZwLNGIPoRT4O8b3BIBiRm2fnJu5ui3xbTfQWH1/OagWhgiBkvcKJ4IoZuxdlQnBjCOSig4BMUopjAQ49YaPX78qDBFTDSkk5ofogs1nKHRo41EmdR8Kl7JI=""
   SENTRY_DSN: ""AgB9i02k9BgaIXF0p9Qyyeo0PRa9bd3UiPBWQ3V4Jn19Vy5XAzKfYvqP8t+vafN2ffY+wCk1FlhYzdIuFjh3oRvdKvtwGEBZk6nLFiUrw/GSum0ueR2OzEy+AwGFXA9FstD0KCMJvyehSv9xRm9kqLOC4Xb/5lOWwTNF3AKqkEMEeKrOWx4OLXG6MLdR7OicY45BCE5WvcV2PizDaN5w3J72eUxFP0HjXit/aW/gK32IJME0RxeuQZ5TnPKTNrooYPR0eWXd2PgYshFjQ2ARy/OsvOrD10y8tQ3M5qx/HNWLC/r0lEu2np+9iUIAE1ufSwjmNSyi4V8usdZWq7xnf3vuKlSgmveqKkLbwQUWj1BpLNIjUvyY+1Rk1rxup/WCgaw+xOZd6sR/qTIjILv5GuzpU0AiwEm7sgl2pmpFXq6n6QjNOfZoPBTL73f4bpXNJ3EyMYDbPxOtGDz91B+bDtOsMr1DNWQslKkk3EIilm/l0+NuLKxf/e2HwM3sB15mkQqVZBdbiVOr7B27cR9xAnr296KE/BU6E9dp/fl+IgcaonMpTsE61pCLHWxQXNBO5X078/zhmaXBQyEBNQ5SPDr9u3pHWrrLkBtXwldZvgmLMMVFMAzrVVkJB4lC9sZj0pXPhda0/BsA4xcGRELj/PizwSr+kb3lDumNMqzEap5ZjEGCBpeeIVSo19v+RoEDw0AFmyxfYx2+91HsgiEqjEUg+J6yDmjAoRpOD1wRZOnnpR8ufMiqdBteCG8B5SXkhgto1WtDyOMVlX2wbmBFVetv2nAbMIA/l4E/Yv8HXiJsTqAkeYc5Qak6/SMGnZTw7Q==""
-  SUPABASE_SERVICE_ROLE_KEY: ""AgCrHCd2AdIv++sX7AAf0YoV+qDFhPuErd/Q9Jgj8/1wDJklqv0giI/M7TRUV6j2Gqa/yLP90Hoiy2BboE0V3FrTtHzasxtSK0hd93+bxvZ34FEfKQyAiddBR8OxzlPwaplzaJ+/Tu+yHf1EesgXrUdydk38D4AQqkrC30FRKJcCxJNTHHzsZiHGQLZNP2l0cEsmqtMXMk8TqbcqHvJZRpr8jP1dSJ7bxEdU9mH/zB4HV+EsPLDFWFAnFjbEQwv8FEGgqpy81ifch4Hz7S0wjwk0x/QsagKavBTvI579K6Sx7uJyMyilpzm5Ct8kDXTEGUWv7pFINXM5cAbcBNzuvwvtXmshMwRsl9e/5Y2/T2VgS7/wPTJA4AmyyrSK976SOjo7imb4XfMwc6Cc/2GE0BRW9jiKvzjQ1TC2ovQpNujTYYgPzIq8sFXEVss31DIcfwbRAzgKTTQZKl+H+i9AS0q6iYHtKORwTQ2bv2XwQwxogXMHTUq1oC3MkzjKfV9DcoTHU2o/+gTyOBW5i3BRatuublA1x0EwDoEVmWA1+i1h2bpkl4QYuyeNlhJnRHzuQU3RdFLWn3MkDM8Q4Y9n0/XXwwTCgqtdAExqNh3YJYumWiGiWfdBpEUqlUtOUurNMXy6rHH4odnNKeLQfMOa9406x5H5xiwNkl3mzGjNiPDMS7JMTptlsoL8DshE2TM0PqZVrQy81OsGNpdiU8MVeUdHO6/bDBe7j9v0FipqpeehX1AZEYb/4CWosTJACWpaTnLYRh+w12bk3x6Sj0kriDKMOuJLBRh1fveZXUC9C0FsEPhq2rBLQDVh78DkBIeKVGUzuxDP/6mT3OSBPe4aCye0vTmwtEOEvB+A7rcMkOl+j90bKAveE9H+f7UVU6Og40Nc3sSuMolKHbQyB9TNd4+jOfmySSN675riL6BpFFCSuWqjrqWFr0yI1h/xAg+YMg8WzWarwSeWr3ykXrbhQvu7Oj27ffLXEIvS0gU=""
\ No newline at end of file
+  SUPABASE_SERVICE_ROLE_KEY: ""AgBKJDPEiTQUYLY0B/NKaAkxH7whrGuxQVtRdz9mEr/Bx06n1Yu1Zm4/oEQp3OvYerRvQWuv1k3//jf3eiya4ZW9+ZntfPdQWL9/tzq+/spevFtiEvuQ8uuUhtNOU4IGt27KTTlhCfeHKte8jtLQ/lwcrSrfPZ1T8Gy8PXdsAgakGUauEs2oHuX2XUaPE9UFF4HRAhmjPZ9e7u7Zfgcj8D+otjrwNVC5ZXFM7/ha0roeZHdpTvOcemKjxhiZA0FmdkXgOCPihNxlz0sKcupCEte6ocnSkpL3pBflBsa9+NLz7kLCUQPeOCExkMTndyqWk1kFci6j35cBP6PQlHfWPdo8OFCdG+3EfvEt5+4PQ08d7nXRZqowBiQdE2/e8qA/dZc8cJ7ecpza+9Qf/pNIl+9Ix0EFvmB6rpbO9w5Ptw2yMOAebVl7qV+A65GelvcPWROK5Vfftwx8KT2sn9ldVOYy+C7OafgOm8qaL7mEMePSwJy68MKpnMm/TceE7xxZ2sMSWEl9FMn4QXEawD4LQrJHKpum6XyUG2FlMkogHMikOEbJzz1ICAcHB6OWJXo3wU+fK8jkI4/UYioFSfF9MQXaC8bUGc4NT6T62KvjnrdkmOHG7HcN4UNQ7yBa/fP1pM7peYQdwAKr4Oxl4v3i96uKRdCuIimYiWpcxklkQhmSsMLKFMZGDDvv1BNtL6oxK4ZaEyWoorEyjkd2UrSpbP6cvyVMVWbTl1/BD350NRn6OYTpGIXwmAhqVWuuyt8kfLLU6Ot2MYcq/i16qvc3dA5XizLKHY95X8R+DlUCEzawF75Sx++eMPKU/o5rxhZNRjvffIcXtw1Hy/uqVCqilmSt33RqUsehOxQUqHBIW7L7sAik/L+hgTiE3MwN8XSfGncDB/bNweJh3ZSXsdwZD2bleEY1nWpsXVhcJDNcdW3YscJbsyTCGQcOb0zEQaxSmfLAd3rIa+SAZpFEOsD8A5kZjI4QpmqPkhNHeF8=""
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-market/values.prod.yaml ---
@@ -93,7 +93,7 @@ env:
   BACKEND_CORS_ALLOW_ORIGINS: ""https://platform.agpt.co""
 
 secrets:
-  DATABASE_URL: ""AgCe47Y6QFnZRmNNpc3iVIcJ9zAZMPr/1OU61Slr0oM1yjneT7LgNTrAD9+QSu7Q0q2u+533FImOu8o/pKG0gNzEtyeSEEsegmCiaxs4Wi+/jVodU8CgfrYN3xkgi7QuD2fMs/zz+sv25LDg8LR1mIvkv+W/PkbqoVx3UAUXL7ZM+UvkFqie+69C/kwoH51xPaYi+FajSzql+VdhDc28aFkwrDApenyLbyKAHSnplWqpFDVtcQK4dL7K9EhRkUnWORNHiYT+N0Ras5tw1ief481nDud29nhlQ+5HIHGK5QouKmA1yJIJqavbzsDf7n+nWCwULIWXGi5d8A23e8vZAuF2CInUHAmP8d+xBDRx8aATZigoOM0GpHn5ljxNs0TCZ1HvQ8TjzQOpcgmBZ9l5Eod3y/PRhjGBRrcR550PAxpkjRj9VjfMN5NSiHVsGw7xKQr2+4yghv3VgSZFvOg1qUxmleJ9khwZq2Gel0uvhGStYw50x/C+EDMaJNQUaBDDbo5Bjy6/RNAEgrX0snQAZWCZSg4bsb4+2jRvo50W1wMr9076qOFViNn2YM+exIGXdmgggAKk7foZDZz1KgG+dAhKBXoUhXwHO9P450gq4xxDGSk0ZCe10OiszNkXVtmmE+Ryi5JjnbDsxLJP1tynrljFUb29VePt0zwZAhdnz0MQU1T9IVbjcKYB92h19lhcdgE=""
-  SUPABASE_JWT_SECRET: ""AgDCNoyGjkV74NoJTSN+VDpiIl8B7sRzDK3WFAO2wBWdhFSwnO2x4cZ7F9YxiEQgvjslCEn5wCrgqBiO6L3EP4qd0EUibZrx+6xXIK5tRY3YACXf1pQEgRTl5fXTbdlRJgr0+2upe1bB30LecbM/G+goX+RprKmwSxNJfBo/AQQP1l1dJsl4v/yGbEj8WQFD7jTiyCGT8skIX07GUvzZVbAD+DaNmvucuENja90O7q3ACOIJ9VWX9rTJX1V5brrb7y4ge8Iv97bUisH/MtFtZMEBEK1csixdBUC47wtboxn3LnMUaE2OlJZD+9IzEf6TqTJGREyOd+h2V/8BmUYnKRZUVWPURsWLinfbDpyXPmGSBgnfYCd5ZKS5dvwvQwiR6ODlO9E2WOe4xoAHSq57uUxLopcrDsVzZcLiahA02613vYafwc9svg/8dJV2FokKrnQs/bRHlVCa51Vs8z/zCBnHzS6RBq2p2vMU/PbzMfMR2DjzQcvE6hOnyLMlOMpYe67FaHC2cZTayUqNzi5hDNUp19grEqwjdvannOenn/ewTX4yCOVaOoAQ+QBrv1o4g46E18wFnDMoYH+b7PJ0mUf3NSV0jXH+elbW5H6c5WdnmKT+nWQhaVTD4pMAlY8z2W6LddpA7XHfj/lAzboSj+VJqwCrx8AVMKJ4LTbYGTdu9RkcNZLVHkrtafEAYZNnYrIwNZT3SuLWO8X/dGKrrZmOoaaQJZkBuRy1bLdOGXKUIBvf+MDvmApjp/+ScDxl11KifiEO3tO65hNVa2YPjkIf36fJpJ6vtDchsmyowJ9cRhduZsu4PO4D""
+  DATABASE_URL: ""AgB3onbSwBZQZxQPDejZr+tkrkj7cDwBGOjKsVSWmnvX9S665u7857SbfXDOLF+24f/mrujyaD0598Tg8coAOScbcWLv7CoM72GWokcgtdJJLSC08GAGiVgzIqeRYhdDgYvcKzLNAxbxKjOIQ2OHRONHyCddqt1niYTnuMKDyt3ExEA8il0qDA+HAST2kt+c29ic/nwsHWCCJs6wMB5LLA2le8ReiWO5jOpXiwjewf2ykT9YJbO3Ri6PzChrTvWwrt2J+6iRVAdLoD6uoSXxA3nhZkR06ko+xBCkH8gtJyQu8Z2RCXv3LoPMrBNye5XdD0Lw14aln2Yacp8jeunncBfMygA8UCNj9n7y26CWsFu8LSZbzg7Xtnb3NeyZTu6plzsQkh248jk5F1hL5b8J0fBqVs2tHHUEbVqBiR7xH7wmNEPXCe5/+CtMOaog+0mL3uRQd1wMbbsWgZtebgibI++po7+KjlQnFpJ0yP9YU9UQgEZh1IRSi/uUTtJqTuse6zj9slbSRntMSlcfNOX7+bhca7pRfuDS3r5hwQat7kIRjF0WAzDWxfWZ/6gwJO85OysLJy5Eo9gQcV0Nz2r2VGx0tVtYMFffh4V3GX9/mViDScIms8aBRwCFFmx+lwpEwUIqwnInAmkIPJ/UgEAdKDwCbV8/gbrQrFLnjyFUcP5dyzSU9S0AFffrun8Lb8qktJk=""
+  SUPABASE_JWT_SECRET: ""AgA7V2zXUt1vUA9mM6zbUMH/PTY3MfHZM14hd6jtbdqn1NCGw0IIxKFp58e+vOYNUiMzjN3P+b6nXGoxbv8jeO1/1K76n97ZeJPrAuZwKtdcddM5FHCpeLCuR/R9oqv0PHSbvBcwPEtMTtAns+LybmyMyWh1mv4RwbeCSJk0QL68VkRomiY9co2eZo0FO2EgWr0guoUtbd3mY9S0lMAZeggso9M8W4FIjHlsAi2XEDWQrRuyM5l/c7g8oEBytBWK/aI6WzfyvE5XkdsnwdqkvdHnqGkMeuSKQlym162JJ1gr9FPOIIUVVo9dVLy4FJWkAi6/D9wbsqkWyHuc8Bzq25hA7OwiuMZ/QlN9Pd3MqxUMgPwSwUY8ZUi/Isp6jmEbYMg/riUbvYXrFkLAZIiuKAzdaH+tyayaXW2FLbDWCJk+pv9ZF2PIptv65MZuii4KOoC7JE5+t6iOMtJ4yDqkbPD45jOky8njN90RlKID192LmAFjGzqWix+KVrOhWTXNV6LeHf1AfuuOU5rn2c7ayve/LDzgLuOzx/0zVBsBVfWtvZrFWmOJi2X4Ivz7pktyDrHynMSlid2J9UQe2JHRLCNLNSpLATN623K8g0rbHCKs3DfSAXdfXZsC/ArXejAJssyPc6NKfD1/aHFl2TXioLq9hJ/+SbiBEJ28UWXL61asLpz4gZCwlSZkf/eeXSnW7Ig27YQYSWVjBm2fKijgXjqF1xQT6hcsH7Wkk/dEfnGILSeGc92kyMHlLZd1lAkjBTuU/jVNGsmc6fXt3RsR7anczuDgPjVYVJZAmP8fyAGecQfeIArGYwBI""
   SENTRY_DSN: ""AgA+X2HkF9b3+p13JS4vG7VY+8p7su6qJ7smoPKqYh44Vpb7J5Eu9ksPNQkcFTDDPT8jAylqsHWUdI0A8u20+a4lqqGkmPN5tCgyBgAL1pIyvPUQjYUbL7A5lTQKlRLJJ+05h5XbkRU7cWR+G4yDUCDj2HcThne0CNDUbDao9D67ekSLUtp6/d0KO45Efao4MLuqISnypPUBGHmAdWGr2z/w7ItXjvUKt3RpH6pSCrGzjlKPKhenKdTsk/NX4Z+ew/JBbHiDQjKCdj0UlXFWH7Q4axaFy0T8tsqf/UN7n/QTalYE+v28isxrHvoR6h7kZETQV/gl0y7DdmTCi8/A1j1+e/9zUx6HvK+C/qGMsKMdNgaaVNSdfFp/yfMgXTUn4HGAls4gjVKSSRaIAbBq32NdKkIvRfocuAGsxInwbrDXLR0nzbHG/U/QhlvfL2gfqKRIVRJtEh99VW/KMMeXZUWR9dNt9gfTMtyzL7eta4oEV+g7sdO/9VjDn5wtic2/7eAxgA7wTEoDA8m0whpHH4VcPLHUfKLTHnRXVu6bykAfBgfEKhJBS8DghvPyu73qL5MREuYkGya4n0RQ73h5ja7mYwI0lsefQszP9Fz1lR+757dhJ6+/E7nNnOE/ShD/8xE0V54pd2IvrRoJmcOsIOZ5w+xWfmN8OyLn7wuEpqEuMHEoisLF9RSp2V5iKbB+fFB4o5P1/VqkNPEFBe0jA4K8DAGX+VdChMpjAI47wF22aj+jmTRf+EY+5l+aEvjyU0G7oUPVzzG8rYa6p+v56zeVsmU4SHIDO75J1cH7tnYDeOxk9fAYZgNplS4gKHVT0w==""
-  SUPABASE_SERVICE_ROLE_KEY: ""AgC07IPlKFO0JYHzO7/H/SVmws9x4mKUd08OQ8VrrvTrwXTmmkKJ0nrbCR1tqSEQTGAFsoTbAtJjVmz04xDsBRbuBuTfbROcD057J+4nKSEvke0rUPnBESiziYQF1Xo0xC80li6OEpiz2ssp5yCF0oddqOkXGR5BfKJ8ZnOS+YkvNla4uE8fbzMUGJU0Erw+/DUOVdIIbF8/P/k55VXbhzPiafMuISc4+vH33/SLeSnUctUiVq43x42buYApt1qb/0cOKElRWtdI1YIx79mbhG9RbE3XinYQ11Fbvo/SeJmTI5YtatH8aesFKSHJy1svzULPEG1Fx6B1wvlROxtiu4Y3WV2YEHOLMXUbrM1CGsqO/W07ohyAGAF/KlhHfYCl/ZqAs+BtuBvPtXXPkxSEj0clqknAW8x8wdJBckPn3OVba0hsmBPcw4NNJPYf9X95jiYMMP+TrrpryTygL0TBcH4agRCu1AXukzdjelvQhRidzV6ZoRxP3e6QjMcqoFW3jx9TAKjj5iZcC9BIIiic3XYCWVv5ei2HuFG2jDBbVDNaNFIOrx/CyrqNIdNiyPX0DH+GilUY4AoZgN/k9syvmWi2sl81yLOt27gGDjGSJTX2whNztcJTDWLgl7t1snj9if+3KzROR/Kmz1XawaBGK2Md+JyiugludHmC6eOO+TKXrV/d02LEZKf0aKnAuAu+gfBGBBagHF5jjkgmCYOGQpALDZWsafqmUsHOIvHmrAEpnKwRCW1JX7Z1pU6SkFm8ceNwsEFPDqIeYbra3k/pHxoSMA5QAO/IafFQdp6NTnYPduJN5yjRh6MSJPIf2U2PFgLnNAug/3Uojk6I6NikcORZtBCHBGd9dtYH3ykQdBSh44ysS3m2o6QVqpbQRYAaUbKEU/wExtZYWK9NzlbuxmRoSKJDAXtjG7Lzgx66p+fZAxYU+MPgxzaoyM53kfqGtLfuikAxswIyvK1+mcq866tyqLFSOwHoQKfez6Q=""
\ No newline at end of file
+  SUPABASE_SERVICE_ROLE_KEY: ""AgBITjBe8qd40clk/T4awlY+lBhWoVJTvdtzUFfD4UlbBd0fjxNKm457Dva2mKej69Lxn/tY/5MaGvZHNUA5LVQuHKzIY5XKdRus8awdyKWXZy5Wlvf2l943YbEGN6nNB7pzRdgcItcyHN5hHlSq5Ney0pfTaApsTZrxsFyGeW/bc8TKfM5+oW3zQDbBPXrnwv1GjG2T90Zx/cvahBNUG07fR53tCTiqQAsRfyU9DGWp/zZbe+3hcC3562imbEu+er6RUiwp/upCapndR5R2U0Vksv+q+N6wipWUObnH4A33lVk+JhpGpS3N0h1TE7JNSgLJuuDAqw6gq4w0SLmE9VdEWacOnJxVI2d3RsJNfqkUg9R+/pFBW67HV0aknUQxXnfDSNK+BAMMUDel4diLLMyNzGbrxbp1IRfB2hOr3ILKudIzniMjLJ2Veq0/xM8wwfNx2BXaUbHcXdOv9Kw05egTjGa3BGZAlMHvAY40V9iO9P/jys0ny+fd6xuwoHGA5UW+wNx9jR1iYwxQiTTRtDDHMvALycu2VCbDCx43QVZxB8dSq42vpt2/T3YoOhaxNF2GJ9mBWTRPnN0oFeTBQYhopN8VylY1HhsR3T/tdrkIkC6PiRCbyzp/zDq+kY5GkHEBCZyxYyO/n9/0vB8iQpLBEfQUpTkVJjdESqkbp9eQwxr/Jl5xfEAJbAiHW1FRFpobaPKrHhYF7Ggxm7DfLeCY84ieWIss9OenEhYJF3MImlxWkzY58dI734E2Rt1u45llOq3JsZe/uWIJgVcFq1YLEv/eG1Ll8+ZmcOulsfywN8dANRvf5uTvsKX20fzwpdAjZlbiq7Rre9Rwwl+7SkBKBI1TfZHV4V10U30rG2p0FUf7J33Xmmf4W3DGlszaJWSbIlMxQZno+/QEKbb5Ani9AJTPYXJ6xqiQsRReT5dPgbjGtdVKW9X+O9xrORNRc65gAayfVEobFljcWbrjSK/myPG8tMHyjtjBDr8=""
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-server/values.dev.yaml ---
@@ -118,8 +118,8 @@ env:
 secrets:
   ANTHROPIC_API_KEY: ""AgBllA6KzTdyLs6Tc+HrwIeSjdsPQxdU/4qpqT64H4K3nTehS6kpCW1qtH6eBChs1v+m857sUgsrB9u8+P0aAa3DcgZ/gNg+G1GX6vAY2NJvP/2Q+Hiwi1cAn+R3ChHejG9P2C33hTa6+V9cpUI9xUWOwWLOIQZpLvAc7ltsi0ZJ06qFO0Zhj+H9K768h7U3XaivwywX7PT7BnUTiT6AQkAwD2misBkeSQZdsllOD0th3b2245yieqal9osZHlSlslI9c6EMpH0n+szSND7goyjgsik0Tb0xJU6kGggdcw9hl4x91rYDYNPs0hFES9HUxzfiAid6Y2rDUVBXoNg7K7pMR6/foIkl+gCg/1lqOS0FRlUVyAQGJEx6XphyX/SftgLaI7obaVnzjErrpLWY1ZRiD8VVZD40exf8FddGOXwPvxYHrrrPotlTDLONZMn4Fl46tJCTsoQfHCjco+sz7/nLMMnHx+l1D0eKBuGPVsKTtbWozhLCNuWEgcWb4kxJK5sd1g/GylD43g8hFW531Vbpk1J1rpf7Hurd/aTUjwSXmdxB2qXTT4HRG+Us6PnhMIuf/yxilTs4WNShY0zHhYgnQFSM3oCTL6XXG1dqdOwY2k6+k2wCQtpK45boVN5PpBrQuDuFdWb/jM5jH6L8ns0dMMlY3lHM459u7FEn8rum/xXdP/JvpFb+yct3Rgc54SOT5HuVUNAHzzmbWhY4RG4b3i21L2SlsVUwjKvu+PlN4MN5KPilvHe3yODXZu0Gp0ClzDNZQiKQU67H0uYr6eRccMDsHtMlPELqnjyQZ+OriydzB3qXidAkguKNmzPypz0LyTMnry7YpNRGyUw=""
   OPENAI_API_KEY: ""AgBzA0t5U4eXqjAIZ1z2zKWGSYKuPuWMe38gg9DyU5ELbvpWbkBuknl4B1+2PH9Cy1Ma0NGfRCW5p5iqX94ay5y16lWycExgw//ue67E0x5YxZw7Bmp65g5a8IGl1y2uSEEJU7DGGKOSGU7a0vjtLHqy9GfhuGMMF8bKy2Mfz1Q+46f9rtwTs25mk+8tGvL0HJqjgX38Xuu8lbZrab8ywiO66cIJo2B5ncx+kkQ46ApLwWgpsjK/AEbvoWdlCws2PM0Tn3CLV2vDkFSPLyoBOfNfHRcCJuVi8nhzPB2W4XnRqdMYy5/HhRqbU5Fcp4eFSqiMwtd8KdpymijrawcdTgQJX8luv7F5DOVukP1WAMT4a8s7vumwtEeFruobBH8ztrHpGD9rIFJQKCsZwzWEBIRicU2yQlb7L8EhUkCqkUa3yNui7nS4sxRnQx24QHMCdUAdgNB0PiU51RDVbY+r2Rbpj1i6htmp5a64bd+n3jow/D2DYxlMXVEpcfLnhPhYfpsZegCoIaBcOMyCg+p1PUKh9w5TUbByLHAXiwdMk+vS3qf49fCOwvsqq0gBeCeY+7lBPYc3iDR+S0V6rnVv3PzM3fD5ighLGm7+z5eHrKxQapflELAmm+t6usz9wHMRoAzQdu1iuYeaoq07fu/yN2pdIpZ4bYB1vFvpqGq1E/XLFaoVy9tT63vLjwL/URxhk4kUYejCXST3gemm6o2BPoj2tU00SKzttLuJbcaYsyGRyiH5xhcwcVIIMsau+gqG1ofMVp8YJBxIKD0JNyg+/bE+iORIjZeAoRexUfhZfiEyjmPj5bHJgtkMoiWrLnBSIbhjDrW5narzxXgWyjoelSH8x1ko0kVGtHHDCdWoTIHjMA16HiLqv3BqzeB5cXNeqY1afbZe8KH1rUlSJB4Tg2qz6+AEUQ==""
-  SUPABASE_JWT_SECRET: ""AgBL6H6byPKXVN0nYWgqyoZBHJJJqk8S3rNYSu3JvwOsNn3Sw94SrJcXuE48fxcojcbKvYcDshetFhrSNEsfUwvbSFoaIj+MItPIZ8FGHyfXnmeZJ5j/sdvcjaMmWS7CiL2jhzI+nc8rL2ATV2TgA7E6FA9MvhWqkAyZu04pCd1c9DsAlpcfQ3pxywXjOV+BU0+1+++Z+fTnaugt+hRbhHrKTddaPhi72KrIyJPOUlqfht0JcgflT1f5frvmNnDwkiP862knhJsqg7XyrSy4msCN7eH4BvV01pO3KhAEnMG4Lk/5FeE/2t05+HqgB4mvPbkqfY6g8Lvf6qmd5g+stB10wRmr+TxzokOom36r7sYd3tyXZMgemJOi3BZjYk7774zf/TI081pJx1FPvM6dDPQdrgnU1nhshq/gLyKB5tTTCkPQHW+YhUtApWgrC5mq8ezMqfuwrUuR+NvyO59K56ERJJFAw1fDKHIVl4TYmftet42lkVOchml30cje9gjBtpOrTkFf8lMv5DLQ/ygdwsAYmVrpYtXbT+GAaRI9QIv/rZVuckfz4uIhTp7IjAtRXJreMH2V8GZ22h6Of/BQG+XA42lMA2huIyLwsqmtL0qxNmIu5EGjcXBvlOt5eNquzts68jgNqEfE6fEuqS9lDepvtTSxGp7wmcmWwOBbIgbCnxl8t4IW/e1qvOPuvxMldH+YtVIvfHMf3DnvbehhCIYuLmRM+E6139/qdGKreRyCi4PA4PKTMEG962rSu/7z0X5wu+UYY+kESrs7HhksL3PhB3dpbZ0HF+b6lchziTI0atG+UNX05ysL""
+  SUPABASE_JWT_SECRET: ""AgCXWGuGOPbdUZsn1G+amfHxm1CZAmuiULAml7sDJ+SUXUBlBWOf/wb0Gf9vnjPrpS5QqeYUQDzVPIXRqs1BkL7m51zAYt4U5K1XGgF4VmUv5Jqm/99iLB/biuVBuGj32wuYzGNEfuPPz6sfg51AfPfuOCDE/bX9xD+M5E++wVQChulm0Lqab5GdBgZC2M90Cb57EjNbwkCnNhO1HY2etwMKJ5q4J6N8gW1nxdWemUFEtQuHRBwEhCA+XRVf4MHQPwixb0Kn7cA+D6OthxWaxsXgg0li/kY7tF4xed2XXkfhARFbATryExcnAXLOucWS1+NKjLSUCZdqeqR/+C6uKyAYQNj60WU9ikDG5LJrLgnB2dXVBDNFHWbVtWtHABdyIVENZlXCBYtIJUpDBVFVIZp/GOyR9mhwPil0qZOiLE6HXiRENyMcZxNk1E9BHQZHS6WKExsi7RP3kJVFcWknBvH8IydkoINRfGO+LNy+H8EK51ml60iq6pvNVRwcxfZBuNcdJQrWflsLbi2dT6u9tWM27COnV2UCWqJuslVhdEAdpeB/nErgnBcSWXl4vtApasxYw7l5QWTU2597TvMidqm9ardvFOiuj9SxRdLZ/H3x3rsn8yn3C22E8Ism4ciEA9wxjwL3pgWiSsRsIsTpI0++lHSSY7hZvsarwFWcgwzjZhufqjVTbRJiHGOeXijiAqj+b5haCkdYmJCFeJuph11GABtORqnVh2xkPfzB3iWpfshX+udtjr7vdJCcpQyRbq972I8sTqFJXQc5hXQYu8/JWApKnpYMFq7MtrCKGurYxLPx7pYaf1sA""
   REDIS_PASSWORD: ""AgBKMJoMuj4Aze7QZFm0mmR+7FJ/1Shc/fvFMc1yv1WcyT12ngDlSdmw6eW6PaAxnrzTRZbjGNxDVONS/8g86OvEEe+OiZjI7iaGxipGkxeKMzHPbHgQt97gKRT0wEQ8K6d67gD72YZDpVmYKMOWlMDIWl64404O1Xq4FJeBQQiB57MpP5VBX0Haxe+piYfyCcli/V9mZqLb8rzutl+IovCzd3z+rpJ2EC9kgCWjGzH0Kaylmrg86ZFFSQScTcv+UQ6/7y2WldVJPohMFEOFbxUXEThzkPxy7rryNNDrQ2M704a+/ixAqhQ9nJmaAfMNdFgp4T0oEQlsTPBEsXwCt3yzqbdAm+eAohe2X60d+trNsHdMGEzgWDFtTLEjCdKml9a7GJMJsZsf2Qb1AnvdwlLFWm9jm8X+x9YXrHvakso+zvRCB1uvVEB+77ys4y0flBXDheFOTsS7cnGfumexGV/0IrJPBujVJM1q6J1ilPGTYqWVpSznl4taCPvkGjFtsKj1JHlc1FMkyV9vmkHfMfC/YuYYzMpKcfMQlUh22gpth69ENhN3DNUUEH3m5Ea4hzG5lsiCJ9XFJyJ4RSqUU3U58zy18ONEzlX1qNb26oqTSe2j5+29JpTAOkmcRyMBH0WHhB1Us5vgYjN0WNKY4EKLO53kxJDJIKiquEb1mWAmy9yzft+LhroqpyhAUtTvh5MLVs1CCpUX2Q==""
-  DATABASE_URL: ""AgAWMrGQg5ON4uR4ZBWZWvt47nuT57L+D63i9vnfSMH9IGAthi+Z056Om4sBfyjpIOT4uowECnznRWQOZLXMrNeIk3Hwc2cBqFuO2LpnN4UnaRQHYNzp2gn8onwq54XhOhQF/aw0sSMBcXWJKfBOY44wZI0vebFaOE1h615tXVvTz9g8OFavj2Wky25ydHZiukpUs7M9eu7FE5RSGiG8saHL8+VLQRWqODf4dcykFiFcp0hNbaNSmYpAWyI8oe44SkzVb2AWbEZEUjkNLVxV95iMeTi0SRNaJ/hW6wcN7O2ZByb2jwRKiXXRa1l9b5Uy9hcueY1VU5ZCDuX5XNtM9BnfbO+Ez0FCc9J8DhfSi6woG4WceWksZ7unEUspPFKVRTFlKqn5MPR/ppfNwatlCpgf9q+zDybrMRoiD8aOcn7QSLNcs+dRRmFNDtu2+2RMBhoYSuENyOxZZRfjg+xYOL29BGx0SOQ46Jk7W/ZC706+T91SHfvTFMqStWFrYQOBxUcoDSK3XidJ/CYcXw3xzXpM4DTSbKVTwKVkPy72DeQf+eTxk0vS0xnbz3SHZVBMrRAcCfvS1HwZGc9TuV6dMfH6i4WKpPt2PxyuDL/sqt0RdHCKjPL8dC+XozqPTv0tTMQ9Xof2bllXWCN5QDWuC4Gam9M8aWKvALqtxwjDJmeqfqImPe045gsIUEX3pGYvB4PHfRPaocPe9sutjfa5EVk1md0m2yBpBcxouJBwV72sqK3yMVFJ+UYu+1nasiNkG828/hFYhHxlV+oUrGHpDV+p2c4faFUMEyo6FC+fBvM1h8JgM+Bk8kaf8YSUuop6Xwc4s/yF46dB6CdCaVJPvI9m3elj6Cg9EAXq7GY=""
+  DATABASE_URL: ""AgBiuPoCatLyHm2T4JojAjXxjd59gDazf2eSPGFjtagTe/ue6crSW9oios4+kzDhSoK+t6CVqBKtRZRK2pzeKJ0xNsEQbCPU8xGrymUS2HsBuadSKz6opJzsrF7V8cFsiZWl8aoJqV1QR2pbRf/o6ws/g2PiXnbykDPwViamQlN+iZXzYA35h8QPYgXLkdWXzqII6cnpxdkgDQGFuZxkKTm6yqX4tKwCT5GcpNNV333IxX33ljZQDwBJENxAGs43wH8KOhSeVq5uGArJz04teagn6zAxVhP6ZnoK77FCCCHzgQ5eupigBxWnLXYSuC0652hcmCWnVTy+eJzGAWvCwdTk45xZ2fyvxj6uTc5DG9Pqk1U5SlLr9C9yvou9Qwd30M4q/Sj9t4WtH4wMIuCHRp5uaTzDHdW+XHIhflRIPJD4XTXvotsbawCgpulwowrtWXtiDZmUJ1IOw12tXnBROk62lglfeb4y0zCc1snpBQeAJd1GWrksZ/j+VRTl6wJFCPfnQot1g6qccBah4Uiz266o2aybcbZH6nIu/hCrRX8QSFrZQZODJoLGZH1XDjYEPX/LHVaCRsQiBiFuWZbYqcU4RhmOiM/KKTimBsl0lzlAMEz8ITL0sLJnjJleqdqPuDp0IAkAZCjHK9cshJIv5Kxp+m9TFRSSscCRSFeVCqROaxZsYKpfdb0JaHFWaZ/h8Is=""
   SENTRY_DSN: ""AgB9i02k9BgaIXF0p9Qyyeo0PRa9bd3UiPBWQ3V4Jn19Vy5XAzKfYvqP8t+vafN2ffY+wCk1FlhYzdIuFjh3oRvdKvtwGEBZk6nLFiUrw/GSum0ueR2OzEy+AwGFXA9FstD0KCMJvyehSv9xRm9kqLOC4Xb/5lOWwTNF3AKqkEMEeKrOWx4OLXG6MLdR7OicY45BCE5WvcV2PizDaN5w3J72eUxFP0HjXit/aW/gK32IJME0RxeuQZ5TnPKTNrooYPR0eWXd2PgYshFjQ2ARy/OsvOrD10y8tQ3M5qx/HNWLC/r0lEu2np+9iUIAE1ufSwjmNSyi4V8usdZWq7xnf3vuKlSgmveqKkLbwQUWj1BpLNIjUvyY+1Rk1rxup/WCgaw+xOZd6sR/qTIjILv5GuzpU0AiwEm7sgl2pmpFXq6n6QjNOfZoPBTL73f4bpXNJ3EyMYDbPxOtGDz91B+bDtOsMr1DNWQslKkk3EIilm/l0+NuLKxf/e2HwM3sB15mkQqVZBdbiVOr7B27cR9xAnr296KE/BU6E9dp/fl+IgcaonMpTsE61pCLHWxQXNBO5X078/zhmaXBQyEBNQ5SPDr9u3pHWrrLkBtXwldZvgmLMMVFMAzrVVkJB4lC9sZj0pXPhda0/BsA4xcGRELj/PizwSr+kb3lDumNMqzEap5ZjEGCBpeeIVSo19v+RoEDw0AFmyxfYx2+91HsgiEqjEUg+J6yDmjAoRpOD1wRZOnnpR8ufMiqdBteCG8B5SXkhgto1WtDyOMVlX2wbmBFVetv2nAbMIA/l4E/Yv8HXiJsTqAkeYc5Qak6/SMGnZTw7Q==""
-  SUPABASE_SERVICE_ROLE_KEY: ""AgCrHCd2AdIv++sX7AAf0YoV+qDFhPuErd/Q9Jgj8/1wDJklqv0giI/M7TRUV6j2Gqa/yLP90Hoiy2BboE0V3FrTtHzasxtSK0hd93+bxvZ34FEfKQyAiddBR8OxzlPwaplzaJ+/Tu+yHf1EesgXrUdydk38D4AQqkrC30FRKJcCxJNTHHzsZiHGQLZNP2l0cEsmqtMXMk8TqbcqHvJZRpr8jP1dSJ7bxEdU9mH/zB4HV+EsPLDFWFAnFjbEQwv8FEGgqpy81ifch4Hz7S0wjwk0x/QsagKavBTvI579K6Sx7uJyMyilpzm5Ct8kDXTEGUWv7pFINXM5cAbcBNzuvwvtXmshMwRsl9e/5Y2/T2VgS7/wPTJA4AmyyrSK976SOjo7imb4XfMwc6Cc/2GE0BRW9jiKvzjQ1TC2ovQpNujTYYgPzIq8sFXEVss31DIcfwbRAzgKTTQZKl+H+i9AS0q6iYHtKORwTQ2bv2XwQwxogXMHTUq1oC3MkzjKfV9DcoTHU2o/+gTyOBW5i3BRatuublA1x0EwDoEVmWA1+i1h2bpkl4QYuyeNlhJnRHzuQU3RdFLWn3MkDM8Q4Y9n0/XXwwTCgqtdAExqNh3YJYumWiGiWfdBpEUqlUtOUurNMXy6rHH4odnNKeLQfMOa9406x5H5xiwNkl3mzGjNiPDMS7JMTptlsoL8DshE2TM0PqZVrQy81OsGNpdiU8MVeUdHO6/bDBe7j9v0FipqpeehX1AZEYb/4CWosTJACWpaTnLYRh+w12bk3x6Sj0kriDKMOuJLBRh1fveZXUC9C0FsEPhq2rBLQDVh78DkBIeKVGUzuxDP/6mT3OSBPe4aCye0vTmwtEOEvB+A7rcMkOl+j90bKAveE9H+f7UVU6Og40Nc3sSuMolKHbQyB9TNd4+jOfmySSN675riL6BpFFCSuWqjrqWFr0yI1h/xAg+YMg8WzWarwSeWr3ykXrbhQvu7Oj27ffLXEIvS0gU=""
\ No newline at end of file
+  SUPABASE_SERVICE_ROLE_KEY: ""AgBKJDPEiTQUYLY0B/NKaAkxH7whrGuxQVtRdz9mEr/Bx06n1Yu1Zm4/oEQp3OvYerRvQWuv1k3//jf3eiya4ZW9+ZntfPdQWL9/tzq+/spevFtiEvuQ8uuUhtNOU4IGt27KTTlhCfeHKte8jtLQ/lwcrSrfPZ1T8Gy8PXdsAgakGUauEs2oHuX2XUaPE9UFF4HRAhmjPZ9e7u7Zfgcj8D+otjrwNVC5ZXFM7/ha0roeZHdpTvOcemKjxhiZA0FmdkXgOCPihNxlz0sKcupCEte6ocnSkpL3pBflBsa9+NLz7kLCUQPeOCExkMTndyqWk1kFci6j35cBP6PQlHfWPdo8OFCdG+3EfvEt5+4PQ08d7nXRZqowBiQdE2/e8qA/dZc8cJ7ecpza+9Qf/pNIl+9Ix0EFvmB6rpbO9w5Ptw2yMOAebVl7qV+A65GelvcPWROK5Vfftwx8KT2sn9ldVOYy+C7OafgOm8qaL7mEMePSwJy68MKpnMm/TceE7xxZ2sMSWEl9FMn4QXEawD4LQrJHKpum6XyUG2FlMkogHMikOEbJzz1ICAcHB6OWJXo3wU+fK8jkI4/UYioFSfF9MQXaC8bUGc4NT6T62KvjnrdkmOHG7HcN4UNQ7yBa/fP1pM7peYQdwAKr4Oxl4v3i96uKRdCuIimYiWpcxklkQhmSsMLKFMZGDDvv1BNtL6oxK4ZaEyWoorEyjkd2UrSpbP6cvyVMVWbTl1/BD350NRn6OYTpGIXwmAhqVWuuyt8kfLLU6Ot2MYcq/i16qvc3dA5XizLKHY95X8R+DlUCEzawF75Sx++eMPKU/o5rxhZNRjvffIcXtw1Hy/uqVCqilmSt33RqUsehOxQUqHBIW7L7sAik/L+hgTiE3MwN8XSfGncDB/bNweJh3ZSXsdwZD2bleEY1nWpsXVhcJDNcdW3YscJbsyTCGQcOb0zEQaxSmfLAd3rIa+SAZpFEOsD8A5kZjI4QpmqPkhNHeF8=""
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-server/values.prod.yaml ---
@@ -119,8 +119,8 @@ secrets:
   REVID_API_KEY: ""AgBPAmDtdzfHMbudluOeUZS7RCixfJXaI6vBvEUPQhhtpbNW9sUfDv6waKzBdjgWxIf2EqI4QI7QUVqHxA7fMChSjZjt9Np9z6+nHZhKWTqCCKyVR4Lka8tnkU5M62e+x+T7QoHy6mKsB7FEyQ8/FPxUM/Ddp5ZPTj6sbLn3y2uv1SPxInbd6boXeLEwQQcN/Inrww/lzNzJPec4jlHNwPHugjhZJnlWotvyfhU33Fdt5IEusdqt6CM0vS5N7lkR8KTNAg56VLD89yXVRR2VOtkJWzaQJ4lNSztBgUFNGaYtl7SRNVYnMpT1jhyTcAeO/fAGP4O/8haTlAZbfSsOLub5Af9CIA5vtNpU4zoY0Q2MOtKOJ5OTtbbJxmlWex3zc2wpIwdTLCRyBHxiPphdSBXQPW12s9NX6GVR7WDc3Lcvhi0P4uo+y01kyL64JGRigjvBzCYCqhNGWMtJ+YOy4pwcE89Qaz2/EvHgh37P9O7TQhN3Vo8BGRV0+DlNe6uv3OBitgayub5M34nh+qnNHypErkm29SovnqY1fEFhdOib2nmnE2fEXylZMtMPonBVYtVX9iOJLERQMNOzwDxaKzwPdpNu4GhMNVG6joCDjDqKPp9BfnKDJsn0GgUt3oDl5kRWdYL75HLDa3LDWGj0UiAF1YeQE2SHJjlrIoAVJWDdjwTsFJ1x3sMZTt9gB8KiUIDK/hgt7to/kaIyBUTrQIUv/2hHNYI4KH5/nNFZu3TPJXNrxfU=""
   ANTHROPIC_API_KEY: ""AgB+40jZoawJ6HaeyyLZvDp2ByF4EPy2Ce806D/lekwJVmxpYXgkQdLJyav6bt9c1g5eDShJqezx1T+jGV+ApQbhSwmO403nJdYO825Fd3XVJ5K0xfFNt8DOTC9r2egWFvJZL40s/Y24kpr2Mmsqp+Sk9DxMNdYG/Z4PnT8PLWgb3yIYGGPVjlWlHL82gn4/B1bVTk14/cGXX9eSr0ktKKmS2OGLMYUwLT3oYGy4bRq9bH91XwjjdW6vMluNBGYibpi2f4h3nYORaQn42OhzTqON3XUdvNmsw1ZH0raMAJq47SU0lC6Ar9MzwbtUWY3tF6BlTmyx3gPavjQCnXg5cRxmY8JklrynDoyN+SBludzaWDzdAjr4vGPpkOo56RBY+28tnNjmxgyttGIYfFa8DEsrrJJgZZxSUvRqwJc0TWIKRFP1aIHkQ5DclUilFtNfPMezxwcFqrsYTEvtDjsls/E8uTNUN99cVQ2x0PxDsLKr9xVKAKkzzOBEvKEAJy0t5RtRV9A6kc0b16YbjIkFphip4e7HJTWKRvavknw+MXjGXXQrz9+xp8LrjRcgCyZp3BqSo+gsX8KQJSnhiFfKvgt7RdVaUVUA+sn5fIQGPWA5IkbI4gS12BRFDw59+Doc5FbCGUip4jDL8I2bPuNKQZLmSMx93Nu/60WBRhKXYz+GNzLzvhk0IpEI3d2GeWvC61p/f5eKnsLKNLDrc3k8rFHiUmXXhB+oQXMRSUFqq4hen32VVPWRhzT8nefww5Tud21CBg5+87x6WHOnB/A4vw+VuKD3fdeo9tn4HlD3w2funOVu9yv+NaP+MTeHus2PBeab/OtKLH09ezxnhmA=""
   OPENAI_API_KEY: ""AgAjPjhje52qw5YSXjRAwoXU0WyDEIAHnz2CjFtSjkpbsvvXFPlPMlOd/y7/dvABoyZHB9Ukxjna6opqV/hK/vHR9ncp9i7cDYX3Rekj+mkA6arMdqdJ0eikAGqWYPieu8RcBn6pHFGmoC8ZZPgk6Eh3Wyi4OCaPfH/O1bTq/RBQU5VDFvYfaeDZmYIu6SkD88pI0lT12Dklk1apsHlS+g3/rpQwDXgemE/pdmcNnt1zS6Ifu4isN7yg1pg1Thja+UiQnEkIiZkvmD39LO8HrwOFt8guJctRZ5gnVxPmSEdJLN089/fj5VXxTO1kTprbh1KeG9RKYS5LEPNYpgcl9/o884qMc/r0/+Cy7gL5R1THrEPHurVg8JfssCq8k0SaEtCElQ2081Scc/0p/k4URpXrsxUKZ8XUTIvYS0y2mEJPAAqaHAkwthY8sizhOwqWWnt8dGbCPwfQ11TiNSMikKIim9Bwm4tKM9aEolROSkivbGqFQQYSkensyp2mTqx7iFYlGBa7Z7PFRBZgPzD2FojWc6o5tLui5Xgi67ukO5WeaBhO6eMd2CuIlXqu+5x3+ixIytp9Jpke4mZKwbjYai4j3iELbzEwbGkjsnDyWNYn+1KnPOogd6i5+YPn09FbQO2Qvg2t3yUP/ePeX+fdRYk7AnS/o6nllqj9GLas48JFUlEx+KSO4qwrflRqPUmfmD3wPDTYR2q6yJzdatLYzdRQxEctFhgvco63uhW1YH+1ei1YuxutYPkIOqUwbgfIC3XiW7Tr3R8Gd3TimJLQM1etR6dwrEaEm0jTCIKUoZ+65OIAeVtcXIwWtwRjjUOtR8k9B2UdFoJOgtfIFzlxwYj4xUJrzRkCLdFD1W362n2+O5n7QdXDjYXn9KmxVUEph2vloeS8IGrBjM/l743A3trFD4CZ9g==""
-  DATABASE_URL: ""AgCArShEXLoTAfghyAvdy8R62p0n7Qh3xSVz4ISZ/s94M+3H7rCWNZHpx+58DLAZRJXgkXu94sRiMsAa1SNjg7aAY2gMX5n37xDDDXyELW49SBIcRVPHGbVLZ6GFzXr7JbjsxrLJoOQ6mfbSbioqARj5UnDWxBxBaoLGf0YCHb6BHfT1Vw0a/Ca8GwA6UJHhS/umitNwyrnCsIQBuDgF+RSAyerIpGnppSSpM73AL/aam6S5VaUoyfa0YGr5SWp1pBmV+M39Uis4HkNM65yM6iSy7sGcFTpLOuFvWlZstttGCKyQO4PI+bY1In+/MPdKTl14fTs2uqOZ4XaYVzkz89myh6JPDvXYgYxIv04us0Y8x9at12yB5INvScJpCpLbq3Oa9wEh6guw3HvFU9LWO6zrlwDjAzFmvMHyvufvl6/oaFAFBemh1Umv46f/q15Jb89x889hDwnJZl9xmXRhubBHpLlvcoZvhZTN7nkOV49RwDG97enz29Z2YMlN7A2oK30yKzAjRpXBF5m5yKFZCNzEEgMDHxptfygRdN3Mf3W3Pk5C5IE2/htPnO5pxvlr2f6cI3VufxV0x6TEWD6a/88EAf362McGGBFu6Z0/DnJUMs4emDZTNsIsRZ6LNdEWbsF4eNSpIkghNLzfbeloeIuRZDHafhk1VCBYGEZmsNn3uEQ7wkcw1gcfawnuf/3kXQk=""
-  SUPABASE_JWT_SECRET: ""AgDCNoyGjkV74NoJTSN+VDpiIl8B7sRzDK3WFAO2wBWdhFSwnO2x4cZ7F9YxiEQgvjslCEn5wCrgqBiO6L3EP4qd0EUibZrx+6xXIK5tRY3YACXf1pQEgRTl5fXTbdlRJgr0+2upe1bB30LecbM/G+goX+RprKmwSxNJfBo/AQQP1l1dJsl4v/yGbEj8WQFD7jTiyCGT8skIX07GUvzZVbAD+DaNmvucuENja90O7q3ACOIJ9VWX9rTJX1V5brrb7y4ge8Iv97bUisH/MtFtZMEBEK1csixdBUC47wtboxn3LnMUaE2OlJZD+9IzEf6TqTJGREyOd+h2V/8BmUYnKRZUVWPURsWLinfbDpyXPmGSBgnfYCd5ZKS5dvwvQwiR6ODlO9E2WOe4xoAHSq57uUxLopcrDsVzZcLiahA02613vYafwc9svg/8dJV2FokKrnQs/bRHlVCa51Vs8z/zCBnHzS6RBq2p2vMU/PbzMfMR2DjzQcvE6hOnyLMlOMpYe67FaHC2cZTayUqNzi5hDNUp19grEqwjdvannOenn/ewTX4yCOVaOoAQ+QBrv1o4g46E18wFnDMoYH+b7PJ0mUf3NSV0jXH+elbW5H6c5WdnmKT+nWQhaVTD4pMAlY8z2W6LddpA7XHfj/lAzboSj+VJqwCrx8AVMKJ4LTbYGTdu9RkcNZLVHkrtafEAYZNnYrIwNZT3SuLWO8X/dGKrrZmOoaaQJZkBuRy1bLdOGXKUIBvf+MDvmApjp/+ScDxl11KifiEO3tO65hNVa2YPjkIf36fJpJ6vtDchsmyowJ9cRhduZsu4PO4D""
+  DATABASE_URL: ""AgBI8TcJnE7HOjLdcc4czgwE8E2ejDKoQNHXdciXkqRxdNomu663xb5GnHaXybJ3/HjnA+48eZs1enXvedLe521s7Gs+f8JHC7KZ+EE62JqtP8OvKX86D2/GPgDlCMYmkSEkbYWHTCRdIUB2xAyl+5Hs3/srQJqNwWtL25NwkiGimIBCkSdRqql1MtHLOXg9McevVF+Le0NCOpqOh1WV3+Fk/8Y/HnUNQmhiyg81rvu03ce5zSSpQlCkZFCCE+hw/vyS/GlW/PZIaIXTqcp2O2G15hmG8vxQtM5wSEJPIAps1VLw6ZBIPZOayuq74hWeNJiQ7LkHAO8A9b0oA8v3xb3nOGirP3hf3sjKyzLGW8Hp0YHxMrwAgbA2zxH5Y1+LK/zlhbR9iVC0eZ99j+UFCa6GpJQighEx8KN30sM3tHwaFNfdb0uo/mQ3YBusxNmF5IpHy46g2Hmd0Evc99L+ABeKqVWdRulfPtK79l+SfrMDWMTZp3s6576RnxzVrmck8VWKZsdqy/L5xHBK0BDLFv5YmejIjvCTDJZRYGAHXaisQLO1Dwg39QMnrnUeiGO9hQkY87mXZu5jJeRV10+dI6VVx+W9G66KbHfb6M/Nb+KO0HWh6WWc7ZYDNAerpfAISHWMdSblUDay6+MEV9aTjrj1n8TRdYDKNR+5E4Oa3o3ufYi5vqayblqjoEYsBDiSAoo=""
+  SUPABASE_JWT_SECRET: ""AgA7V2zXUt1vUA9mM6zbUMH/PTY3MfHZM14hd6jtbdqn1NCGw0IIxKFp58e+vOYNUiMzjN3P+b6nXGoxbv8jeO1/1K76n97ZeJPrAuZwKtdcddM5FHCpeLCuR/R9oqv0PHSbvBcwPEtMTtAns+LybmyMyWh1mv4RwbeCSJk0QL68VkRomiY9co2eZo0FO2EgWr0guoUtbd3mY9S0lMAZeggso9M8W4FIjHlsAi2XEDWQrRuyM5l/c7g8oEBytBWK/aI6WzfyvE5XkdsnwdqkvdHnqGkMeuSKQlym162JJ1gr9FPOIIUVVo9dVLy4FJWkAi6/D9wbsqkWyHuc8Bzq25hA7OwiuMZ/QlN9Pd3MqxUMgPwSwUY8ZUi/Isp6jmEbYMg/riUbvYXrFkLAZIiuKAzdaH+tyayaXW2FLbDWCJk+pv9ZF2PIptv65MZuii4KOoC7JE5+t6iOMtJ4yDqkbPD45jOky8njN90RlKID192LmAFjGzqWix+KVrOhWTXNV6LeHf1AfuuOU5rn2c7ayve/LDzgLuOzx/0zVBsBVfWtvZrFWmOJi2X4Ivz7pktyDrHynMSlid2J9UQe2JHRLCNLNSpLATN623K8g0rbHCKs3DfSAXdfXZsC/ArXejAJssyPc6NKfD1/aHFl2TXioLq9hJ/+SbiBEJ28UWXL61asLpz4gZCwlSZkf/eeXSnW7Ig27YQYSWVjBm2fKijgXjqF1xQT6hcsH7Wkk/dEfnGILSeGc92kyMHlLZd1lAkjBTuU/jVNGsmc6fXt3RsR7anczuDgPjVYVJZAmP8fyAGecQfeIArGYwBI""
   SENTRY_DSN: ""AgA+X2HkF9b3+p13JS4vG7VY+8p7su6qJ7smoPKqYh44Vpb7J5Eu9ksPNQkcFTDDPT8jAylqsHWUdI0A8u20+a4lqqGkmPN5tCgyBgAL1pIyvPUQjYUbL7A5lTQKlRLJJ+05h5XbkRU7cWR+G4yDUCDj2HcThne0CNDUbDao9D67ekSLUtp6/d0KO45Efao4MLuqISnypPUBGHmAdWGr2z/w7ItXjvUKt3RpH6pSCrGzjlKPKhenKdTsk/NX4Z+ew/JBbHiDQjKCdj0UlXFWH7Q4axaFy0T8tsqf/UN7n/QTalYE+v28isxrHvoR6h7kZETQV/gl0y7DdmTCi8/A1j1+e/9zUx6HvK+C/qGMsKMdNgaaVNSdfFp/yfMgXTUn4HGAls4gjVKSSRaIAbBq32NdKkIvRfocuAGsxInwbrDXLR0nzbHG/U/QhlvfL2gfqKRIVRJtEh99VW/KMMeXZUWR9dNt9gfTMtyzL7eta4oEV+g7sdO/9VjDn5wtic2/7eAxgA7wTEoDA8m0whpHH4VcPLHUfKLTHnRXVu6bykAfBgfEKhJBS8DghvPyu73qL5MREuYkGya4n0RQ73h5ja7mYwI0lsefQszP9Fz1lR+757dhJ6+/E7nNnOE/ShD/8xE0V54pd2IvrRoJmcOsIOZ5w+xWfmN8OyLn7wuEpqEuMHEoisLF9RSp2V5iKbB+fFB4o5P1/VqkNPEFBe0jA4K8DAGX+VdChMpjAI47wF22aj+jmTRf+EY+5l+aEvjyU0G7oUPVzzG8rYa6p+v56zeVsmU4SHIDO75J1cH7tnYDeOxk9fAYZgNplS4gKHVT0w==""
-  SUPABASE_SERVICE_ROLE_KEY: ""AgC07IPlKFO0JYHzO7/H/SVmws9x4mKUd08OQ8VrrvTrwXTmmkKJ0nrbCR1tqSEQTGAFsoTbAtJjVmz04xDsBRbuBuTfbROcD057J+4nKSEvke0rUPnBESiziYQF1Xo0xC80li6OEpiz2ssp5yCF0oddqOkXGR5BfKJ8ZnOS+YkvNla4uE8fbzMUGJU0Erw+/DUOVdIIbF8/P/k55VXbhzPiafMuISc4+vH33/SLeSnUctUiVq43x42buYApt1qb/0cOKElRWtdI1YIx79mbhG9RbE3XinYQ11Fbvo/SeJmTI5YtatH8aesFKSHJy1svzULPEG1Fx6B1wvlROxtiu4Y3WV2YEHOLMXUbrM1CGsqO/W07ohyAGAF/KlhHfYCl/ZqAs+BtuBvPtXXPkxSEj0clqknAW8x8wdJBckPn3OVba0hsmBPcw4NNJPYf9X95jiYMMP+TrrpryTygL0TBcH4agRCu1AXukzdjelvQhRidzV6ZoRxP3e6QjMcqoFW3jx9TAKjj5iZcC9BIIiic3XYCWVv5ei2HuFG2jDBbVDNaNFIOrx/CyrqNIdNiyPX0DH+GilUY4AoZgN/k9syvmWi2sl81yLOt27gGDjGSJTX2whNztcJTDWLgl7t1snj9if+3KzROR/Kmz1XawaBGK2Md+JyiugludHmC6eOO+TKXrV/d02LEZKf0aKnAuAu+gfBGBBagHF5jjkgmCYOGQpALDZWsafqmUsHOIvHmrAEpnKwRCW1JX7Z1pU6SkFm8ceNwsEFPDqIeYbra3k/pHxoSMA5QAO/IafFQdp6NTnYPduJN5yjRh6MSJPIf2U2PFgLnNAug/3Uojk6I6NikcORZtBCHBGd9dtYH3ykQdBSh44ysS3m2o6QVqpbQRYAaUbKEU/wExtZYWK9NzlbuxmRoSKJDAXtjG7Lzgx66p+fZAxYU+MPgxzaoyM53kfqGtLfuikAxswIyvK1+mcq866tyqLFSOwHoQKfez6Q=""
+  SUPABASE_SERVICE_ROLE_KEY: ""AgBITjBe8qd40clk/T4awlY+lBhWoVJTvdtzUFfD4UlbBd0fjxNKm457Dva2mKej69Lxn/tY/5MaGvZHNUA5LVQuHKzIY5XKdRus8awdyKWXZy5Wlvf2l943YbEGN6nNB7pzRdgcItcyHN5hHlSq5Ney0pfTaApsTZrxsFyGeW/bc8TKfM5+oW3zQDbBPXrnwv1GjG2T90Zx/cvahBNUG07fR53tCTiqQAsRfyU9DGWp/zZbe+3hcC3562imbEu+er6RUiwp/upCapndR5R2U0Vksv+q+N6wipWUObnH4A33lVk+JhpGpS3N0h1TE7JNSgLJuuDAqw6gq4w0SLmE9VdEWacOnJxVI2d3RsJNfqkUg9R+/pFBW67HV0aknUQxXnfDSNK+BAMMUDel4diLLMyNzGbrxbp1IRfB2hOr3ILKudIzniMjLJ2Veq0/xM8wwfNx2BXaUbHcXdOv9Kw05egTjGa3BGZAlMHvAY40V9iO9P/jys0ny+fd6xuwoHGA5UW+wNx9jR1iYwxQiTTRtDDHMvALycu2VCbDCx43QVZxB8dSq42vpt2/T3YoOhaxNF2GJ9mBWTRPnN0oFeTBQYhopN8VylY1HhsR3T/tdrkIkC6PiRCbyzp/zDq+kY5GkHEBCZyxYyO/n9/0vB8iQpLBEfQUpTkVJjdESqkbp9eQwxr/Jl5xfEAJbAiHW1FRFpobaPKrHhYF7Ggxm7DfLeCY84ieWIss9OenEhYJF3MImlxWkzY58dI734E2Rt1u45llOq3JsZe/uWIJgVcFq1YLEv/eG1Ll8+ZmcOulsfywN8dANRvf5uTvsKX20fzwpdAjZlbiq7Rre9Rwwl+7SkBKBI1TfZHV4V10U30rG2p0FUf7J33Xmmf4W3DGlszaJWSbIlMxQZno+/QEKbb5Ani9AJTPYXJ6xqiQsRReT5dPgbjGtdVKW9X+O9xrORNRc65gAayfVEobFljcWbrjSK/myPG8tMHyjtjBDr8=""
   REDIS_PASSWORD: ""AgB7eiUuFQO88vVMI28xfmJsA2QzEb71r3NyDJ/KTNsjqn7ai1KpjVaaTDyr4Xzo1wOhwwwxlhIoeBwf26wPiraJtkjRU9z9Aotvy0u8SXFm05ObhMjJoY2dBvW6ga3KNaunWoTx5e6NbYPGRIgNtRBVN4PH5Lf7Ou5SZBjJBaVWgIT1x71tB2eD2XksOw2mrfaF0WODsQxXDOaF9BJ4Gn7yIT0Nh76Okn9uhesQxvojaqlAIeAKXyrZJwAH5qL3D772rYsISmbHC0bCBgx4dbbtvsr4YgiR387ri7KGfrEqoFH/jzUp5cwsJNyBpWG1n2O0QXYgbMIsmJP6rdD+KTZkLGBz0wgq/JySCZM9hj54dYtLE7LMmpZn7//EKZk7zsV1u9oSciQisWcJqW8El+IMOAZilqSR2NjpI4cb0xR7/gTLLQF33+wnZwbbHghbDwTowkzOZ0i7qt73YkR8MKrlLhLcCGHjhyb50xr1DJl9mVUoyHXvFOj2tQO/273sMNdKpJvNFi9EEhdirzbcuphnaRm5xXYF1CHKtXUp6EvdxgHqEuoGwh5Kt8dtGMJfSJ40LsARZXCFU7CC6g/faPq93K5QB/bwlOdABeOVF/odqXZQAADX3TQwIPMH36XuqwNggWQ8Igy5o1d3Hi84jVChmjid/Wk8DREmkntzDy+4Jxzqx1rPSThyoOvopirY8VA=""
\ No newline at end of file",feat
"fix(server): Fix node input concurrency deadlock (#7936)

In `autogpt_server.util.lock:KeyedMutex`:
- track number of pending requests for each lock
- only remove a lock from `self.locks` when the number of pending lock requests hits 0","--- rnd/autogpt_server/autogpt_server/util/lock.py ---
@@ -12,21 +12,20 @@ class KeyedMutex:
     """"""
 
     def __init__(self):
-        self.locks: dict[Any, Lock] = ExpiringDict(max_len=6000, max_age_seconds=60)
+        self.locks: dict[Any, tuple[Lock, int]] = ExpiringDict(
+            max_len=6000, max_age_seconds=60
+        )
         self.locks_lock = Lock()
 
     def lock(self, key: Any):
         with self.locks_lock:
-            if key not in self.locks:
-                self.locks[key] = (lock := Lock())
-            else:
-                lock = self.locks[key]
+            lock, request_count = self.locks.get(key, (Lock(), 0))
+            self.locks[key] = (lock, request_count + 1)
         lock.acquire()
 
     def unlock(self, key: Any):
         with self.locks_lock:
-            if key in self.locks:
-                lock = self.locks.pop(key)
-            else:
-                return
+            lock, request_count = self.locks.pop(key)
+            if request_count > 1:
+                self.locks[key] = (lock, request_count - 1)
         lock.release()",fix
build(backend): update .gitignore to include ignore / ign file extension,"--- autogpt_platform/backend/.gitignore ---
@@ -5,4 +5,7 @@ dev.db-journal
 build/
 config.json
 secrets/*
-!secrets/.gitkeep
\ No newline at end of file
+!secrets/.gitkeep
+
+*.ignore
+*.ign
\ No newline at end of file",build
"chore(platform): Added latest claude version (#8397)

latest sonnet model","--- autogpt_platform/backend/backend/blocks/llm.py ---
@@ -62,7 +62,7 @@ class LlmModel(str, Enum, metaclass=LlmModelMeta):
     GPT4_TURBO = ""gpt-4-turbo""
     GPT3_5_TURBO = ""gpt-3.5-turbo""
     # Anthropic models
-    CLAUDE_3_5_SONNET = ""claude-3-5-sonnet-20240620""
+    CLAUDE_3_5_SONNET = ""claude-3-5-sonnet-latest""
     CLAUDE_3_HAIKU = ""claude-3-haiku-20240307""
     # Groq models
     LLAMA3_8B = ""llama3-8b-8192""",chore
"build(deps): bump supabase from 2.9.1 to 2.10.0 in /autogpt_platform/autogpt_libs in the production-dependencies group (#8617)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/autogpt_libs/poetry.lock ---
@@ -626,13 +626,13 @@ grpc = [""grpcio (>=1.44.0,<2.0.0.dev0)""]
 
 [[package]]
 name = ""gotrue""
-version = ""2.9.3""
+version = ""2.10.0""
 description = ""Python Client Library for Supabase Auth""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""gotrue-2.9.3-py3-none-any.whl"", hash = ""sha256:9d2e9c74405d879f4828e0a7b94daf167a6e109c10ae6e5c59a0e21446f6e423""},
-    {file = ""gotrue-2.9.3.tar.gz"", hash = ""sha256:051551d80e642bdd2ab42cac78207745d89a2a08f429a1512d82624e675d8255""},
+    {file = ""gotrue-2.10.0-py3-none-any.whl"", hash = ""sha256:768e58207488e5184ffbdc4351b7280d913daf97962f4e9f2cca05c80004b042""},
+    {file = ""gotrue-2.10.0.tar.gz"", hash = ""sha256:4edf4c251da3535f2b044e23deba221e848ca1210c17d0c7a9b19f79a1e3f3c0""},
 ]
 
 [package.dependencies]
@@ -986,13 +986,13 @@ files = [
 
 [[package]]
 name = ""postgrest""
-version = ""0.17.2""
+version = ""0.18.0""
 description = ""PostgREST client for Python. This library provides an ORM interface to PostgREST.""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""postgrest-0.17.2-py3-none-any.whl"", hash = ""sha256:f7c4f448e5a5e2d4c1dcf192edae9d1007c4261e9a6fb5116783a0046846ece2""},
-    {file = ""postgrest-0.17.2.tar.gz"", hash = ""sha256:445cd4e4a191e279492549df0c4e827d32f9d01d0852599bb8a6efb0f07fcf78""},
+    {file = ""postgrest-0.18.0-py3-none-any.whl"", hash = ""sha256:200baad0d23fee986b3a0ffd3e07bfe0cdd40e09760f11e8e13a6c0c2376d5fa""},
+    {file = ""postgrest-0.18.0.tar.gz"", hash = ""sha256:29c1a94801a17eb9ad590189993fe5a7a6d8c1bfc11a3c9d0ce7ba146454ebb3""},
 ]
 
 [package.dependencies]
@@ -1373,19 +1373,18 @@ files = [
 
 [[package]]
 name = ""storage3""
-version = ""0.8.2""
+version = ""0.9.0""
 description = ""Supabase Storage client for Python.""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""storage3-0.8.2-py3-none-any.whl"", hash = ""sha256:f2e995b18c77a2a9265d1a33047d43e4d6abb11eb3ca5067959f68281c305de3""},
-    {file = ""storage3-0.8.2.tar.gz"", hash = ""sha256:db05d3fe8fb73bd30c814c4c4749664f37a5dfc78b629e8c058ef558c2b89f5a""},
+    {file = ""storage3-0.9.0-py3-none-any.whl"", hash = ""sha256:8b2fb91f0c61583a2f4eac74a8bae67e00d41ff38095c8a6cd3f2ce5e0ab76e7""},
+    {file = ""storage3-0.9.0.tar.gz"", hash = ""sha256:e16697f60894c94e1d9df0d2e4af783c1b3f7dd08c9013d61978825c624188c4""},
 ]
 
 [package.dependencies]
 httpx = {version = "">=0.26,<0.28"", extras = [""http2""]}
 python-dateutil = "">=2.8.2,<3.0.0""
-typing-extensions = "">=4.2.0,<5.0.0""
 
 [[package]]
 name = ""strenum""
@@ -1405,32 +1404,32 @@ test = [""pylint"", ""pytest"", ""pytest-black"", ""pytest-cov"", ""pytest-pylint""]
 
 [[package]]
 name = ""supabase""
-version = ""2.9.1""
+version = ""2.10.0""
 description = ""Supabase client for Python.""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""supabase-2.9.1-py3-none-any.whl"", hash = ""sha256:a96f857a465712cb551679c1df66ba772c834f861756ce4aa2aa4cb703f6aeb7""},
-    {file = ""supabase-2.9.1.tar.gz"", hash = ""sha256:51fce39c9eb50573126dabb342541ec5e1f13e7476938768f4b0ccfdb8c522cd""},
+    {file = ""supabase-2.10.0-py3-none-any.whl"", hash = ""sha256:183fb23c04528593f8f81c24ceb8178f3a56bff40fec7ed873b6c55ebc2e420a""},
+    {file = ""supabase-2.10.0.tar.gz"", hash = ""sha256:9ac095f8947bf60780e67c0edcbab53e2db3f6f3f022329397b093500bf2607c""},
 ]
 
 [package.dependencies]
-gotrue = "">=2.9.0,<3.0.0""
+gotrue = "">=2.10.0,<3.0.0""
 httpx = "">=0.26,<0.28""
-postgrest = "">=0.17.0,<0.18.0""
+postgrest = "">=0.18,<0.19""
 realtime = "">=2.0.0,<3.0.0""
-storage3 = "">=0.8.0,<0.9.0""
-supafunc = "">=0.6.0,<0.7.0""
+storage3 = "">=0.9.0,<0.10.0""
+supafunc = "">=0.7.0,<0.8.0""
 
 [[package]]
 name = ""supafunc""
-version = ""0.6.2""
+version = ""0.7.0""
 description = ""Library for Supabase Functions""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""supafunc-0.6.2-py3-none-any.whl"", hash = ""sha256:101b30616b0a1ce8cf938eca1df362fa4cf1deacb0271f53ebbd674190fb0da5""},
-    {file = ""supafunc-0.6.2.tar.gz"", hash = ""sha256:c7dfa20db7182f7fe4ae436e94e05c06cd7ed98d697fed75d68c7b9792822adc""},
+    {file = ""supafunc-0.7.0-py3-none-any.whl"", hash = ""sha256:4160260dc02bdd906be1e2ffd7cb3ae8b74ae437c892bb475352b6a99d9ff8eb""},
+    {file = ""supafunc-0.7.0.tar.gz"", hash = ""sha256:5b1c415fba1395740b2b4eedd1d786384bd58b98f6333a11ba7889820a48b6a7""},
 ]
 
 [package.dependencies]
@@ -1751,4 +1750,4 @@ type = [""pytest-mypy""]
 [metadata]
 lock-version = ""2.0""
 python-versions = "">=3.10,<4.0""
-content-hash = ""55475acb18a4fd5dc74bc64d89a24fff1f41e8cd61304c15ec3df2503bbeba56""
+content-hash = ""ec5d13aeeba203069701f11245c89822c99367b7400beb2df22c410a4e9b721e""

--- autogpt_platform/autogpt_libs/pyproject.toml ---
@@ -15,7 +15,7 @@ pydantic-settings = ""^2.6.1""
 pyjwt = ""^2.8.0""
 python = "">=3.10,<4.0""
 python-dotenv = ""^1.0.1""
-supabase = ""^2.9.1""
+supabase = ""^2.10.0""
 
 [tool.poetry.group.dev.dependencies]
 redis = ""^5.2.0""",build
"fix(frontend): avoid displaying long description text for block (#8688)

Co-authored-by: Toran Bruce Richards <toran.richards@gmail.com>","--- autogpt_platform/frontend/src/components/edit/control/BlocksControl.tsx ---
@@ -205,7 +205,10 @@ export const BlocksControl: React.FC<BlocksControlProps> = ({
                         {beautifyString(block.name).replace(/ Block$/, """")}
                       </span>
                       <span className=""block break-words text-xs font-normal text-gray-500"">
-                        {block.description}
+                        {/* Cap description at 100 characters max */}
+                        {block.description?.length > 100
+                          ? block.description.slice(0, 100) + ""...""
+                          : block.description}
                       </span>
                     </div>
                     <div",fix
"build(platform): Include health router (#8362)

include health router","--- autogpt_platform/backend/backend/server/rest_api.py ---
@@ -267,6 +267,7 @@ def run_service(self):
         app.add_exception_handler(500, self.handle_internal_http_error)
 
         app.include_router(api_router)
+        app.include_router(health_router)
 
         uvicorn.run(
             app,",build
"fix(platform): UI fixes; Fix default value on input fields & fix enum custom fields (#8182)

* fix(platform): Fix default value on input fields & fix enum custom fields

* fix(platform): Fix default value on input fields & fix enum custom fields","--- autogpt_platform/backend/backend/blocks/llm.py ---
@@ -92,7 +92,12 @@ class Input(BlockSchema):
             description=""Expected format of the response. If provided, the response will be validated against this format. ""
             ""The keys should be the expected fields in the response, and the values should be the description of the field."",
         )
-        model: LlmModel = LlmModel.GPT4_TURBO
+        model: LlmModel = SchemaField(
+            title=""LLM Model"",
+            default=LlmModel.GPT4_TURBO,
+            description=""The language model to use for answering the prompt."",
+            advanced=False,
+        )
         api_key: BlockSecret = SecretField(value="""")
         sys_prompt: str = """"
         retry: int = 3
@@ -307,7 +312,12 @@ def parse_response(resp: str) -> tuple[dict[str, Any], str | None]:
 class AITextGeneratorBlock(Block):
     class Input(BlockSchema):
         prompt: str
-        model: LlmModel = LlmModel.GPT4_TURBO
+        model: LlmModel = SchemaField(
+            title=""LLM Model"",
+            default=LlmModel.GPT4_TURBO,
+            description=""The language model to use for answering the prompt."",
+            advanced=False,
+        )
         api_key: BlockSecret = SecretField(value="""")
         sys_prompt: str = """"
         retry: int = 3
@@ -355,7 +365,11 @@ def run(self, input_data: Input, **kwargs) -> BlockOutput:
 class AITextSummarizerBlock(Block):
     class Input(BlockSchema):
         text: str
-        model: LlmModel = LlmModel.GPT4_TURBO
+        model: LlmModel = SchemaField(
+            title=""LLM Model"",
+            default=LlmModel.GPT4_TURBO,
+            description=""The language model to use for summarizing the text."",
+        )
         api_key: BlockSecret = SecretField(value="""")
         # TODO: Make this dynamic
         max_tokens: int = 4000  # Adjust based on the model's context window
@@ -492,6 +506,7 @@ class Input(BlockSchema):
             description=""List of messages in the conversation."", min_length=1
         )
         model: LlmModel = SchemaField(
+            title=""LLM Model"",
             default=LlmModel.GPT4_TURBO,
             description=""The language model to use for the conversation."",
         )

--- autogpt_platform/frontend/src/components/node-input-components.tsx ---
@@ -49,7 +49,7 @@ const NodeObjectInputTree: FC<NodeObjectInputTreeProps> = ({
   className,
   displayName,
 }) => {
-  object ??= (""default"" in schema ? schema.default : null) ?? {};
+  object ||= (""default"" in schema ? schema.default : null) ?? {};
   return (
     <div className={cn(className, ""w-full flex-col"")}>
       {displayName && <strong>{displayName}</strong>}
@@ -105,7 +105,7 @@ export const NodeGenericInputField: FC<{
   className,
   displayName,
 }) => {
-  displayName ??= propSchema.title || beautifyString(propKey);
+  displayName ||= propSchema.title || beautifyString(propKey);
 
   if (""allOf"" in propSchema) {
     // If this happens, that is because Pydantic wraps $refs in an allOf if the
@@ -573,6 +573,7 @@ const NodeStringInput: FC<{
   className,
   displayName,
 }) => {
+  value ||= schema.default || """";
   return (
     <div className={className}>
       {schema.enum ? (
@@ -642,6 +643,7 @@ export const NodeTextBoxInput: FC<{
   className,
   displayName,
 }) => {
+  value ||= schema.default || """";
   return (
     <div className={className}>
       <div
@@ -686,8 +688,8 @@ const NodeNumberInput: FC<{
   className,
   displayName,
 }) => {
-  value ??= schema.default;
-  displayName ??= schema.title || beautifyString(selfKey);
+  value ||= schema.default;
+  displayName ||= schema.title || beautifyString(selfKey);
   return (
     <div className={className}>
       <div className=""nodrag flex items-center justify-between space-x-3"">
@@ -723,7 +725,7 @@ const NodeBooleanInput: FC<{
   className,
   displayName,
 }) => {
-  value ??= schema.default ?? false;
+  value ||= schema.default ?? false;
   return (
     <div className={className}>
       <div className=""nodrag flex items-center"">
@@ -757,6 +759,7 @@ const NodeFallbackInput: FC<{
   className,
   displayName,
 }) => {
+  value ||= (schema as BlockIOStringSubSchema)?.default;
   return (
     <NodeStringInput
       selfKey={selfKey}",fix
"chore(platform): Added latest claude version (#8397)

latest sonnet model","--- autogpt_platform/backend/backend/blocks/llm.py ---
@@ -62,7 +62,7 @@ class LlmModel(str, Enum, metaclass=LlmModelMeta):
     GPT4_TURBO = ""gpt-4-turbo""
     GPT3_5_TURBO = ""gpt-3.5-turbo""
     # Anthropic models
-    CLAUDE_3_5_SONNET = ""claude-3-5-sonnet-20240620""
+    CLAUDE_3_5_SONNET = ""claude-3-5-sonnet-latest""
     CLAUDE_3_HAIKU = ""claude-3-haiku-20240307""
     # Groq models
     LLAMA3_8B = ""llama3-8b-8192""",chore
"chore(secrets): Reseal new secrets (#8506)

resealed new secrets","--- autogpt_platform/infra/helm/autogpt-market/values.prod.yaml ---
@@ -93,7 +93,7 @@ env:
   BACKEND_CORS_ALLOW_ORIGINS: ""https://platform.agpt.co""
 
 secrets:
-  DATABASE_URL: ""AgB3onbSwBZQZxQPDejZr+tkrkj7cDwBGOjKsVSWmnvX9S665u7857SbfXDOLF+24f/mrujyaD0598Tg8coAOScbcWLv7CoM72GWokcgtdJJLSC08GAGiVgzIqeRYhdDgYvcKzLNAxbxKjOIQ2OHRONHyCddqt1niYTnuMKDyt3ExEA8il0qDA+HAST2kt+c29ic/nwsHWCCJs6wMB5LLA2le8ReiWO5jOpXiwjewf2ykT9YJbO3Ri6PzChrTvWwrt2J+6iRVAdLoD6uoSXxA3nhZkR06ko+xBCkH8gtJyQu8Z2RCXv3LoPMrBNye5XdD0Lw14aln2Yacp8jeunncBfMygA8UCNj9n7y26CWsFu8LSZbzg7Xtnb3NeyZTu6plzsQkh248jk5F1hL5b8J0fBqVs2tHHUEbVqBiR7xH7wmNEPXCe5/+CtMOaog+0mL3uRQd1wMbbsWgZtebgibI++po7+KjlQnFpJ0yP9YU9UQgEZh1IRSi/uUTtJqTuse6zj9slbSRntMSlcfNOX7+bhca7pRfuDS3r5hwQat7kIRjF0WAzDWxfWZ/6gwJO85OysLJy5Eo9gQcV0Nz2r2VGx0tVtYMFffh4V3GX9/mViDScIms8aBRwCFFmx+lwpEwUIqwnInAmkIPJ/UgEAdKDwCbV8/gbrQrFLnjyFUcP5dyzSU9S0AFffrun8Lb8qktJk=""
-  SUPABASE_JWT_SECRET: ""AgA7V2zXUt1vUA9mM6zbUMH/PTY3MfHZM14hd6jtbdqn1NCGw0IIxKFp58e+vOYNUiMzjN3P+b6nXGoxbv8jeO1/1K76n97ZeJPrAuZwKtdcddM5FHCpeLCuR/R9oqv0PHSbvBcwPEtMTtAns+LybmyMyWh1mv4RwbeCSJk0QL68VkRomiY9co2eZo0FO2EgWr0guoUtbd3mY9S0lMAZeggso9M8W4FIjHlsAi2XEDWQrRuyM5l/c7g8oEBytBWK/aI6WzfyvE5XkdsnwdqkvdHnqGkMeuSKQlym162JJ1gr9FPOIIUVVo9dVLy4FJWkAi6/D9wbsqkWyHuc8Bzq25hA7OwiuMZ/QlN9Pd3MqxUMgPwSwUY8ZUi/Isp6jmEbYMg/riUbvYXrFkLAZIiuKAzdaH+tyayaXW2FLbDWCJk+pv9ZF2PIptv65MZuii4KOoC7JE5+t6iOMtJ4yDqkbPD45jOky8njN90RlKID192LmAFjGzqWix+KVrOhWTXNV6LeHf1AfuuOU5rn2c7ayve/LDzgLuOzx/0zVBsBVfWtvZrFWmOJi2X4Ivz7pktyDrHynMSlid2J9UQe2JHRLCNLNSpLATN623K8g0rbHCKs3DfSAXdfXZsC/ArXejAJssyPc6NKfD1/aHFl2TXioLq9hJ/+SbiBEJ28UWXL61asLpz4gZCwlSZkf/eeXSnW7Ig27YQYSWVjBm2fKijgXjqF1xQT6hcsH7Wkk/dEfnGILSeGc92kyMHlLZd1lAkjBTuU/jVNGsmc6fXt3RsR7anczuDgPjVYVJZAmP8fyAGecQfeIArGYwBI""
+  DATABASE_URL: ""AgCUKDIUv1z6KWRBX+sSfokUYFPZPMurFMcvVG4GKHPtV9ckIZ7tV2S+FxdQcXNnUQeuqQ7lSpaxOp6fnzC2ou9A+mHHstiEl0u9QrrL1gyOF3AsEnEd+TpXTZ3gOq4v6vmEqErNShrm1AiZy5qKQi50JoUUZNh9brM2MmtlSZU58BWxLTjMaEHttPsdQWz3mlumJchRxJzr9xnzVZWwp3Llq2hTGOdwa2UNljd9h11m547/fT2d7o3vqP/Sju+h6SEUB83EHP2Ncjxf9rhVn5KXboxvOSbKXxa8eu5eE87D1tlrCCvnoDV5hh8h+W4EboFwUffJZDD9+VPK5nIJuCZ5k9y/+9peQfOCvQ8LJaNxKxzBfGXxsb9PmYJrdN3KAbE5ZmhjuABvuMcPMdJRxGdwUCNCyw5XpiEQRD0vSSEXuZKOv3Oy0a6mOzcNf2a5QhAqAM98WazaCjg4gmVQ4ZKDUYzjsURpGavb/piBo5pDZHrwWjCilsjJqTFlPTFi39ppVtXitfncYCUPYVts/kNrWa9//4sj9ZKIKUsLzCB8X1B6pA7cG/9u0n61Kllmp7naWM2W9Jq0b7DB8FvihcyMsOPxfyeX66OzTFypat3+cY4JcLr4rx6DPk4hZyHfFnJZdfeSl/MePPkjLTS1aBLZ+sCNaPGWKaEJ97zZSEvm54V2AH5EuLJqSx3EUotpLok=""
+  SUPABASE_JWT_SECRET: ""AgAYMdZyP+UhxIdTx6qyRzq9xf1dT7S+DFEC8KSPEFydX9+hAdJVTpprOlgLnqSbfSDmbqcFnCH+aK/6rdRx3HI3v41FogyCNFFxTrfxq1Esk8VuaVh8XrO2xKPd4iGBPZaTrenKlgt89aGdjPJzgl+NlZ5+/BXd95P2uX39DDGr9GJdO14zBt69O+L+Yt7kdd3ZMBjWYibZAzf+YaNIx/M7jjzGLYvxtywMVTrR+6e6GkGQSt5CzBpgk1b6ugPVtFs7PqmMtUqXMQjlrW2u7WVZRWeXO93ukc/TtjO2XUY9JfrgibMf0H81NDDTAAQBNqaDk0LdXsPUo9QGnyeQZTsfAOaeM6lTxX9qCYjneN6pxe60U1BKLURpordRdBs3peAedNJ95GC75qcdSkZE2agjwJvXKs8yy2Ig5eiU/80W27IWPMSLWhMSSf4ixyfkNWM4EfWL45bXlVGvtYaeyqByb0QU1g+II3AukIyO1qOS572y0sGseEv/UlfU2NDBLFejeBZaz4s/20lSyLhP3v1Y9aTs8qWIGl67syFKZoCwPRxwip2v7wIDnlDYXtlxMpQUWDnSUX16zQiVALD3izeDYkd1RViBgdYT/G0tp6lBeV1vnF8tBEGWIl3GJFV0okUflAQ9NIrdC5+BlcQDD08Jn0oGjyje7KE/BfvB1lHT7K+h9rr8B/U8zBSaAe+KFjA8pcjHqXgi4Zx3ayTXdAddyFZd0YqONohEAvXB+BLLdYJVNNXjBFwY62XQ6ojD2ZYWz4m/Wo+/zG0Zm5s/v2VS8UT5qe2Wjs3oGHKIJc6Eo3hVwLefcb7V""
   SENTRY_DSN: ""AgA+X2HkF9b3+p13JS4vG7VY+8p7su6qJ7smoPKqYh44Vpb7J5Eu9ksPNQkcFTDDPT8jAylqsHWUdI0A8u20+a4lqqGkmPN5tCgyBgAL1pIyvPUQjYUbL7A5lTQKlRLJJ+05h5XbkRU7cWR+G4yDUCDj2HcThne0CNDUbDao9D67ekSLUtp6/d0KO45Efao4MLuqISnypPUBGHmAdWGr2z/w7ItXjvUKt3RpH6pSCrGzjlKPKhenKdTsk/NX4Z+ew/JBbHiDQjKCdj0UlXFWH7Q4axaFy0T8tsqf/UN7n/QTalYE+v28isxrHvoR6h7kZETQV/gl0y7DdmTCi8/A1j1+e/9zUx6HvK+C/qGMsKMdNgaaVNSdfFp/yfMgXTUn4HGAls4gjVKSSRaIAbBq32NdKkIvRfocuAGsxInwbrDXLR0nzbHG/U/QhlvfL2gfqKRIVRJtEh99VW/KMMeXZUWR9dNt9gfTMtyzL7eta4oEV+g7sdO/9VjDn5wtic2/7eAxgA7wTEoDA8m0whpHH4VcPLHUfKLTHnRXVu6bykAfBgfEKhJBS8DghvPyu73qL5MREuYkGya4n0RQ73h5ja7mYwI0lsefQszP9Fz1lR+757dhJ6+/E7nNnOE/ShD/8xE0V54pd2IvrRoJmcOsIOZ5w+xWfmN8OyLn7wuEpqEuMHEoisLF9RSp2V5iKbB+fFB4o5P1/VqkNPEFBe0jA4K8DAGX+VdChMpjAI47wF22aj+jmTRf+EY+5l+aEvjyU0G7oUPVzzG8rYa6p+v56zeVsmU4SHIDO75J1cH7tnYDeOxk9fAYZgNplS4gKHVT0w==""
-  SUPABASE_SERVICE_ROLE_KEY: ""AgBITjBe8qd40clk/T4awlY+lBhWoVJTvdtzUFfD4UlbBd0fjxNKm457Dva2mKej69Lxn/tY/5MaGvZHNUA5LVQuHKzIY5XKdRus8awdyKWXZy5Wlvf2l943YbEGN6nNB7pzRdgcItcyHN5hHlSq5Ney0pfTaApsTZrxsFyGeW/bc8TKfM5+oW3zQDbBPXrnwv1GjG2T90Zx/cvahBNUG07fR53tCTiqQAsRfyU9DGWp/zZbe+3hcC3562imbEu+er6RUiwp/upCapndR5R2U0Vksv+q+N6wipWUObnH4A33lVk+JhpGpS3N0h1TE7JNSgLJuuDAqw6gq4w0SLmE9VdEWacOnJxVI2d3RsJNfqkUg9R+/pFBW67HV0aknUQxXnfDSNK+BAMMUDel4diLLMyNzGbrxbp1IRfB2hOr3ILKudIzniMjLJ2Veq0/xM8wwfNx2BXaUbHcXdOv9Kw05egTjGa3BGZAlMHvAY40V9iO9P/jys0ny+fd6xuwoHGA5UW+wNx9jR1iYwxQiTTRtDDHMvALycu2VCbDCx43QVZxB8dSq42vpt2/T3YoOhaxNF2GJ9mBWTRPnN0oFeTBQYhopN8VylY1HhsR3T/tdrkIkC6PiRCbyzp/zDq+kY5GkHEBCZyxYyO/n9/0vB8iQpLBEfQUpTkVJjdESqkbp9eQwxr/Jl5xfEAJbAiHW1FRFpobaPKrHhYF7Ggxm7DfLeCY84ieWIss9OenEhYJF3MImlxWkzY58dI734E2Rt1u45llOq3JsZe/uWIJgVcFq1YLEv/eG1Ll8+ZmcOulsfywN8dANRvf5uTvsKX20fzwpdAjZlbiq7Rre9Rwwl+7SkBKBI1TfZHV4V10U30rG2p0FUf7J33Xmmf4W3DGlszaJWSbIlMxQZno+/QEKbb5Ani9AJTPYXJ6xqiQsRReT5dPgbjGtdVKW9X+O9xrORNRc65gAayfVEobFljcWbrjSK/myPG8tMHyjtjBDr8=""
\ No newline at end of file
+  SUPABASE_SERVICE_ROLE_KEY: ""AgCADpjXfdpTDruyK2F4GRNT/Kl+yaI87mQdXDHQo3jOC3gWoOiRlXg70JG3jIi2cWjAXwU8ySjpT87aJdRwsMToeMD78zr0FbOSB2abx7OPTij8zWFSzhIo4cLoEkvLxZO9HXwQc959Cxh5oBcn6WBhJ5XMUxNWALIem9+Lb5Eu1CwxSF0EDrl3znx3Iqw/zUqnAgS+Ob4AAiJwXNO641ja7dAKYkb2NJ/KCBgmSXAaPfxQByuNkGP4iwmQuxhhJQ/N+LRVCu03J6NLPVw22feKKtZxAAroMDn5wPhRdmzBawqbRsejiCb0JNL2yd574CDN5xzsDur/RYkCpTrMWzgnN3F1VcYMuB9FwYazKU3XqviOYtP8Ca4sUQChHQEOFP8n3Nt0Z17zo1NtgRt8IBpXpDeZFgDZU6Zy8EtpHHn05KT8YqyLDms2LfJhduiuyndbZgeIfr7IcxbU4aBafh+J/tfN7Tlj5NFYxFImKQ0NFg5z6W9zKKkfFMo9WUcOOXgwg8+g6xeZUX9g3rNpMBNf2bt0UfNqSIBeAmUZVKHuEqneFONbgtqOP2NKsKsSfvCsnpKgAndv+eL627qWAuDzywWuoAcxsF/Kvo/fQnv1a+7abCr1Qhf61u3DBriGp6TAVhQ9z7iGqvkuviELt97NKekeevCgdjwWpk78iKBCmxJobBTErdX2Xhrqfc5AHteoUBYv3TS7N8ZcOmfVmZc2ulgLLQZZ5hK30w9FFu28bu01ArfKcSp3U21keaC/cGHBNdUWgAbg3wIH+3y3vU2MRHI6T6sFrRsNgJH6b8S+HcOInTsoaLFiRv7SYxGYliV47AEukv4G2G+9XO4i4y9P90u5i7KM+J5FRlR6sfiISPozGHUBe9EAKYQcqaSSGP7FWsyNl6DGq/pDkG8IJYqNr21Sl9N1cdhK/Hdd4J80q05A9f3AyzHjtU4YVcvz4TCKr1FJLugBUsz120cA8FxGXweIQRWCzGvSeGA=""
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-server/values.prod.yaml ---
@@ -119,8 +119,8 @@ secrets:
   REVID_API_KEY: ""AgBPAmDtdzfHMbudluOeUZS7RCixfJXaI6vBvEUPQhhtpbNW9sUfDv6waKzBdjgWxIf2EqI4QI7QUVqHxA7fMChSjZjt9Np9z6+nHZhKWTqCCKyVR4Lka8tnkU5M62e+x+T7QoHy6mKsB7FEyQ8/FPxUM/Ddp5ZPTj6sbLn3y2uv1SPxInbd6boXeLEwQQcN/Inrww/lzNzJPec4jlHNwPHugjhZJnlWotvyfhU33Fdt5IEusdqt6CM0vS5N7lkR8KTNAg56VLD89yXVRR2VOtkJWzaQJ4lNSztBgUFNGaYtl7SRNVYnMpT1jhyTcAeO/fAGP4O/8haTlAZbfSsOLub5Af9CIA5vtNpU4zoY0Q2MOtKOJ5OTtbbJxmlWex3zc2wpIwdTLCRyBHxiPphdSBXQPW12s9NX6GVR7WDc3Lcvhi0P4uo+y01kyL64JGRigjvBzCYCqhNGWMtJ+YOy4pwcE89Qaz2/EvHgh37P9O7TQhN3Vo8BGRV0+DlNe6uv3OBitgayub5M34nh+qnNHypErkm29SovnqY1fEFhdOib2nmnE2fEXylZMtMPonBVYtVX9iOJLERQMNOzwDxaKzwPdpNu4GhMNVG6joCDjDqKPp9BfnKDJsn0GgUt3oDl5kRWdYL75HLDa3LDWGj0UiAF1YeQE2SHJjlrIoAVJWDdjwTsFJ1x3sMZTt9gB8KiUIDK/hgt7to/kaIyBUTrQIUv/2hHNYI4KH5/nNFZu3TPJXNrxfU=""
   ANTHROPIC_API_KEY: ""AgB+40jZoawJ6HaeyyLZvDp2ByF4EPy2Ce806D/lekwJVmxpYXgkQdLJyav6bt9c1g5eDShJqezx1T+jGV+ApQbhSwmO403nJdYO825Fd3XVJ5K0xfFNt8DOTC9r2egWFvJZL40s/Y24kpr2Mmsqp+Sk9DxMNdYG/Z4PnT8PLWgb3yIYGGPVjlWlHL82gn4/B1bVTk14/cGXX9eSr0ktKKmS2OGLMYUwLT3oYGy4bRq9bH91XwjjdW6vMluNBGYibpi2f4h3nYORaQn42OhzTqON3XUdvNmsw1ZH0raMAJq47SU0lC6Ar9MzwbtUWY3tF6BlTmyx3gPavjQCnXg5cRxmY8JklrynDoyN+SBludzaWDzdAjr4vGPpkOo56RBY+28tnNjmxgyttGIYfFa8DEsrrJJgZZxSUvRqwJc0TWIKRFP1aIHkQ5DclUilFtNfPMezxwcFqrsYTEvtDjsls/E8uTNUN99cVQ2x0PxDsLKr9xVKAKkzzOBEvKEAJy0t5RtRV9A6kc0b16YbjIkFphip4e7HJTWKRvavknw+MXjGXXQrz9+xp8LrjRcgCyZp3BqSo+gsX8KQJSnhiFfKvgt7RdVaUVUA+sn5fIQGPWA5IkbI4gS12BRFDw59+Doc5FbCGUip4jDL8I2bPuNKQZLmSMx93Nu/60WBRhKXYz+GNzLzvhk0IpEI3d2GeWvC61p/f5eKnsLKNLDrc3k8rFHiUmXXhB+oQXMRSUFqq4hen32VVPWRhzT8nefww5Tud21CBg5+87x6WHOnB/A4vw+VuKD3fdeo9tn4HlD3w2funOVu9yv+NaP+MTeHus2PBeab/OtKLH09ezxnhmA=""
   OPENAI_API_KEY: ""AgAjPjhje52qw5YSXjRAwoXU0WyDEIAHnz2CjFtSjkpbsvvXFPlPMlOd/y7/dvABoyZHB9Ukxjna6opqV/hK/vHR9ncp9i7cDYX3Rekj+mkA6arMdqdJ0eikAGqWYPieu8RcBn6pHFGmoC8ZZPgk6Eh3Wyi4OCaPfH/O1bTq/RBQU5VDFvYfaeDZmYIu6SkD88pI0lT12Dklk1apsHlS+g3/rpQwDXgemE/pdmcNnt1zS6Ifu4isN7yg1pg1Thja+UiQnEkIiZkvmD39LO8HrwOFt8guJctRZ5gnVxPmSEdJLN089/fj5VXxTO1kTprbh1KeG9RKYS5LEPNYpgcl9/o884qMc/r0/+Cy7gL5R1THrEPHurVg8JfssCq8k0SaEtCElQ2081Scc/0p/k4URpXrsxUKZ8XUTIvYS0y2mEJPAAqaHAkwthY8sizhOwqWWnt8dGbCPwfQ11TiNSMikKIim9Bwm4tKM9aEolROSkivbGqFQQYSkensyp2mTqx7iFYlGBa7Z7PFRBZgPzD2FojWc6o5tLui5Xgi67ukO5WeaBhO6eMd2CuIlXqu+5x3+ixIytp9Jpke4mZKwbjYai4j3iELbzEwbGkjsnDyWNYn+1KnPOogd6i5+YPn09FbQO2Qvg2t3yUP/ePeX+fdRYk7AnS/o6nllqj9GLas48JFUlEx+KSO4qwrflRqPUmfmD3wPDTYR2q6yJzdatLYzdRQxEctFhgvco63uhW1YH+1ei1YuxutYPkIOqUwbgfIC3XiW7Tr3R8Gd3TimJLQM1etR6dwrEaEm0jTCIKUoZ+65OIAeVtcXIwWtwRjjUOtR8k9B2UdFoJOgtfIFzlxwYj4xUJrzRkCLdFD1W362n2+O5n7QdXDjYXn9KmxVUEph2vloeS8IGrBjM/l743A3trFD4CZ9g==""
-  DATABASE_URL: ""AgBI8TcJnE7HOjLdcc4czgwE8E2ejDKoQNHXdciXkqRxdNomu663xb5GnHaXybJ3/HjnA+48eZs1enXvedLe521s7Gs+f8JHC7KZ+EE62JqtP8OvKX86D2/GPgDlCMYmkSEkbYWHTCRdIUB2xAyl+5Hs3/srQJqNwWtL25NwkiGimIBCkSdRqql1MtHLOXg9McevVF+Le0NCOpqOh1WV3+Fk/8Y/HnUNQmhiyg81rvu03ce5zSSpQlCkZFCCE+hw/vyS/GlW/PZIaIXTqcp2O2G15hmG8vxQtM5wSEJPIAps1VLw6ZBIPZOayuq74hWeNJiQ7LkHAO8A9b0oA8v3xb3nOGirP3hf3sjKyzLGW8Hp0YHxMrwAgbA2zxH5Y1+LK/zlhbR9iVC0eZ99j+UFCa6GpJQighEx8KN30sM3tHwaFNfdb0uo/mQ3YBusxNmF5IpHy46g2Hmd0Evc99L+ABeKqVWdRulfPtK79l+SfrMDWMTZp3s6576RnxzVrmck8VWKZsdqy/L5xHBK0BDLFv5YmejIjvCTDJZRYGAHXaisQLO1Dwg39QMnrnUeiGO9hQkY87mXZu5jJeRV10+dI6VVx+W9G66KbHfb6M/Nb+KO0HWh6WWc7ZYDNAerpfAISHWMdSblUDay6+MEV9aTjrj1n8TRdYDKNR+5E4Oa3o3ufYi5vqayblqjoEYsBDiSAoo=""
-  SUPABASE_JWT_SECRET: ""AgA7V2zXUt1vUA9mM6zbUMH/PTY3MfHZM14hd6jtbdqn1NCGw0IIxKFp58e+vOYNUiMzjN3P+b6nXGoxbv8jeO1/1K76n97ZeJPrAuZwKtdcddM5FHCpeLCuR/R9oqv0PHSbvBcwPEtMTtAns+LybmyMyWh1mv4RwbeCSJk0QL68VkRomiY9co2eZo0FO2EgWr0guoUtbd3mY9S0lMAZeggso9M8W4FIjHlsAi2XEDWQrRuyM5l/c7g8oEBytBWK/aI6WzfyvE5XkdsnwdqkvdHnqGkMeuSKQlym162JJ1gr9FPOIIUVVo9dVLy4FJWkAi6/D9wbsqkWyHuc8Bzq25hA7OwiuMZ/QlN9Pd3MqxUMgPwSwUY8ZUi/Isp6jmEbYMg/riUbvYXrFkLAZIiuKAzdaH+tyayaXW2FLbDWCJk+pv9ZF2PIptv65MZuii4KOoC7JE5+t6iOMtJ4yDqkbPD45jOky8njN90RlKID192LmAFjGzqWix+KVrOhWTXNV6LeHf1AfuuOU5rn2c7ayve/LDzgLuOzx/0zVBsBVfWtvZrFWmOJi2X4Ivz7pktyDrHynMSlid2J9UQe2JHRLCNLNSpLATN623K8g0rbHCKs3DfSAXdfXZsC/ArXejAJssyPc6NKfD1/aHFl2TXioLq9hJ/+SbiBEJ28UWXL61asLpz4gZCwlSZkf/eeXSnW7Ig27YQYSWVjBm2fKijgXjqF1xQT6hcsH7Wkk/dEfnGILSeGc92kyMHlLZd1lAkjBTuU/jVNGsmc6fXt3RsR7anczuDgPjVYVJZAmP8fyAGecQfeIArGYwBI""
+  DATABASE_URL: ""AgAfP8iiQGaA68dGVHQuHiKXldqhWungOlLEy6kg6nkKIY6LAwwUJbF59SrsbJ6Lvaq+40XiPSEV6ZjC1JpDyNQyPYzS6hUO9Ev82ViQ2H4Ba62jehBjXufVhabGurHe+F/WsyrXAEY496yX8I3/voy92bR+r0z66jRKHPwI+OXP2CyvdfIz6ziGwInkdfGdP0WRopvmSzbr/atUc1MGVBGuCvNguYWQ3WUwiF38EPObsoYpgV8fuD4trrFE2imHRs23AXMK/ntkqAjZwVWXfZNwaFECT9y1ue04rjDhuoFsL6lhvsK9Xf07mrTzBjdjJl0eCCTxsm0kZTTCwsPSq6H+6w8bjH33M1qeEnORwMuthFy4p0r3e+qlWbhHHwR6ku9wiwzCavDTd27EEfMKkD3zG7NrnbYA4zelHfG2q3/1/PZCeAOsa5jo0EuMTJr4p1Z6deKS4wevzOqJ/FcU1/5T24aKdxhVMnVrF9HKCLKHD+lJLJE8XgdZLFeded234nQfc9MGoBCD6FJvgfJCrjQh8QCSpm1aBKgu795Esff3ZqXJFiq7YCTQTOv/P6RXR5XA/LEqq1m5pcyBDzKixILE1SEbNdeXbYNhe7SbobKpQ9gq3f2ssCRNZGMgJtde6TQFx7J76IE4Eu9oqZefNQxHvh9lH2l0bROWy5NYKHfAejXnVGxIEVnoyRvyFB/HMOc=""
+  SUPABASE_JWT_SECRET: ""AgAYMdZyP+UhxIdTx6qyRzq9xf1dT7S+DFEC8KSPEFydX9+hAdJVTpprOlgLnqSbfSDmbqcFnCH+aK/6rdRx3HI3v41FogyCNFFxTrfxq1Esk8VuaVh8XrO2xKPd4iGBPZaTrenKlgt89aGdjPJzgl+NlZ5+/BXd95P2uX39DDGr9GJdO14zBt69O+L+Yt7kdd3ZMBjWYibZAzf+YaNIx/M7jjzGLYvxtywMVTrR+6e6GkGQSt5CzBpgk1b6ugPVtFs7PqmMtUqXMQjlrW2u7WVZRWeXO93ukc/TtjO2XUY9JfrgibMf0H81NDDTAAQBNqaDk0LdXsPUo9QGnyeQZTsfAOaeM6lTxX9qCYjneN6pxe60U1BKLURpordRdBs3peAedNJ95GC75qcdSkZE2agjwJvXKs8yy2Ig5eiU/80W27IWPMSLWhMSSf4ixyfkNWM4EfWL45bXlVGvtYaeyqByb0QU1g+II3AukIyO1qOS572y0sGseEv/UlfU2NDBLFejeBZaz4s/20lSyLhP3v1Y9aTs8qWIGl67syFKZoCwPRxwip2v7wIDnlDYXtlxMpQUWDnSUX16zQiVALD3izeDYkd1RViBgdYT/G0tp6lBeV1vnF8tBEGWIl3GJFV0okUflAQ9NIrdC5+BlcQDD08Jn0oGjyje7KE/BfvB1lHT7K+h9rr8B/U8zBSaAe+KFjA8pcjHqXgi4Zx3ayTXdAddyFZd0YqONohEAvXB+BLLdYJVNNXjBFwY62XQ6ojD2ZYWz4m/Wo+/zG0Zm5s/v2VS8UT5qe2Wjs3oGHKIJc6Eo3hVwLefcb7V""
   SENTRY_DSN: ""AgA+X2HkF9b3+p13JS4vG7VY+8p7su6qJ7smoPKqYh44Vpb7J5Eu9ksPNQkcFTDDPT8jAylqsHWUdI0A8u20+a4lqqGkmPN5tCgyBgAL1pIyvPUQjYUbL7A5lTQKlRLJJ+05h5XbkRU7cWR+G4yDUCDj2HcThne0CNDUbDao9D67ekSLUtp6/d0KO45Efao4MLuqISnypPUBGHmAdWGr2z/w7ItXjvUKt3RpH6pSCrGzjlKPKhenKdTsk/NX4Z+ew/JBbHiDQjKCdj0UlXFWH7Q4axaFy0T8tsqf/UN7n/QTalYE+v28isxrHvoR6h7kZETQV/gl0y7DdmTCi8/A1j1+e/9zUx6HvK+C/qGMsKMdNgaaVNSdfFp/yfMgXTUn4HGAls4gjVKSSRaIAbBq32NdKkIvRfocuAGsxInwbrDXLR0nzbHG/U/QhlvfL2gfqKRIVRJtEh99VW/KMMeXZUWR9dNt9gfTMtyzL7eta4oEV+g7sdO/9VjDn5wtic2/7eAxgA7wTEoDA8m0whpHH4VcPLHUfKLTHnRXVu6bykAfBgfEKhJBS8DghvPyu73qL5MREuYkGya4n0RQ73h5ja7mYwI0lsefQszP9Fz1lR+757dhJ6+/E7nNnOE/ShD/8xE0V54pd2IvrRoJmcOsIOZ5w+xWfmN8OyLn7wuEpqEuMHEoisLF9RSp2V5iKbB+fFB4o5P1/VqkNPEFBe0jA4K8DAGX+VdChMpjAI47wF22aj+jmTRf+EY+5l+aEvjyU0G7oUPVzzG8rYa6p+v56zeVsmU4SHIDO75J1cH7tnYDeOxk9fAYZgNplS4gKHVT0w==""
-  SUPABASE_SERVICE_ROLE_KEY: ""AgBITjBe8qd40clk/T4awlY+lBhWoVJTvdtzUFfD4UlbBd0fjxNKm457Dva2mKej69Lxn/tY/5MaGvZHNUA5LVQuHKzIY5XKdRus8awdyKWXZy5Wlvf2l943YbEGN6nNB7pzRdgcItcyHN5hHlSq5Ney0pfTaApsTZrxsFyGeW/bc8TKfM5+oW3zQDbBPXrnwv1GjG2T90Zx/cvahBNUG07fR53tCTiqQAsRfyU9DGWp/zZbe+3hcC3562imbEu+er6RUiwp/upCapndR5R2U0Vksv+q+N6wipWUObnH4A33lVk+JhpGpS3N0h1TE7JNSgLJuuDAqw6gq4w0SLmE9VdEWacOnJxVI2d3RsJNfqkUg9R+/pFBW67HV0aknUQxXnfDSNK+BAMMUDel4diLLMyNzGbrxbp1IRfB2hOr3ILKudIzniMjLJ2Veq0/xM8wwfNx2BXaUbHcXdOv9Kw05egTjGa3BGZAlMHvAY40V9iO9P/jys0ny+fd6xuwoHGA5UW+wNx9jR1iYwxQiTTRtDDHMvALycu2VCbDCx43QVZxB8dSq42vpt2/T3YoOhaxNF2GJ9mBWTRPnN0oFeTBQYhopN8VylY1HhsR3T/tdrkIkC6PiRCbyzp/zDq+kY5GkHEBCZyxYyO/n9/0vB8iQpLBEfQUpTkVJjdESqkbp9eQwxr/Jl5xfEAJbAiHW1FRFpobaPKrHhYF7Ggxm7DfLeCY84ieWIss9OenEhYJF3MImlxWkzY58dI734E2Rt1u45llOq3JsZe/uWIJgVcFq1YLEv/eG1Ll8+ZmcOulsfywN8dANRvf5uTvsKX20fzwpdAjZlbiq7Rre9Rwwl+7SkBKBI1TfZHV4V10U30rG2p0FUf7J33Xmmf4W3DGlszaJWSbIlMxQZno+/QEKbb5Ani9AJTPYXJ6xqiQsRReT5dPgbjGtdVKW9X+O9xrORNRc65gAayfVEobFljcWbrjSK/myPG8tMHyjtjBDr8=""
+  SUPABASE_SERVICE_ROLE_KEY: ""AgCADpjXfdpTDruyK2F4GRNT/Kl+yaI87mQdXDHQo3jOC3gWoOiRlXg70JG3jIi2cWjAXwU8ySjpT87aJdRwsMToeMD78zr0FbOSB2abx7OPTij8zWFSzhIo4cLoEkvLxZO9HXwQc959Cxh5oBcn6WBhJ5XMUxNWALIem9+Lb5Eu1CwxSF0EDrl3znx3Iqw/zUqnAgS+Ob4AAiJwXNO641ja7dAKYkb2NJ/KCBgmSXAaPfxQByuNkGP4iwmQuxhhJQ/N+LRVCu03J6NLPVw22feKKtZxAAroMDn5wPhRdmzBawqbRsejiCb0JNL2yd574CDN5xzsDur/RYkCpTrMWzgnN3F1VcYMuB9FwYazKU3XqviOYtP8Ca4sUQChHQEOFP8n3Nt0Z17zo1NtgRt8IBpXpDeZFgDZU6Zy8EtpHHn05KT8YqyLDms2LfJhduiuyndbZgeIfr7IcxbU4aBafh+J/tfN7Tlj5NFYxFImKQ0NFg5z6W9zKKkfFMo9WUcOOXgwg8+g6xeZUX9g3rNpMBNf2bt0UfNqSIBeAmUZVKHuEqneFONbgtqOP2NKsKsSfvCsnpKgAndv+eL627qWAuDzywWuoAcxsF/Kvo/fQnv1a+7abCr1Qhf61u3DBriGp6TAVhQ9z7iGqvkuviELt97NKekeevCgdjwWpk78iKBCmxJobBTErdX2Xhrqfc5AHteoUBYv3TS7N8ZcOmfVmZc2ulgLLQZZ5hK30w9FFu28bu01ArfKcSp3U21keaC/cGHBNdUWgAbg3wIH+3y3vU2MRHI6T6sFrRsNgJH6b8S+HcOInTsoaLFiRv7SYxGYliV47AEukv4G2G+9XO4i4y9P90u5i7KM+J5FRlR6sfiISPozGHUBe9EAKYQcqaSSGP7FWsyNl6DGq/pDkG8IJYqNr21Sl9N1cdhK/Hdd4J80q05A9f3AyzHjtU4YVcvz4TCKr1FJLugBUsz120cA8FxGXweIQRWCzGvSeGA=""
   REDIS_PASSWORD: ""AgB7eiUuFQO88vVMI28xfmJsA2QzEb71r3NyDJ/KTNsjqn7ai1KpjVaaTDyr4Xzo1wOhwwwxlhIoeBwf26wPiraJtkjRU9z9Aotvy0u8SXFm05ObhMjJoY2dBvW6ga3KNaunWoTx5e6NbYPGRIgNtRBVN4PH5Lf7Ou5SZBjJBaVWgIT1x71tB2eD2XksOw2mrfaF0WODsQxXDOaF9BJ4Gn7yIT0Nh76Okn9uhesQxvojaqlAIeAKXyrZJwAH5qL3D772rYsISmbHC0bCBgx4dbbtvsr4YgiR387ri7KGfrEqoFH/jzUp5cwsJNyBpWG1n2O0QXYgbMIsmJP6rdD+KTZkLGBz0wgq/JySCZM9hj54dYtLE7LMmpZn7//EKZk7zsV1u9oSciQisWcJqW8El+IMOAZilqSR2NjpI4cb0xR7/gTLLQF33+wnZwbbHghbDwTowkzOZ0i7qt73YkR8MKrlLhLcCGHjhyb50xr1DJl9mVUoyHXvFOj2tQO/273sMNdKpJvNFi9EEhdirzbcuphnaRm5xXYF1CHKtXUp6EvdxgHqEuoGwh5Kt8dtGMJfSJ40LsARZXCFU7CC6g/faPq93K5QB/bwlOdABeOVF/odqXZQAADX3TQwIPMH36XuqwNggWQ8Igy5o1d3Hi84jVChmjid/Wk8DREmkntzDy+4Jxzqx1rPSThyoOvopirY8VA=""
\ No newline at end of file",chore
feat(platform): Add Graph Execution error data & status (#8250),"--- autogpt_platform/backend/backend/data/execution.py ---
@@ -268,10 +268,29 @@ async def update_graph_execution_start_time(graph_exec_id: str):
     )
 
 
-async def update_graph_execution_stats(graph_exec_id: str, stats: dict[str, Any]):
+async def update_graph_execution_stats(
+    graph_exec_id: str,
+    error: Exception | None,
+    wall_time: float,
+    cpu_time: float,
+    node_count: int,
+):
+    status = ExecutionStatus.FAILED if error else ExecutionStatus.COMPLETED
+    stats = (
+        {
+            ""walltime"": wall_time,
+            ""cputime"": cpu_time,
+            ""nodecount"": node_count,
+            ""error"": str(error) if error else None,
+        },
+    )
+
     await AgentGraphExecution.prisma().update(
         where={""id"": graph_exec_id},
-        data={""executionStatus"": ExecutionStatus.COMPLETED, ""stats"": json.dumps(stats)},
+        data={
+            ""executionStatus"": status,
+            ""stats"": json.dumps(stats),
+        },
     )
 
 

--- autogpt_platform/backend/backend/executor/manager.py ---
@@ -561,18 +561,17 @@ def on_graph_execution(cls, graph_exec: GraphExecution, cancel: threading.Event)
             node_eid=""*"",
             block_name=""-"",
         )
-        timing_info, node_count = cls._on_graph_execution(
+        timing_info, (node_count, error) = cls._on_graph_execution(
             graph_exec, cancel, log_metadata
         )
 
         cls.loop.run_until_complete(
             update_graph_execution_stats(
-                graph_exec.graph_exec_id,
-                {
-                    ""walltime"": timing_info.wall_time,
-                    ""cputime"": timing_info.cpu_time,
-                    ""nodecount"": node_count,
-                },
+                graph_exec_id=graph_exec.graph_exec_id,
+                error=error,
+                wall_time=timing_info.wall_time,
+                cpu_time=timing_info.cpu_time,
+                node_count=node_count,
             )
         )
 
@@ -583,9 +582,15 @@ def _on_graph_execution(
         graph_exec: GraphExecution,
         cancel: threading.Event,
         log_metadata: LogMetadata,
-    ) -> int:
+    ) -> tuple[int, Exception | None]:
+        """"""
+        Returns:
+            The number of node executions completed.
+            The error that occurred during the execution.
+        """"""
         log_metadata.info(f""Start graph execution {graph_exec.graph_exec_id}"")
         n_node_executions = 0
+        error = None
         finished = False
 
         def cancel_handler():
@@ -619,7 +624,8 @@ def callback(_):
 
             while not queue.empty():
                 if cancel.is_set():
-                    return n_node_executions
+                    error = RuntimeError(""Execution is cancelled"")
+                    return n_node_executions, error
 
                 exec_data = queue.get()
 
@@ -653,7 +659,8 @@ def callback(_):
                     )
                     for node_id, execution in list(running_executions.items()):
                         if cancel.is_set():
-                            return n_node_executions
+                            error = RuntimeError(""Execution is cancelled"")
+                            return n_node_executions, error
 
                         if not queue.empty():
                             break  # yield to parent loop to execute new queue items
@@ -666,12 +673,13 @@ def callback(_):
             log_metadata.exception(
                 f""Failed graph execution {graph_exec.graph_exec_id}: {e}""
             )
+            error = e
         finally:
             if not cancel.is_set():
                 finished = True
                 cancel.set()
             cancel_thread.join()
-            return n_node_executions
+            return n_node_executions, error
 
 
 class ExecutionManager(AppService):",feat
"build(deps): bump actions/cache from 2 to 4 (#8467)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- .github/workflows/platform-autgpt-deploy-prod.yml ---
@@ -78,7 +78,7 @@ jobs:
       uses: docker/setup-buildx-action@v3
 
     - name: Cache Docker layers
-      uses: actions/cache@v2
+      uses: actions/cache@v4
       with:
         path: /tmp/.buildx-cache
         key: ${{ runner.os }}-buildx-${{ github.sha }}

--- .github/workflows/platform-autogpt-deploy.yaml ---
@@ -82,7 +82,7 @@ jobs:
       uses: docker/setup-buildx-action@v3
 
     - name: Cache Docker layers
-      uses: actions/cache@v2
+      uses: actions/cache@v4
       with:
         path: /tmp/.buildx-cache
         key: ${{ runner.os }}-buildx-${{ github.sha }}",build
fix(rnd): Fix prisma connection acquisition intermittent error on linux (#7999),"--- rnd/autogpt_server/autogpt_server/app.py ---
@@ -1,3 +1,4 @@
+from multiprocessing import set_start_method
 from typing import TYPE_CHECKING
 
 from .util.logging import configure_logging
@@ -11,6 +12,7 @@ def run_processes(*processes: ""AppProcess"", **kwargs):
     Execute all processes in the app. The last process is run in the foreground.
     """"""
     try:
+        set_start_method(""spawn"", force=True)
         configure_logging()
 
         for process in processes[:-1]:

--- rnd/autogpt_server/autogpt_server/data/db.py ---
@@ -1,3 +1,4 @@
+import asyncio
 import os
 from contextlib import asynccontextmanager
 from uuid import uuid4
@@ -11,17 +12,33 @@
 PRISMA_SCHEMA = os.getenv(""PRISMA_SCHEMA"", ""schema.prisma"")
 os.environ[""PRISMA_SCHEMA_PATH""] = PRISMA_SCHEMA
 
-prisma = Prisma(auto_register=True)
+prisma, conn_id = Prisma(auto_register=True), """"
 
 
-async def connect():
-    if not prisma.is_connected():
-        await prisma.connect()
+async def connect(call_count=0):
+    global conn_id
+    if not conn_id:
+        conn_id = str(uuid4())
+
+    try:
+        print(f""[Prisma-{conn_id}] Acquiring connection.."")
+        if not prisma.is_connected():
+            await prisma.connect()
+        print(f""[Prisma-{conn_id}] Connection acquired!"")
+    except Exception as e:
+        if call_count <= 5:
+            print(f""[Prisma-{conn_id}] Connection failed: {e}. Retrying now.."")
+            await asyncio.sleep(call_count)
+            await connect(call_count + 1)
+        else:
+            raise e
 
 
 async def disconnect():
     if prisma.is_connected():
+        print(f""[Prisma-{conn_id}] Releasing connection."")
         await prisma.disconnect()
+        print(f""[Prisma-{conn_id}] Connection released."")
 
 
 @asynccontextmanager

--- rnd/autogpt_server/autogpt_server/executor/manager.py ---
@@ -621,7 +621,7 @@ def callback(_):
 
 class ExecutionManager(AppService):
     def __init__(self):
-        self.use_redis = False
+        self.use_db = True
         self.pool_size = Config().num_graph_workers
         self.queue = ExecutionQueue[GraphExecution]()
         self.active_graph_runs: dict[str, tuple[Future, threading.Event]] = {}

--- rnd/autogpt_server/autogpt_server/executor/scheduler.py ---
@@ -19,9 +19,9 @@ def log(msg, **kwargs):
 
 class ExecutionScheduler(AppService):
     def __init__(self, refresh_interval=10):
+        self.use_db = True
         self.last_check = datetime.min
         self.refresh_interval = refresh_interval
-        self.use_redis = False
 
     @property
     def execution_manager_client(self) -> ExecutionManager:

--- rnd/autogpt_server/autogpt_server/server/rest_api.py ---
@@ -29,7 +29,6 @@
 
 class AgentServer(AppService):
     mutex = KeyedMutex()
-    use_db = False
     use_redis = True
     _test_dependency_overrides = {}
 

--- rnd/autogpt_server/autogpt_server/util/process.py ---
@@ -1,7 +1,7 @@
 import os
 import sys
 from abc import ABC, abstractmethod
-from multiprocessing import Process
+from multiprocessing import Process, set_start_method
 from typing import Optional
 
 
@@ -11,6 +11,7 @@ class AppProcess(ABC):
     """"""
 
     process: Optional[Process] = None
+    set_start_method(""spawn"", force=True)
 
     @abstractmethod
     def run(self):

--- rnd/autogpt_server/autogpt_server/util/retry.py ---
@@ -0,0 +1,7 @@
+from tenacity import retry, stop_after_attempt, wait_exponential
+
+conn_retry = retry(
+    stop=stop_after_attempt(30),
+    wait=wait_exponential(multiplier=1, min=1, max=30),
+    reraise=True,
+)

--- rnd/autogpt_server/autogpt_server/util/service.py ---
@@ -7,17 +7,14 @@
 
 from Pyro5 import api as pyro
 from Pyro5 import nameserver
-from tenacity import retry, stop_after_attempt, wait_exponential
 
 from autogpt_server.data import db
 from autogpt_server.data.queue import AsyncEventQueue, AsyncRedisEventQueue
 from autogpt_server.util.process import AppProcess
+from autogpt_server.util.retry import conn_retry
 from autogpt_server.util.settings import Config
 
 logger = logging.getLogger(__name__)
-conn_retry = retry(
-    stop=stop_after_attempt(30), wait=wait_exponential(multiplier=1, min=1, max=30)
-)
 T = TypeVar(""T"")
 C = TypeVar(""C"", bound=Callable)
 
@@ -65,7 +62,7 @@ def health_check(self):
 class AppService(AppProcess):
     shared_event_loop: asyncio.AbstractEventLoop
     event_queue: AsyncEventQueue = AsyncRedisEventQueue()
-    use_db: bool = True
+    use_db: bool = False
     use_redis: bool = False
 
     @classmethod

--- rnd/autogpt_server/poetry.lock ---
@@ -25,7 +25,7 @@ requests = ""*""
 sentry-sdk = ""^1.40.4""
 
 [package.extras]
-benchmark = [""agbenchmark""]
+benchmark = [""agbenchmark @ file:///Users/majdyz/Code/AutoGPT/benchmark""]
 
 [package.source]
 type = ""directory""
@@ -386,7 +386,7 @@ watchdog = ""4.0.0""
 webdriver-manager = ""^4.0.1""
 
 [package.extras]
-benchmark = [""agbenchmark""]
+benchmark = [""agbenchmark @ file:///Users/majdyz/Code/AutoGPT/benchmark""]
 
 [package.source]
 type = ""directory""",fix
"feat(market) Add on delete to market (#8255)

* add on delete to market

* add migrations

* updated schema

* add endpint

* add migrations

* remove transaction

---------

Co-authored-by: Zamil Majdy <zamil.majdy@agpt.co>","--- autogpt_platform/market/market/db.py ---
@@ -55,6 +55,29 @@ class FeaturedAgentResponse(pydantic.BaseModel):
     page_size: int
     total_pages: int
 
+async def delete_agent(agent_id: str) -> prisma.models.Agents | None:
+    """"""
+    Delete an agent from the database.
+
+    Args:
+        agent_id (str): The ID of the agent to delete.
+
+    Returns:
+        prisma.models.Agents | None: The deleted agent if found, None otherwise.
+
+    Raises:
+        AgentQueryError: If there is an error deleting the agent from the database.
+    """"""
+    try:
+        deleted_agent = await prisma.models.Agents.prisma().delete(
+            where={""id"": agent_id}
+        )
+        return deleted_agent
+    except prisma.errors.PrismaError as e:
+        raise AgentQueryError(f""Database query failed: {str(e)}"")
+    except Exception as e:
+        raise AgentQueryError(f""Unexpected error occurred: {str(e)}"")
+
 
 async def create_agent_entry(
     name: str,

--- autogpt_platform/market/market/routes/admin.py ---
@@ -15,6 +15,38 @@
 router = fastapi.APIRouter()
 
 
+@router.delete(""/agent/{agent_id}"", response_model=market.model.AgentResponse)
+async def delete_agent(
+    agent_id: str,
+    user: autogpt_libs.auth.User = fastapi.Depends(
+        autogpt_libs.auth.requires_admin_user
+    ),
+):
+    """"""
+    Delete an agent and all related records from the database.
+
+    Args:
+        agent_id (str): The ID of the agent to delete.
+
+    Returns:
+        market.model.AgentResponse: The deleted agent's data.
+
+    Raises:
+        fastapi.HTTPException: If the agent is not found or if there's an error during deletion.
+    """"""
+    try:
+        deleted_agent = await market.db.delete_agent(agent_id)
+        if deleted_agent:
+            return market.model.AgentResponse(**deleted_agent.dict())
+        else:
+            raise fastapi.HTTPException(status_code=404, detail=""Agent not found"")
+    except market.db.AgentQueryError as e:
+        logger.error(f""Error deleting agent: {e}"")
+        raise fastapi.HTTPException(status_code=500, detail=str(e))
+    except Exception as e:
+        logger.error(f""Unexpected error deleting agent: {e}"")
+        raise fastapi.HTTPException(status_code=500, detail=""An unexpected error occurred"")
+
 @router.post(""/agent"", response_model=market.model.AgentResponse)
 async def create_agent_entry(
     request: market.model.AddAgentRequest,

--- autogpt_platform/market/migrations/20241003134209_update_foreign_key_on_delete/migration.sql ---
@@ -0,0 +1,20 @@
+-- DropForeignKey
+ALTER TABLE ""AnalyticsTracker"" DROP CONSTRAINT ""AnalyticsTracker_agentId_fkey"";
+
+-- DropForeignKey
+ALTER TABLE ""FeaturedAgent"" DROP CONSTRAINT ""FeaturedAgent_agentId_fkey"";
+
+-- DropForeignKey
+ALTER TABLE ""InstallTracker"" DROP CONSTRAINT ""InstallTracker_marketplaceAgentId_fkey"";
+
+-- DropIndex
+DROP INDEX ""AnalyticsTracker_agentId_key"";
+
+-- AddForeignKey
+ALTER TABLE ""AnalyticsTracker"" ADD CONSTRAINT ""AnalyticsTracker_agentId_fkey"" FOREIGN KEY (""agentId"") REFERENCES ""Agents""(""id"") ON DELETE CASCADE ON UPDATE CASCADE;
+
+-- AddForeignKey
+ALTER TABLE ""InstallTracker"" ADD CONSTRAINT ""InstallTracker_marketplaceAgentId_fkey"" FOREIGN KEY (""marketplaceAgentId"") REFERENCES ""Agents""(""id"") ON DELETE CASCADE ON UPDATE CASCADE;
+
+-- AddForeignKey
+ALTER TABLE ""FeaturedAgent"" ADD CONSTRAINT ""FeaturedAgent_agentId_fkey"" FOREIGN KEY (""agentId"") REFERENCES ""Agents""(""id"") ON DELETE CASCADE ON UPDATE CASCADE;

--- autogpt_platform/market/schema.prisma ---
@@ -47,8 +47,8 @@ model Agents {
 
 model AnalyticsTracker {
   id        String @id @unique @default(dbgenerated(""gen_random_uuid()"")) @db.Uuid
-  agentId   String @unique @db.Uuid
-  agent     Agents @relation(fields: [agentId], references: [id])
+  agentId   String @db.Uuid
+  agent     Agents @relation(fields: [agentId], references: [id], onDelete: Cascade)
   views     Int
   downloads Int
 }
@@ -61,7 +61,7 @@ enum InstallationLocation {
 model InstallTracker {
   id                   String               @id @default(dbgenerated(""gen_random_uuid()"")) @db.Uuid
   marketplaceAgentId   String               @db.Uuid
-  marketplaceAgent     Agents               @relation(fields: [marketplaceAgentId], references: [id])
+  marketplaceAgent     Agents               @relation(fields: [marketplaceAgentId], references: [id], onDelete: Cascade)
   installedAgentId     String               @db.Uuid
   installationLocation InstallationLocation
   createdAt            DateTime             @default(now())
@@ -72,7 +72,7 @@ model InstallTracker {
 model FeaturedAgent {
   id                 String   @id @unique @default(dbgenerated(""gen_random_uuid()"")) @db.Uuid
   agentId            String   @unique @db.Uuid
-  agent              Agents   @relation(fields: [agentId], references: [id])
+  agent              Agents   @relation(fields: [agentId], references: [id], onDelete: Cascade)
   isActive           Boolean  @default(false)
   featuredCategories String[]
   createdAt          DateTime @default(now())",feat
"feat(platform): reseal revid (#8523)

reseal revid","--- autogpt_platform/infra/helm/autogpt-server/values.prod.yaml ---
@@ -116,7 +116,7 @@ secrets:
   REPLICATE_API_KEY: ""AgCPCgcYb+tE8/k45Y7/my4G2jWPCuEMTXJIn1fG1q4x4ZJPFzb43m7Uqtwn23NkmUZ5Qvh8BXedrtHwxapuYzw/P6c7xK66xfLKRbTWtYk4twS3sxPb+pt1FXY4USEjj5yeIFduybkqhE2QfnGoyrbDZ4Bz3AIgnrRD0Ee5m9u5yNZTPmJqZZqg4MRdUBCxCWIJBkW6DCE9nCPAQeNPD6e+lZ1j+/LocT2HX/ZlcsPXCxbn6wkxoyLqA0vUKSG9azS6oLvn0/3Cb01ozG8S2OEAqWIImFqhKGMfGqL6jSZWln43cmQdMTzSzM+HiprA9JHjZqGK7wOV9HZvSR+58IXoJGPBEIM7jIg5KqPjpZY4KFZBp5OiiRRYu+nCbuD+KsY/7ogjPHjbi1rpR8TrtXdzWNmwsTTmjytB/KEqeUpLWOEPgArFPyrNTS5/nmREH7r9jNEhfIRdTlS3IVGGXp/VN8napbNND1GDyzowvF771neq7/zTmfCRCJ4J0gwPNKM5rzOuRW+caEf2qOFBKIldVa/J0PFg5bAgpGL6jhpXHj0Q/+j1s3FA/D2ZebZTPIpKe40It3sWsS/0Qjhbj1GMbL4yUWvGpBSUTk7kZazkaVND1LbhjC+4AolTQdIU4MgW0bkmDn5ZI4a9/dHyLS3lFeYNSQ6vnbz+Id7zB3O0D6/FH8nfAUGL8V+J3eFKMp+G67z+XYH6WGABaNicz41zFBDF5hRax+k/ZziPPlFY0kDc3cAB6pLc""
   IDEOGRAM_API_KEY: ""AgBTMZopEC5qALJvordVcdbUnwOEhLR5v6+7bTWg8GF2GSeNn2jKqM+o+wr2FjZJ0vtfyS+MjpOrr1xXrhdWLHg6HXyonjg67jS4BwxFrX60MbnkuoeYDX10O30JloAaMcq3a7OzLa/2r9RjqICO0fappaYHuysTcj6XD+wHsgQgZBSaqaomP7WR0YEIEiLVJaVFfQJaj1lqffIXxSQHE/oqafKqV3CeBPcD2jgwvErBMOBldTNDY2ehSmS54ebwLcXcLwf6JoQjXeit2Zry2ffnW5eNIIwYVl5GO4JT6rE2lB4B6jDs0z/y7toXdN5pGuVoYGDia8OKd7MuW3IlAWkhYLcoKla62/YzcC1JffMrqV++lWt4WFcuXWvL6UUNshwCdX/LQ9/tMt81cCQuin4mrVPxrEYALkin6HBaOWChCbhVS31lPWmFLM+vE+dvogY9Zp3PubxP5E3gsRLKn2LeAEXiGjBlf2H3IQ6/YI/WonsT1pKTHMkegHmvNz79XCFAJLnUIXlffznyTj+A+5VAVVl+i90mc2UtQLyEVuMbwK3lcoKB0IzNCs8OY/9DkuoROIikPOg79ZVmo+d1DzSl3y2tlR64Sw/pd5TL58+/MVbLFI35mKo1HKoxN+kUIDehFfZ8Sn8+8MkUsuAT7xfDvgYZpIxC2138XqTFJn2PhvdbQGB4l9dGIo+fjrddWuoEhAzZXJ8EmxTUaY+SRPKyWqKgf+w+qjdzRKqsE/zIo5Xj3LrnJh3VEC01waR1TdM+qIRTlpAO8m5oYHO8QB32GnabUbjPRDVIq2Vkp9qKpwgWtrBHTQ==""
   GROQ_API_KEY: ""AgCxjMuIUxeJYxvGFMMRV3vOeTs7eJbA+oHsjCi6dCVL4/rk9GBK+NSDuG87ltIk5iwXsx75arP8YLHjifC0Jn5lfzxy4KLmQSkgfXBw+X05nO1zNoSWCadVhZDKAu1YL/FTD874f2UsSRLMV9BkqW2YNjN+WXab+dDTkicNcNTV6q/HKn6vMLeQd5PDv0Nbtup7B3C6rfSnIiKC0YH0Bqvc5BPEmw+6PVK9nPpdJiL6IxPX84LsJ/T1vMRNxlkFgEAN+3CZyx5q3ycMEQjOsBQGWny1HDeGuYeeYxRbg8PWMT+mx5uDampxqf66ztT1+PxpBx/+pgReSvWot5zGI1uN20Fiqav/n8VYF9x0wvYfFaSSGWeosjJ195MZDjq0cjWsy14lhGPbA839aZm+E6EQ3hmFzQULM4iR1sGu1OP87GhE6HbJ3Os4Gmsbo3XqWEy2puWSqcnZbkZvely5MGU6HDQ0L09EDMTG1PmmI3VmRiPUmJGxe+GtHaCmtJINsBrrbvjIki3TLSGwbIITKh5OEy5Y9My9H7WWZnzX8Dppkpqti1eUxh/GdtIZvLBve2N9nw65NRcx0sNp2knsO7Yk2+J2I9IrEwE8eC/AeBt7ii1ukCf1CSPNDj42GtqWgrQ15X85i7XCudmi2n4QfVL9/ZGOIjt95m8Ge+/o1Q4ltZBJ0wNgQPHClr12s/2H02BkmoJfUBlVQsGSc7yDz+cwPHLGb+tpjdPwENkm8yizTgK9/SJYa8gNLxFlJRa5MqZyMuye2A1mBQ==""
-  REVID_API_KEY: ""AgBPAmDtdzfHMbudluOeUZS7RCixfJXaI6vBvEUPQhhtpbNW9sUfDv6waKzBdjgWxIf2EqI4QI7QUVqHxA7fMChSjZjt9Np9z6+nHZhKWTqCCKyVR4Lka8tnkU5M62e+x+T7QoHy6mKsB7FEyQ8/FPxUM/Ddp5ZPTj6sbLn3y2uv1SPxInbd6boXeLEwQQcN/Inrww/lzNzJPec4jlHNwPHugjhZJnlWotvyfhU33Fdt5IEusdqt6CM0vS5N7lkR8KTNAg56VLD89yXVRR2VOtkJWzaQJ4lNSztBgUFNGaYtl7SRNVYnMpT1jhyTcAeO/fAGP4O/8haTlAZbfSsOLub5Af9CIA5vtNpU4zoY0Q2MOtKOJ5OTtbbJxmlWex3zc2wpIwdTLCRyBHxiPphdSBXQPW12s9NX6GVR7WDc3Lcvhi0P4uo+y01kyL64JGRigjvBzCYCqhNGWMtJ+YOy4pwcE89Qaz2/EvHgh37P9O7TQhN3Vo8BGRV0+DlNe6uv3OBitgayub5M34nh+qnNHypErkm29SovnqY1fEFhdOib2nmnE2fEXylZMtMPonBVYtVX9iOJLERQMNOzwDxaKzwPdpNu4GhMNVG6joCDjDqKPp9BfnKDJsn0GgUt3oDl5kRWdYL75HLDa3LDWGj0UiAF1YeQE2SHJjlrIoAVJWDdjwTsFJ1x3sMZTt9gB8KiUIDK/hgt7to/kaIyBUTrQIUv/2hHNYI4KH5/nNFZu3TPJXNrxfU=""
+  REVID_API_KEY: ""AgB2+w7euCOnPTTag2oZWnTDiuHZJGjpsIVzIhlXXL4HURNEesANasrjyaQo1Lw7Zi2QDEKF+0XnZduOs0q5kRED3CUD9QN2aDClblOXC1g5zfmsrRp2wpISdsvOmPuMbzmVgIGA8fxSASm8+tlGh8T+QvlmXVvfD6ZWAbLXEW/4Inrz8o9RyEIjoS/g6NynVYg4CaY4xdG6KZIUuR3VkiI8irH8mXKf5O4LKNC9qKTMF8/tYyyv1gS8GAiU9JcuWKUYpqHoNah293d+vTVXVwo6o0GoQ+huxh+90cS3D1FPhiWHABeLYS292brnshJY3AuoCAPZxyQK69EXZgjUFCc+m5n2juF27P38QcCxtgr66kMXwg582OikJ77nDg6QHafIGnqSkUG3O184UOAzUe/iOjjDNlpxQaZoRQXP37zPIZcingWUx4zvZVjbsQcKSqdiI5u6K8kDw7F8wfCJI+3Y6YH9k7cWE+6ZmK1U7hEh3YKmqI5I0e4WolljRv8PlsWLZdgN5u5M7NqtYjqEhdd2fJ9fJYedXeATRefUHtthhvLeSbg3wS0f90pldIej+da1ZPpnToBN/o2YUA03pbQmty0Ce4EVBbwEN9sSNJGC1hicquURQP0baLBTsXzVZRkTT8OckxRkCN8UysTdkMtIf10AdQ0QVe6lAxR0DjnBL/ysgpSF1ZyKBWm6l7rBEsIIWXjBJpeGo1arVQVtepk8q1nLLWVpykJIfRnPRTCE41/Z9c0=""
   ANTHROPIC_API_KEY: ""AgB+40jZoawJ6HaeyyLZvDp2ByF4EPy2Ce806D/lekwJVmxpYXgkQdLJyav6bt9c1g5eDShJqezx1T+jGV+ApQbhSwmO403nJdYO825Fd3XVJ5K0xfFNt8DOTC9r2egWFvJZL40s/Y24kpr2Mmsqp+Sk9DxMNdYG/Z4PnT8PLWgb3yIYGGPVjlWlHL82gn4/B1bVTk14/cGXX9eSr0ktKKmS2OGLMYUwLT3oYGy4bRq9bH91XwjjdW6vMluNBGYibpi2f4h3nYORaQn42OhzTqON3XUdvNmsw1ZH0raMAJq47SU0lC6Ar9MzwbtUWY3tF6BlTmyx3gPavjQCnXg5cRxmY8JklrynDoyN+SBludzaWDzdAjr4vGPpkOo56RBY+28tnNjmxgyttGIYfFa8DEsrrJJgZZxSUvRqwJc0TWIKRFP1aIHkQ5DclUilFtNfPMezxwcFqrsYTEvtDjsls/E8uTNUN99cVQ2x0PxDsLKr9xVKAKkzzOBEvKEAJy0t5RtRV9A6kc0b16YbjIkFphip4e7HJTWKRvavknw+MXjGXXQrz9+xp8LrjRcgCyZp3BqSo+gsX8KQJSnhiFfKvgt7RdVaUVUA+sn5fIQGPWA5IkbI4gS12BRFDw59+Doc5FbCGUip4jDL8I2bPuNKQZLmSMx93Nu/60WBRhKXYz+GNzLzvhk0IpEI3d2GeWvC61p/f5eKnsLKNLDrc3k8rFHiUmXXhB+oQXMRSUFqq4hen32VVPWRhzT8nefww5Tud21CBg5+87x6WHOnB/A4vw+VuKD3fdeo9tn4HlD3w2funOVu9yv+NaP+MTeHus2PBeab/OtKLH09ezxnhmA=""
   OPENAI_API_KEY: ""AgAjPjhje52qw5YSXjRAwoXU0WyDEIAHnz2CjFtSjkpbsvvXFPlPMlOd/y7/dvABoyZHB9Ukxjna6opqV/hK/vHR9ncp9i7cDYX3Rekj+mkA6arMdqdJ0eikAGqWYPieu8RcBn6pHFGmoC8ZZPgk6Eh3Wyi4OCaPfH/O1bTq/RBQU5VDFvYfaeDZmYIu6SkD88pI0lT12Dklk1apsHlS+g3/rpQwDXgemE/pdmcNnt1zS6Ifu4isN7yg1pg1Thja+UiQnEkIiZkvmD39LO8HrwOFt8guJctRZ5gnVxPmSEdJLN089/fj5VXxTO1kTprbh1KeG9RKYS5LEPNYpgcl9/o884qMc/r0/+Cy7gL5R1THrEPHurVg8JfssCq8k0SaEtCElQ2081Scc/0p/k4URpXrsxUKZ8XUTIvYS0y2mEJPAAqaHAkwthY8sizhOwqWWnt8dGbCPwfQ11TiNSMikKIim9Bwm4tKM9aEolROSkivbGqFQQYSkensyp2mTqx7iFYlGBa7Z7PFRBZgPzD2FojWc6o5tLui5Xgi67ukO5WeaBhO6eMd2CuIlXqu+5x3+ixIytp9Jpke4mZKwbjYai4j3iELbzEwbGkjsnDyWNYn+1KnPOogd6i5+YPn09FbQO2Qvg2t3yUP/ePeX+fdRYk7AnS/o6nllqj9GLas48JFUlEx+KSO4qwrflRqPUmfmD3wPDTYR2q6yJzdatLYzdRQxEctFhgvco63uhW1YH+1ei1YuxutYPkIOqUwbgfIC3XiW7Tr3R8Gd3TimJLQM1etR6dwrEaEm0jTCIKUoZ+65OIAeVtcXIwWtwRjjUOtR8k9B2UdFoJOgtfIFzlxwYj4xUJrzRkCLdFD1W362n2+O5n7QdXDjYXn9KmxVUEph2vloeS8IGrBjM/l743A3trFD4CZ9g==""
   DATABASE_URL: ""AgAfP8iiQGaA68dGVHQuHiKXldqhWungOlLEy6kg6nkKIY6LAwwUJbF59SrsbJ6Lvaq+40XiPSEV6ZjC1JpDyNQyPYzS6hUO9Ev82ViQ2H4Ba62jehBjXufVhabGurHe+F/WsyrXAEY496yX8I3/voy92bR+r0z66jRKHPwI+OXP2CyvdfIz6ziGwInkdfGdP0WRopvmSzbr/atUc1MGVBGuCvNguYWQ3WUwiF38EPObsoYpgV8fuD4trrFE2imHRs23AXMK/ntkqAjZwVWXfZNwaFECT9y1ue04rjDhuoFsL6lhvsK9Xf07mrTzBjdjJl0eCCTxsm0kZTTCwsPSq6H+6w8bjH33M1qeEnORwMuthFy4p0r3e+qlWbhHHwR6ku9wiwzCavDTd27EEfMKkD3zG7NrnbYA4zelHfG2q3/1/PZCeAOsa5jo0EuMTJr4p1Z6deKS4wevzOqJ/FcU1/5T24aKdxhVMnVrF9HKCLKHD+lJLJE8XgdZLFeded234nQfc9MGoBCD6FJvgfJCrjQh8QCSpm1aBKgu795Esff3ZqXJFiq7YCTQTOv/P6RXR5XA/LEqq1m5pcyBDzKixILE1SEbNdeXbYNhe7SbobKpQ9gq3f2ssCRNZGMgJtde6TQFx7J76IE4Eu9oqZefNQxHvh9lH2l0bROWy5NYKHfAejXnVGxIEVnoyRvyFB/HMOc=""",feat
"build(platform/ci): Add prod migrations (#8396)

* ci with workload identity

* temp update

* update name

* wip

* update auth step

* update provider name

* remove audience

* temp set to false

* update registry naming

* update context

* update login

* revert temp updates

* add prod iam and pool

* add release deploy with approval

* use gha default approval behaviour

* add back in release trigger

* add new line

* add prod migrations

* prod migrations without check","--- .github/workflows/platform-autgpt-deploy-prod.yml ---
@@ -15,6 +15,39 @@ env:
   NAMESPACE: prod-agpt
 
 jobs:
+  migrate:
+    environment: production
+    name: Run migrations for AutoGPT Platform
+    runs-on: ubuntu-latest
+
+    steps:
+      - name: Checkout code
+        uses: actions/checkout@v2
+
+      - name: Set up Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+
+      - name: Install Python dependencies
+        run: |
+          python -m pip install --upgrade pip
+          pip install prisma
+
+      - name: Run Backend Migrations
+        working-directory: ./autogpt_platform/backend
+        run: |
+          python -m prisma migrate deploy
+        env:
+          DATABASE_URL: ${{ secrets.BACKEND_DATABASE_URL }}
+
+      - name: Run Market Migrations
+        working-directory: ./autogpt_platform/market
+        run: |
+          python -m prisma migrate deploy
+        env:
+          DATABASE_URL: ${{ secrets.MARKET_DATABASE_URL }}
+          
   build-push-deploy:
     environment: production
     name: Build, Push, and Deploy",build
"fix(platform): Fix containerized connection issues with DB Manager (#8412)

add missing DB manager host values","--- autogpt_platform/docker-compose.platform.yml ---
@@ -66,6 +66,7 @@ services:
       - ENABLE_AUTH=true
       - PYRO_HOST=0.0.0.0
       - EXECUTIONMANAGER_HOST=executor
+      - DBMANAGER_HOST=executor
       - FRONTEND_BASE_URL=http://localhost:3000
       - BACKEND_CORS_ALLOW_ORIGINS=[""http://localhost:3000""]
     ports:

--- autogpt_platform/infra/helm/autogpt-server/values.dev.yaml ---
@@ -106,6 +106,7 @@ env:
   SUPABASE_URL: ""https://adfjtextkuilwuhzdjpf.supabase.co""
   AGENTSERVER_HOST: ""autogpt-server.dev-agpt.svc.cluster.local""
   EXECUTIONMANAGER_HOST: ""autogpt-server-executor.dev-agpt.svc.cluster.local""
+  DBMANAGER_HOST: ""autogpt-server-executor.dev-agpt.svc.cluster.local""
 
 secrets:
   ANTHROPIC_API_KEY: ""AgBllA6KzTdyLs6Tc+HrwIeSjdsPQxdU/4qpqT64H4K3nTehS6kpCW1qtH6eBChs1v+m857sUgsrB9u8+P0aAa3DcgZ/gNg+G1GX6vAY2NJvP/2Q+Hiwi1cAn+R3ChHejG9P2C33hTa6+V9cpUI9xUWOwWLOIQZpLvAc7ltsi0ZJ06qFO0Zhj+H9K768h7U3XaivwywX7PT7BnUTiT6AQkAwD2misBkeSQZdsllOD0th3b2245yieqal9osZHlSlslI9c6EMpH0n+szSND7goyjgsik0Tb0xJU6kGggdcw9hl4x91rYDYNPs0hFES9HUxzfiAid6Y2rDUVBXoNg7K7pMR6/foIkl+gCg/1lqOS0FRlUVyAQGJEx6XphyX/SftgLaI7obaVnzjErrpLWY1ZRiD8VVZD40exf8FddGOXwPvxYHrrrPotlTDLONZMn4Fl46tJCTsoQfHCjco+sz7/nLMMnHx+l1D0eKBuGPVsKTtbWozhLCNuWEgcWb4kxJK5sd1g/GylD43g8hFW531Vbpk1J1rpf7Hurd/aTUjwSXmdxB2qXTT4HRG+Us6PnhMIuf/yxilTs4WNShY0zHhYgnQFSM3oCTL6XXG1dqdOwY2k6+k2wCQtpK45boVN5PpBrQuDuFdWb/jM5jH6L8ns0dMMlY3lHM459u7FEn8rum/xXdP/JvpFb+yct3Rgc54SOT5HuVUNAHzzmbWhY4RG4b3i21L2SlsVUwjKvu+PlN4MN5KPilvHe3yODXZu0Gp0ClzDNZQiKQU67H0uYr6eRccMDsHtMlPELqnjyQZ+OriydzB3qXidAkguKNmzPypz0LyTMnry7YpNRGyUw=""

--- autogpt_platform/infra/helm/autogpt-server/values.prod.yaml ---
@@ -103,6 +103,7 @@ env:
   SUPABASE_URL: ""https://bgwpwdsxblryihinutbx.supabase.co""
   AGENTSERVER_HOST: ""autogpt-server.prod-agpt.svc.cluster.local""
   EXECUTIONMANAGER_HOST: ""autogpt-server-executor.prod-agpt.svc.cluster.local""
+  DBMANAGER_HOST: ""autogpt-server-executor.prod-agpt.svc.cluster.local""
 
 secrets:
   ANTHROPIC_API_KEY: ""AgCf0CUyhYluMW13zvdScIzF50c1u4P3sUkKZjwe2lJGil/WrxN1r+GQGoLzjMn8ODANV7FiJN2+Y+ilVgpf0tVA9uEWLCL/OguNshRYWfNfU0PCgciXvz+Cy8xILfJW5SIZvZgDV5zMbzXeBomJYq+qFpr+PRyiIzA6ciHK/ZuItcGBB0FMdJ6w2gvAlLTFmAK0ekyXTzYidPEkBp+DA4jJXuzjXGd4U8iC4IcrSs/o0eaqfMQSOBRc7w/6SK+YDUnWypc2awBX4qNwqKbQRYAT59lihy/B0D4BhjjiUb2bAlzNWP0STsJONrOPbnHzuvipm1xpk+1bdYFpkqJAf9rk9GOPAMfB5f/kOdmaoj9jdQN55NIomSzub+KnSGt+m4G6YlEnUf2ZBZTKTeWO1jzk0gnzrdFZclPq/9Dd0qUBsZ/30KjbBRJyL9SexwxpfMoaf6dKJHcsOdOevaCpMQZaQ/AjcFZRtntw8mLALJzTZbTq7Gb6h25blwe1Oi6DrOuTrWT+OMHeUJcDQA3q1rJERa4xV0wLjYraCTerezhZgjMvfRD1Ykm5S+1U9hzsZUZZQS6OEEIS0BaOfYugt3DiFSNLrIUwVcYbl5geLoiMW6oSukEeb4s2AukRqKkMYz8/stjCgJB2NiarVi2NIaDvgaXWLgJxNxxovgtHyS4RR8WpRPdWJdjAs6RH13ve42a35S2m65jvUNg875GSO8Eo1izYH6q2LvJgGmlTfMworP6O2ryZO9tBjNS58UYxM8EqvtXLVktA0TYlK7wlF2NzA/waIMmiOiKJrb8YnQF28ePxYnmQSqqe2ZpwSiDBsDNrzfZvvTk9Ai81qu8=""",fix
docs(server): Request to use UUID generators for new block ids (#8241),"--- docs/content/server/new_blocks.md ---
@@ -49,13 +49,15 @@ Follow these steps to create and test a new block:
 
 4. **Implement the `__init__` method, including test data and mocks:**
 
+    !!! important
+        Use UUID generator (e.g. https://www.uuidgenerator.net/) for every new block `id` and *do not* make up your own. Alternatively, you can run this python code to generate an uuid: `print(__import__('uuid').uuid4())`
+
    ```python
    def __init__(self):
        super().__init__(
            # Unique ID for the block, used across users for templates
-           # you can generate this with this python one liner
-           # print(__import__('uuid').uuid4())
-           id=""h5e7f8g9-1b2c-3d4e-5f6g-7h8i9j0k1l2m"",
+           # If you are an AI leave it as is or change to ""generate-proper-uuid""
+           id=""xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"",
            input_schema=WikipediaSummaryBlock.Input,  # Assign input schema
            output_schema=WikipediaSummaryBlock.Output,  # Assign output schema",docs
"fix(deps): manual fix!! bump replicate from 0.34.1 to 1.0.3 in /autogpt_platform/backend (#8476)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Nicholas Tindle <nicholas.tindle@agpt.co>","--- autogpt_platform/backend/backend/blocks/replicate_flux_advanced.py ---
@@ -5,6 +5,7 @@
 import replicate
 from autogpt_libs.supabase_integration_credentials_store.types import APIKeyCredentials
 from pydantic import SecretStr
+from replicate.helpers import FileOutput
 
 from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema
 from backend.data.model import CredentialsField, CredentialsMetaInput, SchemaField
@@ -197,7 +198,7 @@ def run_model(
         client = replicate.Client(api_token=api_key.get_secret_value())
 
         # Run the model with additional parameters
-        output = client.run(
+        output: FileOutput | list[FileOutput] = client.run(  # type: ignore This is because they changed the return type, and didn't update the type hint! It should be overloaded depending on the value of `use_file_output` to `FileOutput | list[FileOutput]` but it's `Any | Iterator[Any]`
             f""{model_name}"",
             input={
                 ""prompt"": prompt,
@@ -210,13 +211,21 @@ def run_model(
                 ""output_quality"": output_quality,
                 ""safety_tolerance"": safety_tolerance,
             },
+            wait=False,  # don't arbitrarily return data:octect/stream or sometimes url depending on the model???? what is this api
         )
 
         # Check if output is a list or a string and extract accordingly; otherwise, assign a default message
         if isinstance(output, list) and len(output) > 0:
-            result_url = output[0]  # If output is a list, get the first element
+            if isinstance(output[0], FileOutput):
+                result_url = output[0].url  # If output is a list, get the first element
+            else:
+                result_url = output[
+                    0
+                ]  # If output is a list and not a FileOutput, get the first element. Should never happen, but just in case.
+        elif isinstance(output, FileOutput):
+            result_url = output.url  # If output is a FileOutput, use the url
         elif isinstance(output, str):
-            result_url = output  # If output is a string, use it directly
+            result_url = output  # If output is a string (for some reason due to their janky type hinting), use it directly
         else:
             result_url = (
                 ""No output received""  # Fallback message if output is not as expected

--- autogpt_platform/backend/poetry.lock ---
@@ -296,7 +296,7 @@ colorama = ""^0.4.6""
 expiringdict = ""^1.2.2""
 google-cloud-logging = ""^3.11.3""
 pydantic = ""^2.9.2""
-pydantic-settings = ""^2.6.0""
+pydantic-settings = ""^2.6.1""
 pyjwt = ""^2.8.0""
 python-dotenv = ""^1.0.1""
 supabase = ""^2.9.1""
@@ -1988,8 +1988,8 @@ python-dateutil = "">=2.5.3""
 tqdm = "">=4.64.1""
 typing-extensions = "">=3.7.4""
 urllib3 = [
-    {version = "">=1.26.5"", markers = ""python_version >= \""3.12\"" and python_version < \""4.0\""""},
     {version = "">=1.26.0"", markers = ""python_version >= \""3.8\"" and python_version < \""3.12\""""},
+    {version = "">=1.26.5"", markers = ""python_version >= \""3.12\"" and python_version < \""4.0\""""},
 ]
 
 [package.extras]
@@ -2285,8 +2285,8 @@ files = [
 annotated-types = "">=0.6.0""
 pydantic-core = ""2.23.4""
 typing-extensions = [
-    {version = "">=4.12.2"", markers = ""python_version >= \""3.13\""""},
     {version = "">=4.6.1"", markers = ""python_version < \""3.13\""""},
+    {version = "">=4.12.2"", markers = ""python_version >= \""3.13\""""},
 ]
 
 [package.extras]
@@ -2396,13 +2396,13 @@ typing-extensions = "">=4.6.0,<4.7.0 || >4.7.0""
 
 [[package]]
 name = ""pydantic-settings""
-version = ""2.6.0""
+version = ""2.6.1""
 description = ""Settings management using Pydantic""
 optional = false
 python-versions = "">=3.8""
 files = [
-    {file = ""pydantic_settings-2.6.0-py3-none-any.whl"", hash = ""sha256:4a819166f119b74d7f8c765196b165f95cc7487ce58ea27dec8a5a26be0970e0""},
-    {file = ""pydantic_settings-2.6.0.tar.gz"", hash = ""sha256:44a1804abffac9e6a30372bb45f6cafab945ef5af25e66b1c634c01dd39e0188""},
+    {file = ""pydantic_settings-2.6.1-py3-none-any.whl"", hash = ""sha256:7fb0637c786a558d3103436278a7c4f1cfd29ba8973238a50c5bb9a55387da87""},
+    {file = ""pydantic_settings-2.6.1.tar.gz"", hash = ""sha256:e0f92546d8a9923cb8941689abf85d6601a8c19a23e97a34b2964a2e3f813ca0""},
 ]
 
 [package.dependencies]
@@ -2698,13 +2698,13 @@ rpds-py = "">=0.7.0""
 
 [[package]]
 name = ""replicate""
-version = ""0.34.1""
+version = ""1.0.3""
 description = ""Python client for Replicate""
 optional = false
 python-versions = "">=3.8""
 files = [
-    {file = ""replicate-0.34.1-py3-none-any.whl"", hash = ""sha256:beeebbdd83dca46eee960c383dfd8dcc48d7922d9fe9e613f242cc69ed522f2f""},
-    {file = ""replicate-0.34.1.tar.gz"", hash = ""sha256:57cf80c7f4d7f6ae503b1bef400f57c26d494724002d7e9a8750d01394dcfc76""},
+    {file = ""replicate-1.0.3-py3-none-any.whl"", hash = ""sha256:8c49d63444b7ea9ac1d6af99eb23a01efb5b7f079cc8a020d6f52b38843db1da""},
+    {file = ""replicate-1.0.3.tar.gz"", hash = ""sha256:0fd9ca5230fe67c42e4508dd96a5b1414b3fefa5342f8921dbb63c74266cb130""},
 ]
 
 [package.dependencies]
@@ -3880,4 +3880,4 @@ type = [""pytest-mypy""]
 [metadata]
 lock-version = ""2.0""
 python-versions = ""^3.10""
-content-hash = ""bbad5245c6bd3cd1d93d9f047b65e40beda081d83c2eed59eed508c41a9b5ff1""
+content-hash = ""aa0e24af7168780d5a06b239e5379d6f11dd0398ace124ab40eadca09c57fe67""

--- autogpt_platform/backend/pyproject.toml ---
@@ -44,7 +44,7 @@ uvicorn = { extras = [""standard""], version = ""^0.30.1"" }
 websockets = ""^13.1""
 youtube-transcript-api = ""^0.6.2""
 googlemaps = ""^4.10.0""
-replicate = ""^0.34.1""
+replicate = ""^1.0.3""
 pinecone = ""^5.3.1""
 cryptography = ""^43.0.3""
 [tool.poetry.group.dev.dependencies]",fix
fix(rnd): Fix unparsed string on HTTP block (#7795),"--- rnd/autogpt_server/autogpt_server/blocks/http.py ---
@@ -1,3 +1,4 @@
+import json
 from enum import Enum
 
 import requests
@@ -37,6 +38,9 @@ def __init__(self):
         )
 
     def run(self, input_data: Input) -> BlockOutput:
+        if isinstance(input_data.body, str):
+            input_data.body = json.loads(input_data.body)
+
         response = requests.request(
             input_data.method.value,
             input_data.url,",fix
"chore(deps): bump uuid from 10.0.0 to 11.0.2 in /autogpt_platform/frontend (#8552)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/frontend/package.json ---
@@ -66,7 +66,7 @@
     ""recharts"": ""^2.13.0"",
     ""tailwind-merge"": ""^2.5.4"",
     ""tailwindcss-animate"": ""^1.0.7"",
-    ""uuid"": ""^10.0.0"",
+    ""uuid"": ""^11.0.2"",
     ""zod"": ""^3.23.8""
   },
   ""devDependencies"": {

--- autogpt_platform/frontend/yarn.lock ---
@@ -11797,10 +11797,10 @@ utils-merge@1.0.1:
   resolved ""https://registry.npmjs.org/utils-merge/-/utils-merge-1.0.1.tgz""
   integrity sha512-pMZTvIkT1d+TFGvDOqodOclx0QWkkgi6Tdoa8gC8ffGAAqz9pzPTZWAybbsHHoED/ztMtkv/VoYTYyShUn81hA==
 
-uuid@^10.0.0:
-  version ""10.0.0""
-  resolved ""https://registry.npmjs.org/uuid/-/uuid-10.0.0.tgz""
-  integrity sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==
+uuid@^11.0.2:
+  version ""11.0.2""
+  resolved ""https://registry.yarnpkg.com/uuid/-/uuid-11.0.2.tgz#a8d68ba7347d051e7ea716cc8dcbbab634d66875""
+  integrity sha512-14FfcOJmqdjbBPdDjFQyk/SdT4NySW4eM0zcG+HqbHP5jzuH56xO3J1DGhgs/cEMCfwYi3HQI1gnTO62iaG+tQ==
 
 uuid@^8.3.2:
   version ""8.3.2""",chore
"build(frontend): Remove Sentry Pop-up and add run options (#8138)

* modify sentry setup

* Update sentry.client.config.ts

* remove env vars from dev so it will work on windows still","--- autogpt_platform/frontend/package.json ---
@@ -3,7 +3,8 @@
   ""version"": ""0.1.0"",
   ""private"": true,
   ""scripts"": {
-    ""dev"": ""export NODE_ENV=development && next dev"",
+    ""dev"": ""next dev"",
+    ""dev:nosentry"": ""export NODE_ENV=development && export DISABLE_SENTRY=true && next dev"",
     ""dev:test"": ""export NODE_ENV=test && next dev"",
     ""build"": ""next build"",
     ""start"": ""next start"",

--- autogpt_platform/frontend/sentry.client.config.ts ---
@@ -7,7 +7,7 @@ import * as Sentry from ""@sentry/nextjs"";
 Sentry.init({
   dsn: ""https://fe4e4aa4a283391808a5da396da20159@o4505260022104064.ingest.us.sentry.io/4507946746380288"",
 
-  enabled: process.env.NODE_ENV !== ""development"",
+  enabled: process.env.DISABLE_SENTRY !== ""true"",
 
   // Add optional integrations for additional features
   integrations: [
@@ -31,14 +31,6 @@ Sentry.init({
     /^https:\/\/dev\-builder\.agpt\.co\/api/,
   ],
 
-  beforeSend(event, hint) {
-    // Check if it is an exception, and if so, show the report dialog
-    if (event.exception && event.event_id) {
-      Sentry.showReportDialog({ eventId: event.event_id });
-    }
-    return event;
-  },
-
   // Define how likely Replay events are sampled.
   // This sets the sample rate to be 10%. You may want this to be 100% while
   // in development and sample at a lower rate in production",build
"feat(platform): Expose DB Manager Port (#8424)

expose 8005 for db manager","--- autogpt_platform/infra/helm/autogpt-server/templates/deployment-executor.yaml ---
@@ -46,6 +46,9 @@ spec:
             - name: http
               containerPort: {{ .Values.serviceExecutor.port }}
               protocol: TCP
+            - name: db-http
+              containerPort: {{ .Values.serviceDBManager.port }}
+              protocol: TCP
           resources:
             {{- toYaml .Values.resources | nindent 12 }}
           {{- with .Values.volumeMounts }}

--- autogpt_platform/infra/helm/autogpt-server/templates/service-executor.yaml ---
@@ -15,5 +15,9 @@ spec:
       targetPort: http
       protocol: TCP
       name: http
+    - port: {{ .Values.serviceDBManager.port }}
+      targetPort: db-http
+      protocol: TCP
+      name: db-http
   selector:
-    app.kubernetes.io/component: executor
+    app.kubernetes.io/component: executor
\ No newline at end of file

--- autogpt_platform/infra/helm/autogpt-server/values.dev.yaml ---
@@ -25,6 +25,13 @@ serviceExecutor:
   annotations:
     beta.cloud.google.com/backend-config: '{""default"": ""autogpt-server-backend-config""}'
 
+serviceDBManager:
+  type: ClusterIP
+  port: 8005
+  targetPort: 8005
+  annotations:
+    beta.cloud.google.com/backend-config: '{""default"": ""autogpt-server-backend-config""}'
+
 ingress:
   enabled: true
   className: ""gce""

--- autogpt_platform/infra/helm/autogpt-server/values.prod.yaml ---
@@ -25,6 +25,13 @@ serviceExecutor:
   annotations:
     beta.cloud.google.com/backend-config: '{""default"": ""autogpt-server-backend-config""}'
 
+serviceDBManager:
+  type: ClusterIP
+  port: 8005
+  targetPort: 8005
+  annotations:
+    beta.cloud.google.com/backend-config: '{""default"": ""autogpt-server-backend-config""}'
+
 ingress:
   enabled: true
   className: ""gce""",feat
feat(backend): Add credit for Jina/Search & LLM blocks (#8361),"--- autogpt_platform/backend/backend/blocks/llm.py ---
@@ -96,25 +96,25 @@ def cost_factor(self) -> int:
 
 
 MODEL_METADATA = {
-    LlmModel.O1_PREVIEW: ModelMetadata(""openai"", 32000, cost_factor=60),
-    LlmModel.O1_MINI: ModelMetadata(""openai"", 62000, cost_factor=30),
-    LlmModel.GPT4O_MINI: ModelMetadata(""openai"", 128000, cost_factor=10),
-    LlmModel.GPT4O: ModelMetadata(""openai"", 128000, cost_factor=12),
-    LlmModel.GPT4_TURBO: ModelMetadata(""openai"", 128000, cost_factor=11),
-    LlmModel.GPT3_5_TURBO: ModelMetadata(""openai"", 16385, cost_factor=8),
-    LlmModel.CLAUDE_3_5_SONNET: ModelMetadata(""anthropic"", 200000, cost_factor=14),
-    LlmModel.CLAUDE_3_HAIKU: ModelMetadata(""anthropic"", 200000, cost_factor=13),
-    LlmModel.LLAMA3_8B: ModelMetadata(""groq"", 8192, cost_factor=6),
-    LlmModel.LLAMA3_70B: ModelMetadata(""groq"", 8192, cost_factor=9),
-    LlmModel.MIXTRAL_8X7B: ModelMetadata(""groq"", 32768, cost_factor=7),
-    LlmModel.GEMMA_7B: ModelMetadata(""groq"", 8192, cost_factor=6),
-    LlmModel.GEMMA2_9B: ModelMetadata(""groq"", 8192, cost_factor=7),
-    LlmModel.LLAMA3_1_405B: ModelMetadata(""groq"", 8192, cost_factor=10),
+    LlmModel.O1_PREVIEW: ModelMetadata(""openai"", 32000, cost_factor=16),
+    LlmModel.O1_MINI: ModelMetadata(""openai"", 62000, cost_factor=4),
+    LlmModel.GPT4O_MINI: ModelMetadata(""openai"", 128000, cost_factor=1),
+    LlmModel.GPT4O: ModelMetadata(""openai"", 128000, cost_factor=3),
+    LlmModel.GPT4_TURBO: ModelMetadata(""openai"", 128000, cost_factor=10),
+    LlmModel.GPT3_5_TURBO: ModelMetadata(""openai"", 16385, cost_factor=1),
+    LlmModel.CLAUDE_3_5_SONNET: ModelMetadata(""anthropic"", 200000, cost_factor=4),
+    LlmModel.CLAUDE_3_HAIKU: ModelMetadata(""anthropic"", 200000, cost_factor=1),
+    LlmModel.LLAMA3_8B: ModelMetadata(""groq"", 8192, cost_factor=1),
+    LlmModel.LLAMA3_70B: ModelMetadata(""groq"", 8192, cost_factor=1),
+    LlmModel.MIXTRAL_8X7B: ModelMetadata(""groq"", 32768, cost_factor=1),
+    LlmModel.GEMMA_7B: ModelMetadata(""groq"", 8192, cost_factor=1),
+    LlmModel.GEMMA2_9B: ModelMetadata(""groq"", 8192, cost_factor=1),
+    LlmModel.LLAMA3_1_405B: ModelMetadata(""groq"", 8192, cost_factor=1),
     # Limited to 16k during preview
-    LlmModel.LLAMA3_1_70B: ModelMetadata(""groq"", 131072, cost_factor=15),
-    LlmModel.LLAMA3_1_8B: ModelMetadata(""groq"", 131072, cost_factor=13),
-    LlmModel.OLLAMA_LLAMA3_8B: ModelMetadata(""ollama"", 8192, cost_factor=7),
-    LlmModel.OLLAMA_LLAMA3_405B: ModelMetadata(""ollama"", 8192, cost_factor=11),
+    LlmModel.LLAMA3_1_70B: ModelMetadata(""groq"", 131072, cost_factor=1),
+    LlmModel.LLAMA3_1_8B: ModelMetadata(""groq"", 131072, cost_factor=1),
+    LlmModel.OLLAMA_LLAMA3_8B: ModelMetadata(""ollama"", 8192, cost_factor=1),
+    LlmModel.OLLAMA_LLAMA3_405B: ModelMetadata(""ollama"", 8192, cost_factor=1),
 }
 
 for model in LlmModel:

--- autogpt_platform/backend/backend/data/credit.py ---
@@ -17,6 +17,7 @@
     AITextSummarizerBlock,
     LlmModel,
 )
+from backend.blocks.search import ExtractWebsiteContentBlock, SearchTheWebBlock
 from backend.blocks.talking_head import CreateTalkingAvatarVideoBlock
 from backend.data.block import Block, BlockInput, get_block
 from backend.util.settings import Config
@@ -74,6 +75,10 @@ def __init__(
     CreateTalkingAvatarVideoBlock: [
         BlockCost(cost_amount=15, cost_filter={""api_key"": None})
     ],
+    SearchTheWebBlock: [BlockCost(cost_amount=1)],
+    ExtractWebsiteContentBlock: [
+        BlockCost(cost_amount=1, cost_filter={""raw_content"": False})
+    ],
 }",feat
"build(pre-commit): Detect secrets (#8507)

Add detect secrets pre commit","--- .pre-commit-config.yaml ---
@@ -9,6 +9,15 @@ repos:
       - id: check-merge-conflict
       - id: check-symlinks
       - id: debug-statements
+  
+  - repo: https://github.com/Yelp/detect-secrets
+    rev: v1.5.0
+    hooks:
+      - id: detect-secrets
+        name: Detect secrets
+        description: Detects high entropy strings that are likely to be passwords.
+        files: ^autogpt_platform/
+        stages: [push]
 
   - repo: local
     # isort needs the context of which packages are installed to function, so we
@@ -42,7 +51,7 @@ repos:
     hooks:
       - id: black
         name: Lint (Black)
-        language_version: python3.10
+        language_version: python3.12
 
   - repo: https://github.com/PyCQA/flake8
     rev: 7.0.0

--- autogpt_platform/backend/backend/usecases/block_autogen.py ---
@@ -124,7 +124,7 @@ def create_test_graph() -> Graph:
 
 Here are a couple of sample of the Block class implementation:
 
-{""--------------\n"".join([sample_block_codes[v] for v in sample_block_modules])}
+{""--------------"".join([sample_block_codes[v] for v in sample_block_modules])}
 """""",
         },
     )",build
"build(deps): bump @next/third-parties from 14.2.6 to 15.0.2 in /autogpt_platform/frontend (#8490)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/frontend/package.json ---
@@ -23,7 +23,7 @@
   ],
   ""dependencies"": {
     ""@hookform/resolvers"": ""^3.9.1"",
-    ""@next/third-parties"": ""^14.2.5"",
+    ""@next/third-parties"": ""^15.0.2"",
     ""@radix-ui/react-avatar"": ""^1.1.1"",
     ""@radix-ui/react-checkbox"": ""^1.1.2"",
     ""@radix-ui/react-collapsible"": ""^1.1.1"",

--- autogpt_platform/frontend/yarn.lock ---
@@ -1714,10 +1714,10 @@
   resolved ""https://registry.yarnpkg.com/@next/swc-win32-x64-msvc/-/swc-win32-x64-msvc-14.2.13.tgz#5a920eea82a58affa6146192586716cec6c87fed""
   integrity sha512-WwzOEAFBGhlDHE5Z73mNU8CO8mqMNLqaG+AO9ETmzdCQlJhVtWZnOl2+rqgVQS+YHunjOWptdFmNfbpwcUuEsw==
 
-""@next/third-parties@^14.2.5"":
-  version ""14.2.6""
-  resolved ""https://registry.npmjs.org/@next/third-parties/-/third-parties-14.2.6.tgz""
-  integrity sha512-gIayZnFgiir4HlyrqI/KS+MB4y82oVfSYYH4QwHa2KNOtCjX6etF8/cX3pSeSGsQi2VFiI+a9LL+MDMRYgIIoQ==
+""@next/third-parties@^15.0.2"":
+  version ""15.0.2""
+  resolved ""https://registry.yarnpkg.com/@next/third-parties/-/third-parties-15.0.2.tgz#f25c4b58f5242d7918acdeb3b5fb0809309738c7""
+  integrity sha512-Ohlh0KKfag3Vrx+yuSMJ/fSoCVvRoVG9wRiz8jvYelmg+l0970d41VoGzF2UeKwh9s5qXVRDVqiN/mIeiJ4iLg==
   dependencies:
     third-party-capital ""1.0.20""",build
"build(ci): Fix the prod workload identity pool defined in the prod yaml (#8456)

fix project id","--- .github/workflows/platform-autgpt-deploy-prod.yml ---
@@ -62,7 +62,7 @@ jobs:
     - id: 'auth'
       uses: 'google-github-actions/auth@v1'
       with:
-        workload_identity_provider: 'projects/638488734936/locations/global/workloadIdentityPools/prod-pool/providers/github'
+        workload_identity_provider: 'projects/1021527134101/locations/global/workloadIdentityPools/prod-pool/providers/github'
         service_account: 'prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com'
         token_format: 'access_token'
         create_credentials_file: true",build
"fix(rnd): Prevent boolean with no default value on AGPT-builder (#7884)

### Background

Boolean without default value is a UX problem. It's currently displayed as a toggle and it has no way to describe the `null` value.
So we need to prevent blocks from introducing a nullable boolean.

### Changes üèóÔ∏è

Add explicit check to prevent nullable boolean. Fix existing block field that has nullable boolean.","--- rnd/autogpt_builder/src/components/edit/control/BlocksControl.tsx ---
@@ -36,8 +36,12 @@ export const BlocksControl: React.FC<BlocksControlProps> = ({
 }) => {
   const [searchQuery, setSearchQuery] = useState("""");
 
-  const filteredBlocks = blocks.filter((block: Block) =>
-    block.name.toLowerCase().includes(searchQuery.toLowerCase()),
+  const filteredBlocks = blocks.filter(
+    (block: Block) =>
+      block.name.toLowerCase().includes(searchQuery.toLowerCase()) ||
+      beautifyString(block.name)
+        .toLowerCase()
+        .includes(searchQuery.toLowerCase()),
   );
 
   return (

--- rnd/autogpt_server/autogpt_server/blocks/__init__.py ---
@@ -54,6 +54,10 @@ def all_subclasses(clz):
     if block.id in AVAILABLE_BLOCKS:
         raise ValueError(f""Block ID {block.name} error: {block.id} is already in use"")
 
+    for field in block.input_schema.__fields__.values():
+        if field.annotation is bool and field.default not in (True, False):
+            raise ValueError(f""{block.name} has a boolean field with no default value"")
+
     if block.disabled:
         continue
 

--- rnd/autogpt_server/autogpt_server/blocks/search.py ---
@@ -135,7 +135,7 @@ class GetOpenWeatherMapBlock(Block, GetRequest):
     class Input(BlockSchema):
         location: str
         api_key: BlockSecret = SecretField(key=""openweathermap_api_key"")
-        use_celsius: bool
+        use_celsius: bool = True
 
     class Output(BlockSchema):
         temperature: str",fix
"chore(frontend): Fix broken terms of use link (#8279)

Co-authored-by: Aarushi <50577581+aarushik93@users.noreply.github.com>
Co-authored-by: Nicholas Tindle <nicholas.tindle@agpt.co>","--- .github/workflows/platform-frontend-ci.yml ---
@@ -39,10 +39,27 @@ jobs:
     runs-on: ubuntu-latest
 
     steps:
+      - name: Free Disk Space (Ubuntu)
+        uses: jlumbroso/free-disk-space@main
+        with:
+          # this might remove tools that are actually needed,
+          # if set to ""true"" but frees about 6 GB
+          tool-cache: false
+
+          # all of these default to true, but feel free to set to
+          # ""false"" if necessary for your workflow
+          android: false
+          dotnet: false
+          haskell: false
+          large-packages: true
+          docker-images: true
+          swap-storage: true
+
       - name: Checkout repository
         uses: actions/checkout@v4
         with:
           submodules: recursive
+
       - name: Set up Node.js
         uses: actions/setup-node@v4
         with:

--- autogpt_platform/frontend/src/app/marketplace/submit/page.tsx ---
@@ -144,7 +144,7 @@ const SubmitPage: React.FC = () => {
     setSubmitError(null);
 
     if (!data.agreeToTerms) {
-      throw new Error(""You must agree to the terms of service"");
+      throw new Error(""You must agree to the terms of use"");
     }
 
     try {
@@ -404,7 +404,7 @@ const SubmitPage: React.FC = () => {
             <Controller
               name=""agreeToTerms""
               control={control}
-              rules={{ required: ""You must agree to the terms of service"" }}
+              rules={{ required: ""You must agree to the terms of use"" }}
               render={({ field }) => (
                 <div className=""flex items-center space-x-2"">
                   <Checkbox
@@ -417,8 +417,11 @@ const SubmitPage: React.FC = () => {
                     className=""text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70""
                   >
                     I agree to the{"" ""}
-                    <a href=""/terms"" className=""text-blue-500 hover:underline"">
-                      terms of service
+                    <a
+                      href=""https://auto-gpt.notion.site/Terms-of-Use-11400ef5bece80d0b087d7831c5fd6bf""
+                      className=""text-blue-500 hover:underline""
+                    >
+                      terms of use
                     </a>
                   </label>
                 </div>",chore
"fix(frontend): Unbreak credentials input on single-provider blocks (vol. 2)

Fix bad condition introduced in aaa0b79f (#8636) to resolve #8635","--- autogpt_platform/frontend/src/hooks/useCredentials.ts ---
@@ -45,15 +45,20 @@ export default function useCredentials(): CredentialsData | null {
       ]) ||
     null;
 
-  if (
-    !discriminatorValue &&
-    credentialsSchema.credentials_provider.length > 1
-  ) {
-    throw new Error(""Multi-provider credential input requires discriminator!"");
+  let providerName: CredentialsProviderName;
+  if (credentialsSchema.credentials_provider.length > 1) {
+    if (!credentialsSchema.discriminator) {
+      throw new Error(
+        ""Multi-provider credential input requires discriminator!"",
+      );
+    }
+    if (!discriminatorValue) {
+      return null;
+    }
+    providerName = discriminatorValue;
+  } else {
+    providerName = credentialsSchema.credentials_provider[0];
   }
-
-  const providerName =
-    discriminatorValue || credentialsSchema.credentials_provider[0];
   const provider = allProviders ? allProviders[providerName] : null;
 
   // If block input schema doesn't have credentials, return null",fix
"fix(backend): Add migrations to fix credentials inputs with invalid provider ""llm"" (#8674)

In #8524, the ""llm"" credentials provider was replaced. There are still entries with `""provider"": ""llm""` in the system though, and those break if not migrated.

- SQL migration to fix the obvious ones where we know the provider from `credentials.id`
- Non-SQL migration to fix the rest","--- autogpt_platform/backend/backend/data/graph.py ---
@@ -5,6 +5,7 @@
 from datetime import datetime, timezone
 from typing import Any, Literal, Type
 
+import prisma
 from prisma.models import AgentGraph, AgentGraphExecution, AgentNode, AgentNodeLink
 from prisma.types import AgentGraphWhereInput
 from pydantic.fields import computed_field
@@ -523,3 +524,84 @@ async def __create_graph(tx, graph: Graph, user_id: str):
             for link in graph.links
         ]
     )
+
+
+# ------------------------ UTILITIES ------------------------ #
+
+
+async def fix_llm_provider_credentials():
+    """"""Fix node credentials with provider `llm`""""""
+    from autogpt_libs.supabase_integration_credentials_store import (
+        SupabaseIntegrationCredentialsStore,
+    )
+
+    from .redis import get_redis
+    from .user import get_user_integrations
+
+    store = SupabaseIntegrationCredentialsStore(get_redis())
+
+    broken_nodes = await prisma.get_client().query_raw(
+        """"""
+        SELECT    ""User"".id            user_id,
+                  node.id              node_id,
+                  node.""constantInput"" node_preset_input
+        FROM      platform.""AgentNode""  node
+        LEFT JOIN platform.""AgentGraph"" graph
+        ON        node.""agentGraphId"" = graph.id
+        LEFT JOIN platform.""User""       ""User""
+        ON        graph.""userId"" = ""User"".id
+        WHERE     node.""constantInput""::jsonb->'credentials'->>'provider' = 'llm'
+        ORDER BY  user_id;
+        """"""
+    )
+    logger.info(f""Fixing LLM credential inputs on {len(broken_nodes)} nodes"")
+
+    user_id: str = """"
+    user_integrations = None
+    for node in broken_nodes:
+        if node[""user_id""] != user_id:
+            # Save queries by only fetching once per user
+            user_id = node[""user_id""]
+            user_integrations = await get_user_integrations(user_id)
+        elif not user_integrations:
+            raise RuntimeError(f""Impossible state while processing node {node}"")
+
+        node_id: str = node[""node_id""]
+        node_preset_input: dict = json.loads(node[""node_preset_input""])
+        credentials_meta: dict = node_preset_input[""credentials""]
+
+        credentials = next(
+            (
+                c
+                for c in user_integrations.credentials
+                if c.id == credentials_meta[""id""]
+            ),
+            None,
+        )
+        if not credentials:
+            continue
+        if credentials.type != ""api_key"":
+            logger.warning(
+                f""User {user_id} credentials {credentials.id} with provider 'llm' ""
+                f""has invalid type '{credentials.type}'""
+            )
+            continue
+
+        api_key = credentials.api_key.get_secret_value()
+        if api_key.startswith(""sk-ant-api03-""):
+            credentials.provider = credentials_meta[""provider""] = ""anthropic""
+        elif api_key.startswith(""sk-""):
+            credentials.provider = credentials_meta[""provider""] = ""openai""
+        elif api_key.startswith(""gsk_""):
+            credentials.provider = credentials_meta[""provider""] = ""groq""
+        else:
+            logger.warning(
+                f""Could not identify provider from key prefix {api_key[:13]}*****""
+            )
+            continue
+
+        store.update_creds(user_id, credentials)
+        await AgentNode.prisma().update(
+            where={""id"": node_id},
+            data={""constantInput"": json.dumps(node_preset_input)},
+        )

--- autogpt_platform/backend/backend/server/rest_api.py ---
@@ -9,6 +9,7 @@
 
 import backend.data.block
 import backend.data.db
+import backend.data.graph
 import backend.data.user
 import backend.server.routers.v1
 import backend.util.service
@@ -23,6 +24,7 @@ async def lifespan_context(app: fastapi.FastAPI):
     await backend.data.db.connect()
     await backend.data.block.initialize_blocks()
     await backend.data.user.migrate_and_encrypt_user_integrations()
+    await backend.data.graph.fix_llm_provider_credentials()
     yield
     await backend.data.db.disconnect()
 

--- autogpt_platform/backend/migrations/20241115170707_fix_llm_provider_credentials/migration.sql ---
@@ -0,0 +1,13 @@
+-- Correct credentials.provider field on all nodes with 'llm' provider credentials
+UPDATE ""AgentNode""
+SET    ""constantInput"" = JSONB_SET(
+         ""constantInput""::jsonb,
+         '{credentials,provider}',
+         CASE
+           WHEN ""constantInput""::jsonb->'credentials'->>'id' = '53c25cb8-e3ee-465c-a4d1-e75a4c899c2a' THEN '""openai""'::jsonb
+           WHEN ""constantInput""::jsonb->'credentials'->>'id' = '24e5d942-d9e3-4798-8151-90143ee55629' THEN '""anthropic""'::jsonb
+           WHEN ""constantInput""::jsonb->'credentials'->>'id' = '4ec22295-8f97-4dd1-b42b-2c6957a02545' THEN '""groq""'::jsonb
+           ELSE ""constantInput""::jsonb->'credentials'->'provider'
+         END
+       )::text
+WHERE  ""constantInput""::jsonb->'credentials'->>'provider' = 'llm';",fix
"build(deps-dev): bump the development-dependencies group in /autogpt_platform/backend with 2 updates (#8543)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/backend/poetry.lock ---
@@ -1988,8 +1988,8 @@ python-dateutil = "">=2.5.3""
 tqdm = "">=4.64.1""
 typing-extensions = "">=3.7.4""
 urllib3 = [
-    {version = "">=1.26.0"", markers = ""python_version >= \""3.8\"" and python_version < \""3.12\""""},
     {version = "">=1.26.5"", markers = ""python_version >= \""3.12\"" and python_version < \""4.0\""""},
+    {version = "">=1.26.0"", markers = ""python_version >= \""3.8\"" and python_version < \""3.12\""""},
 ]
 
 [package.extras]
@@ -2285,8 +2285,8 @@ files = [
 annotated-types = "">=0.6.0""
 pydantic-core = ""2.23.4""
 typing-extensions = [
-    {version = "">=4.6.1"", markers = ""python_version < \""3.13\""""},
     {version = "">=4.12.2"", markers = ""python_version >= \""3.13\""""},
+    {version = "">=4.6.1"", markers = ""python_version < \""3.13\""""},
 ]
 
 [package.extras]
@@ -2458,13 +2458,13 @@ diagrams = [""jinja2"", ""railroad-diagrams""]
 
 [[package]]
 name = ""pyright""
-version = ""1.1.386""
+version = ""1.1.387""
 description = ""Command line wrapper for pyright""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""pyright-1.1.386-py3-none-any.whl"", hash = ""sha256:7071ac495593b2258ccdbbf495f1a5c0e5f27951f6b429bed4e8b296eb5cd21d""},
-    {file = ""pyright-1.1.386.tar.gz"", hash = ""sha256:8e9975e34948ba5f8e07792a9c9d2bdceb2c6c0b61742b068d2229ca2bc4a9d9""},
+    {file = ""pyright-1.1.387-py3-none-any.whl"", hash = ""sha256:6a1f495a261a72e12ad17e20d1ae3df4511223c773b19407cfa006229b1b08a5""},
+    {file = ""pyright-1.1.387.tar.gz"", hash = ""sha256:577de60224f7fe36505d5b181231e3a395d427b7873be0bbcaa962a29ea93a60""},
 ]
 
 [package.dependencies]
@@ -2880,29 +2880,29 @@ pyasn1 = "">=0.1.3""
 
 [[package]]
 name = ""ruff""
-version = ""0.7.1""
+version = ""0.7.2""
 description = ""An extremely fast Python linter and code formatter, written in Rust.""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""ruff-0.7.1-py3-none-linux_armv6l.whl"", hash = ""sha256:cb1bc5ed9403daa7da05475d615739cc0212e861b7306f314379d958592aaa89""},
-    {file = ""ruff-0.7.1-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:27c1c52a8d199a257ff1e5582d078eab7145129aa02721815ca8fa4f9612dc35""},
-    {file = ""ruff-0.7.1-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:588a34e1ef2ea55b4ddfec26bbe76bc866e92523d8c6cdec5e8aceefeff02d99""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:94fc32f9cdf72dc75c451e5f072758b118ab8100727168a3df58502b43a599ca""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:985818742b833bffa543a84d1cc11b5e6871de1b4e0ac3060a59a2bae3969250""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:32f1e8a192e261366c702c5fb2ece9f68d26625f198a25c408861c16dc2dea9c""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:699085bf05819588551b11751eff33e9ca58b1b86a6843e1b082a7de40da1565""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:344cc2b0814047dc8c3a8ff2cd1f3d808bb23c6658db830d25147339d9bf9ea7""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:4316bbf69d5a859cc937890c7ac7a6551252b6a01b1d2c97e8fc96e45a7c8b4a""},
-    {file = ""ruff-0.7.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:79d3af9dca4c56043e738a4d6dd1e9444b6d6c10598ac52d146e331eb155a8ad""},
-    {file = ""ruff-0.7.1-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:c5c121b46abde94a505175524e51891f829414e093cd8326d6e741ecfc0a9112""},
-    {file = ""ruff-0.7.1-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:8422104078324ea250886954e48f1373a8fe7de59283d747c3a7eca050b4e378""},
-    {file = ""ruff-0.7.1-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:56aad830af8a9db644e80098fe4984a948e2b6fc2e73891538f43bbe478461b8""},
-    {file = ""ruff-0.7.1-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:658304f02f68d3a83c998ad8bf91f9b4f53e93e5412b8f2388359d55869727fd""},
-    {file = ""ruff-0.7.1-py3-none-win32.whl"", hash = ""sha256:b517a2011333eb7ce2d402652ecaa0ac1a30c114fbbd55c6b8ee466a7f600ee9""},
-    {file = ""ruff-0.7.1-py3-none-win_amd64.whl"", hash = ""sha256:f38c41fcde1728736b4eb2b18850f6d1e3eedd9678c914dede554a70d5241307""},
-    {file = ""ruff-0.7.1-py3-none-win_arm64.whl"", hash = ""sha256:19aa200ec824c0f36d0c9114c8ec0087082021732979a359d6f3c390a6ff2a37""},
-    {file = ""ruff-0.7.1.tar.gz"", hash = ""sha256:9d8a41d4aa2dad1575adb98a82870cf5db5f76b2938cf2206c22c940034a36f4""},
+    {file = ""ruff-0.7.2-py3-none-linux_armv6l.whl"", hash = ""sha256:b73f873b5f52092e63ed540adefc3c36f1f803790ecf2590e1df8bf0a9f72cb8""},
+    {file = ""ruff-0.7.2-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:5b813ef26db1015953daf476202585512afd6a6862a02cde63f3bafb53d0b2d4""},
+    {file = ""ruff-0.7.2-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:853277dbd9675810c6826dad7a428d52a11760744508340e66bf46f8be9701d9""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:21aae53ab1490a52bf4e3bf520c10ce120987b047c494cacf4edad0ba0888da2""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:ccc7e0fc6e0cb3168443eeadb6445285abaae75142ee22b2b72c27d790ab60ba""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:fd77877a4e43b3a98e5ef4715ba3862105e299af0c48942cc6d51ba3d97dc859""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:e00163fb897d35523c70d71a46fbaa43bf7bf9af0f4534c53ea5b96b2e03397b""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:f3c54b538633482dc342e9b634d91168fe8cc56b30a4b4f99287f4e339103e88""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7b792468e9804a204be221b14257566669d1db5c00d6bb335996e5cd7004ba80""},
+    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:dba53ed84ac19ae4bfb4ea4bf0172550a2285fa27fbb13e3746f04c80f7fa088""},
+    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:b19fafe261bf741bca2764c14cbb4ee1819b67adb63ebc2db6401dcd652e3748""},
+    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:28bd8220f4d8f79d590db9e2f6a0674f75ddbc3847277dd44ac1f8d30684b828""},
+    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:9fd67094e77efbea932e62b5d2483006154794040abb3a5072e659096415ae1e""},
+    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:576305393998b7bd6c46018f8104ea3a9cb3fa7908c21d8580e3274a3b04b691""},
+    {file = ""ruff-0.7.2-py3-none-win32.whl"", hash = ""sha256:fa993cfc9f0ff11187e82de874dfc3611df80852540331bc85c75809c93253a8""},
+    {file = ""ruff-0.7.2-py3-none-win_amd64.whl"", hash = ""sha256:dd8800cbe0254e06b8fec585e97554047fb82c894973f7ff18558eee33d1cb88""},
+    {file = ""ruff-0.7.2-py3-none-win_arm64.whl"", hash = ""sha256:bb8368cd45bba3f57bb29cbb8d64b4a33f8415d0149d2655c5c8539452ce7760""},
+    {file = ""ruff-0.7.2.tar.gz"", hash = ""sha256:2b14e77293380e475b4e3a7a368e14549288ed2931fce259a6f99978669e844f""},
 ]
 
 [[package]]
@@ -3880,4 +3880,4 @@ type = [""pytest-mypy""]
 [metadata]
 lock-version = ""2.0""
 python-versions = ""^3.10""
-content-hash = ""00069717c4818aa24b164e3c00a104d559c2fb16c531f60bccfcf5a69fb553c8""
+content-hash = ""bbad5245c6bd3cd1d93d9f047b65e40beda081d83c2eed59eed508c41a9b5ff1""

--- autogpt_platform/backend/pyproject.toml ---
@@ -52,8 +52,8 @@ poethepoet = ""^0.29.0""
 httpx = ""^0.27.0""
 pytest-watcher = ""^0.4.2""
 requests = ""^2.32.3""
-ruff = ""^0.7.1""
-pyright = ""^1.1.386""
+ruff = ""^0.7.2""
+pyright = ""^1.1.387""
 isort = ""^5.13.2""
 black = ""^24.10.0""
 aiohappyeyeballs = ""^2.4.3""",build
"fix(rnd): Update port in market (#8036)

update port","--- rnd/infra/helm/autogpt-market/values.dev.yaml ---
@@ -13,7 +13,7 @@ serviceAccount:
 service:
   type: ClusterIP
   port: 8000
-  targetPort: 8000
+  targetPort: 8005
   annotations:
     cloud.google.com/neg: '{""ingress"": true}'
     beta.cloud.google.com/backend-config: '{""default"": ""autogpt-market""}'",fix
"fix(builder): Prevent zooming on input field modal

- Add `nowheel` class to Textarea parent div","--- rnd/autogpt_builder/src/components/InputModalComponent.tsx ---
@@ -62,7 +62,7 @@ const InputModalComponent: FC<ModalProps> = ({
       <h2 className=""mb-4 text-center text-lg font-semibold"">
         {title || ""Enter input text""}
       </h2>
-      <div className=""relative flex-grow"">
+      <div className=""nowheel relative flex-grow"">
         <Textarea
           className=""h-full min-h-[200px] w-full resize-none""
           value={tempValue}",fix
"build(deps-dev): bump ruff from 0.7.3 to 0.7.4 in /autogpt_platform/autogpt_libs in the development-dependencies group (#8701)

build(deps-dev): bump ruff

Bumps the development-dependencies group in /autogpt_platform/autogpt_libs with 1 update: [ruff](https://github.com/astral-sh/ruff).


Updates `ruff` from 0.7.3 to 0.7.4
- [Release notes](https://github.com/astral-sh/ruff/releases)
- [Changelog](https://github.com/astral-sh/ruff/blob/main/CHANGELOG.md)
- [Commits](https://github.com/astral-sh/ruff/compare/0.7.3...0.7.4)

---
updated-dependencies:
- dependency-name: ruff
  dependency-type: direct:development
  update-type: version-update:semver-patch
  dependency-group: development-dependencies
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/autogpt_libs/poetry.lock ---
@@ -1324,29 +1324,29 @@ pyasn1 = "">=0.1.3""
 
 [[package]]
 name = ""ruff""
-version = ""0.7.3""
+version = ""0.7.4""
 description = ""An extremely fast Python linter and code formatter, written in Rust.""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""ruff-0.7.3-py3-none-linux_armv6l.whl"", hash = ""sha256:34f2339dc22687ec7e7002792d1f50712bf84a13d5152e75712ac08be565d344""},
-    {file = ""ruff-0.7.3-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:fb397332a1879b9764a3455a0bb1087bda876c2db8aca3a3cbb67b3dbce8cda0""},
-    {file = ""ruff-0.7.3-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:37d0b619546103274e7f62643d14e1adcbccb242efda4e4bdb9544d7764782e9""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:5d59f0c3ee4d1a6787614e7135b72e21024875266101142a09a61439cb6e38a5""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:44eb93c2499a169d49fafd07bc62ac89b1bc800b197e50ff4633aed212569299""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:6d0242ce53f3a576c35ee32d907475a8d569944c0407f91d207c8af5be5dae4e""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:6b6224af8b5e09772c2ecb8dc9f3f344c1aa48201c7f07e7315367f6dd90ac29""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:c50f95a82b94421c964fae4c27c0242890a20fe67d203d127e84fbb8013855f5""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7f3eff9961b5d2644bcf1616c606e93baa2d6b349e8aa8b035f654df252c8c67""},
-    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:b8963cab06d130c4df2fd52c84e9f10d297826d2e8169ae0c798b6221be1d1d2""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:61b46049d6edc0e4317fb14b33bd693245281a3007288b68a3f5b74a22a0746d""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:10ebce7696afe4644e8c1a23b3cf8c0f2193a310c18387c06e583ae9ef284de2""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:3f36d56326b3aef8eeee150b700e519880d1aab92f471eefdef656fd57492aa2""},
-    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:5d024301109a0007b78d57ab0ba190087b43dce852e552734ebf0b0b85e4fb16""},
-    {file = ""ruff-0.7.3-py3-none-win32.whl"", hash = ""sha256:4ba81a5f0c5478aa61674c5a2194de8b02652f17addf8dfc40c8937e6e7d79fc""},
-    {file = ""ruff-0.7.3-py3-none-win_amd64.whl"", hash = ""sha256:588a9ff2fecf01025ed065fe28809cd5a53b43505f48b69a1ac7707b1b7e4088""},
-    {file = ""ruff-0.7.3-py3-none-win_arm64.whl"", hash = ""sha256:1713e2c5545863cdbfe2cbce21f69ffaf37b813bfd1fb3b90dc9a6f1963f5a8c""},
-    {file = ""ruff-0.7.3.tar.gz"", hash = ""sha256:e1d1ba2e40b6e71a61b063354d04be669ab0d39c352461f3d789cac68b54a313""},
+    {file = ""ruff-0.7.4-py3-none-linux_armv6l.whl"", hash = ""sha256:a4919925e7684a3f18e18243cd6bea7cfb8e968a6eaa8437971f681b7ec51478""},
+    {file = ""ruff-0.7.4-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:cfb365c135b830778dda8c04fb7d4280ed0b984e1aec27f574445231e20d6c63""},
+    {file = ""ruff-0.7.4-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:63a569b36bc66fbadec5beaa539dd81e0527cb258b94e29e0531ce41bacc1f20""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:0d06218747d361d06fd2fdac734e7fa92df36df93035db3dc2ad7aa9852cb109""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:e0cea28d0944f74ebc33e9f934238f15c758841f9f5edd180b5315c203293452""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:80094ecd4793c68b2571b128f91754d60f692d64bc0d7272ec9197fdd09bf9ea""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:997512325c6620d1c4c2b15db49ef59543ef9cd0f4aa8065ec2ae5103cedc7e7""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:00b4cf3a6b5fad6d1a66e7574d78956bbd09abfd6c8a997798f01f5da3d46a05""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7dbdc7d8274e1422722933d1edddfdc65b4336abf0b16dfcb9dedd6e6a517d06""},
+    {file = ""ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:0e92dfb5f00eaedb1501b2f906ccabfd67b2355bdf117fea9719fc99ac2145bc""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:3bd726099f277d735dc38900b6a8d6cf070f80828877941983a57bca1cd92172""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:2e32829c429dd081ee5ba39aef436603e5b22335c3d3fff013cd585806a6486a""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:662a63b4971807623f6f90c1fb664613f67cc182dc4d991471c23c541fee62dd""},
+    {file = ""ruff-0.7.4-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:876f5e09eaae3eb76814c1d3b68879891d6fde4824c015d48e7a7da4cf066a3a""},
+    {file = ""ruff-0.7.4-py3-none-win32.whl"", hash = ""sha256:75c53f54904be42dd52a548728a5b572344b50d9b2873d13a3f8c5e3b91f5cac""},
+    {file = ""ruff-0.7.4-py3-none-win_amd64.whl"", hash = ""sha256:745775c7b39f914238ed1f1b0bebed0b9155a17cd8bc0b08d3c87e4703b990d6""},
+    {file = ""ruff-0.7.4-py3-none-win_arm64.whl"", hash = ""sha256:11bff065102c3ae9d3ea4dc9ecdfe5a5171349cdd0787c1fc64761212fc9cf1f""},
+    {file = ""ruff-0.7.4.tar.gz"", hash = ""sha256:cd12e35031f5af6b9b93715d8c4f40360070b2041f81273d0527683d5708fce2""},
 ]
 
 [[package]]
@@ -1750,4 +1750,4 @@ type = [""pytest-mypy""]
 [metadata]
 lock-version = ""2.0""
 python-versions = "">=3.10,<4.0""
-content-hash = ""d4832e28357e45796e63f4b0f450a3a4953f8f3e536e0dc378b6970c3c94243d""
+content-hash = ""48184ad1281689c7743b8ca23135a647dc52257d54702d88b043fe31fe27ff27""

--- autogpt_platform/autogpt_libs/pyproject.toml ---
@@ -19,7 +19,7 @@ supabase = ""^2.10.0""
 
 [tool.poetry.group.dev.dependencies]
 redis = ""^5.2.0""
-ruff = ""^0.7.3""
+ruff = ""^0.7.4""
 
 [build-system]
 requires = [""poetry-core""]",build
"build(platform/dockercompose): Put removed services back in (#8386)

put removed services back in","--- autogpt_platform/docker-compose.yml ---
@@ -96,6 +96,37 @@ services:
       file: ./supabase/docker/docker-compose.yml
       service: rest
 
+
+  realtime:
+    <<: *supabase-services
+    extends:
+      file: ./supabase/docker/docker-compose.yml
+      service: realtime
+
+  storage:
+    <<: *supabase-services
+    extends:
+      file: ./supabase/docker/docker-compose.yml
+      service: storage
+
+  imgproxy:
+    <<: *supabase-services
+    extends:
+      file: ./supabase/docker/docker-compose.yml
+      service: imgproxy
+
+  meta:
+    <<: *supabase-services
+    extends:
+      file: ./supabase/docker/docker-compose.yml
+      service: meta
+
+  functions:
+    <<: *supabase-services
+    extends:
+      file: ./supabase/docker/docker-compose.yml
+      service: functions
+
   analytics:
     <<: *supabase-services
     extends:",build
"fix(backend): Add migrations to fix credentials inputs with invalid provider ""llm""(#8674)

In #8524, the ""llm"" credentials provider was replaced. There are still entries with 	""provider"": ""llm""	 in the system though, and those break if not migrated.

- SQL migration to fix the obvious ones where we know the provider from `credentials.id`
- Non-SQL migration to fix the rest","--- autogpt_platform/backend/backend/data/graph.py ---
@@ -5,6 +5,7 @@
 from datetime import datetime, timezone
 from typing import Any, Literal, Type
 
+import prisma
 from prisma.models import AgentGraph, AgentGraphExecution, AgentNode, AgentNodeLink
 from prisma.types import AgentGraphWhereInput
 from pydantic.fields import computed_field
@@ -528,3 +529,84 @@ async def __create_graph(tx, graph: Graph, user_id: str):
             for link in graph.links
         ]
     )
+
+
+# ------------------------ UTILITIES ------------------------ #
+
+
+async def fix_llm_provider_credentials():
+    """"""Fix node credentials with provider `llm`""""""
+    from autogpt_libs.supabase_integration_credentials_store import (
+        SupabaseIntegrationCredentialsStore,
+    )
+
+    from .redis import get_redis
+    from .user import get_user_integrations
+
+    store = SupabaseIntegrationCredentialsStore(get_redis())
+
+    broken_nodes = await prisma.get_client().query_raw(
+        """"""
+        SELECT    user.id              user_id,
+                  node.id              node_id,
+                  node.""constantInput"" node_preset_input
+        FROM      platform.""AgentGraph"" graph
+        LEFT JOIN platform.""AgentNode""  node
+        ON        node.""agentGraphId"" = graph.id
+        LEFT JOIN platform.""User""       user
+        ON        graph.""userId"" = user.id
+        WHERE     node.""constantInput""::jsonb->'credentials'->>'provider' = 'llm'
+        ORDER BY user_id;
+    """"""
+    )
+    logger.info(f""Fixing LLM credential inputs on {len(broken_nodes)} nodes"")
+
+    user_id: str = """"
+    user_integrations = None
+    for node in broken_nodes:
+        if node[""user_id""] != user_id:
+            # Save queries by only fetching once per user
+            user_id = node[""user_id""]
+            user_integrations = await get_user_integrations(user_id)
+        elif not user_integrations:
+            raise RuntimeError(f""Impossible state while processing node {node}"")
+
+        node_id: str = node[""node_id""]
+        node_preset_input: dict = json.loads(node[""node_preset_input""])
+        credentials_meta: dict = node_preset_input[""credentials""]
+
+        credentials = next(
+            (
+                c
+                for c in user_integrations.credentials
+                if c.id == credentials_meta[""id""]
+            ),
+            None,
+        )
+        if not credentials:
+            continue
+        if credentials.type != ""api_key"":
+            logger.warning(
+                f""User {user_id} credentials {credentials.id} with provider 'llm' ""
+                f""has invalid type '{credentials.type}'""
+            )
+            continue
+
+        api_key = credentials.api_key.get_secret_value()
+        if api_key.startswith(""sk-ant-api03-""):
+            credentials.provider = credentials_meta[""provider""] = ""anthropic""
+        elif api_key.startswith(""sk-""):
+            credentials.provider = credentials_meta[""provider""] = ""openai""
+        elif api_key.startswith(""gsk_""):
+            credentials.provider = credentials_meta[""provider""] = ""groq""
+        else:
+            logger.warning(
+                f""Could not identify provider from key prefix {api_key[:13]}*****""
+            )
+            continue
+
+        store.update_creds(user_id, credentials)
+        await AgentNode.prisma().update(
+            where={""id"": node_id},
+            data={""constantInput"": json.dumps(node_preset_input)},
+        )

--- autogpt_platform/backend/backend/server/rest_api.py ---
@@ -9,6 +9,7 @@
 
 import backend.data.block
 import backend.data.db
+import backend.data.graph
 import backend.data.user
 import backend.server.routers.v1
 import backend.util.service
@@ -23,6 +24,7 @@ async def lifespan_context(app: fastapi.FastAPI):
     await backend.data.db.connect()
     await backend.data.block.initialize_blocks()
     await backend.data.user.migrate_and_encrypt_user_integrations()
+    await backend.data.graph.fix_llm_provider_credentials()
     yield
     await backend.data.db.disconnect()
 

--- autogpt_platform/backend/migrations/20241115170707_fix_llm_provider_credentials/migration.sql ---
@@ -0,0 +1,13 @@
+-- Correct credentials.provider field on all nodes with 'llm' provider credentials
+UPDATE ""AgentNode""
+SET    ""constantInput"" = JSONB_SET(
+         ""constantInput""::jsonb,
+         '{credentials,provider}',
+         CASE
+           WHEN ""constantInput""::jsonb->'credentials'->>'id' = '53c25cb8-e3ee-465c-a4d1-e75a4c899c2a' THEN '""openai""'::jsonb
+           WHEN ""constantInput""::jsonb->'credentials'->>'id' = '24e5d942-d9e3-4798-8151-90143ee55629' THEN '""anthropic""'::jsonb
+           WHEN ""constantInput""::jsonb->'credentials'->>'id' = '4ec22295-8f97-4dd1-b42b-2c6957a02545' THEN '""groq""'::jsonb
+           ELSE (""constantInput""::jsonb->'credentials'->>'provider')::jsonb
+         END
+       )::text
+WHERE  ""constantInput""::jsonb->'credentials'->>'provider' = 'llm';",fix
"feat(infra): Add prod redis values (#8202)

add redis production values","--- autogpt_platform/infra/helm/redis-values.prod.yaml ---
@@ -0,0 +1,15 @@
+architecture: standalone
+auth:
+  enabled: true
+  password: """" #empty on purpose
+master:
+  persistence:
+    enabled: true
+    size: 3Gi
+  configmap:
+    redis.conf: |
+      bind 127.0.0.1
+      protected-mode yes
+      requirepass password
+replica:
+  replicaCount: 0
\ No newline at end of file",feat
"build(deps): bump date-fns from 3.6.0 to 4.1.0 in /autogpt_platform/frontend (#8550)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/frontend/package.json ---
@@ -49,7 +49,7 @@
     ""class-variance-authority"": ""^0.7.0"",
     ""clsx"": ""^2.1.1"",
     ""cmdk"": ""1.0.4"",
-    ""date-fns"": ""^3.6.0"",
+    ""date-fns"": ""^4.1.0"",
     ""dotenv"": ""^16.4.5"",
     ""lucide-react"": ""^0.454.0"",
     ""moment"": ""^2.30.1"",

--- autogpt_platform/frontend/yarn.lock ---
@@ -5592,11 +5592,6 @@ data-view-byte-offset@^1.0.0:
     es-errors ""^1.3.0""
     is-data-view ""^1.0.1""
 
-date-fns@^3.6.0:
-  version ""3.6.0""
-  resolved ""https://registry.npmjs.org/date-fns/-/date-fns-3.6.0.tgz""
-  integrity sha512-fRHTG8g/Gif+kSh50gaGEdToemgfj74aRX3swtiouboip5JDLAyDE9F11nHMIcvOaXeOC6D7SpNhi7uFyB7Uww==
-
 date-fns@^4.1.0:
   version ""4.1.0""
   resolved ""https://registry.yarnpkg.com/date-fns/-/date-fns-4.1.0.tgz#64b3d83fff5aa80438f5b1a633c2e83b8a1c2d14""",build
docs(platform): correct readme,"--- autogpt_platform/README.md ---
@@ -28,9 +28,9 @@ To run the AutoGPT Platform, follow these steps:
 
 3. Run the following command:
    ```
-   cp supabase/docker/.env.example .env.local
+   cp supabase/docker/.env.example .env
    ```
-   This command will copy the `.env.example` file to `.env.local` in the `supabase/docker` directory. You can modify the `.env.local` file to add your own environment variables.
+   This command will copy the `.env.example` file to `.env` in the `supabase/docker` directory. You can modify the `.env` file to add your own environment variables.
 
 4. Run the following command:
    ```
@@ -46,9 +46,9 @@ To run the AutoGPT Platform, follow these steps:
 
 6. Run the following command: 
    ```
-   cp .env.example .env
+   cp .env.example .env.local
    ```
-   This command will copy the `.env.example` file to `.env` in the `frontend` directory. You can modify the `.env` within this folder to add your own environment variables for the frontend application.
+   This command will copy the `.env.example` file to `.env.local` in the `frontend` directory. You can modify the `.env.local` within this folder to add your own environment variables for the frontend application.
 
 7. Run the following command:
    ```",docs
"fix(block): Updated model_version to prevent conflicts with pydantic naming (#8729)

changed model_version name to avoid conflicts","--- autogpt_platform/backend/backend/blocks/ai_music_generator.py ---
@@ -63,7 +63,7 @@ class Input(BlockSchema):
             placeholder=""e.g., 'An upbeat electronic dance track with heavy bass'"",
             title=""Prompt"",
         )
-        model_version: MusicGenModelVersion = SchemaField(
+        music_gen_model_version: MusicGenModelVersion = SchemaField(
             description=""Model to use for generation"",
             default=MusicGenModelVersion.STEREO_LARGE,
             title=""Model Version"",
@@ -118,7 +118,7 @@ def __init__(self):
             test_input={
                 ""credentials"": TEST_CREDENTIALS_INPUT,
                 ""prompt"": ""An upbeat electronic dance track with heavy bass"",
-                ""model_version"": MusicGenModelVersion.STEREO_LARGE,
+                ""music_gen_model_version"": MusicGenModelVersion.STEREO_LARGE,
                 ""duration"": 8,
                 ""temperature"": 1.0,
                 ""top_k"": 250,
@@ -134,7 +134,7 @@ def __init__(self):
                 ),
             ],
             test_mock={
-                ""run_model"": lambda api_key, model_version, prompt, duration, temperature, top_k, top_p, classifier_free_guidance, output_format, normalization_strategy: ""https://replicate.com/output/generated-audio-url.wav"",
+                ""run_model"": lambda api_key, music_gen_model_version, prompt, duration, temperature, top_k, top_p, classifier_free_guidance, output_format, normalization_strategy: ""https://replicate.com/output/generated-audio-url.wav"",
             },
             test_credentials=TEST_CREDENTIALS,
         )
@@ -153,7 +153,7 @@ def run(
                 )
                 result = self.run_model(
                     api_key=credentials.api_key,
-                    model_version=input_data.model_version,
+                    music_gen_model_version=input_data.music_gen_model_version,
                     prompt=input_data.prompt,
                     duration=input_data.duration,
                     temperature=input_data.temperature,
@@ -182,7 +182,7 @@ def run(
     def run_model(
         self,
         api_key: SecretStr,
-        model_version: MusicGenModelVersion,
+        music_gen_model_version: MusicGenModelVersion,
         prompt: str,
         duration: int,
         temperature: float,
@@ -200,7 +200,7 @@ def run_model(
             ""meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb"",
             input={
                 ""prompt"": prompt,
-                ""model_version"": model_version,
+                ""music_gen_model_version"": music_gen_model_version,
                 ""duration"": duration,
                 ""temperature"": temperature,
                 ""top_k"": top_k,",fix
build(backend): Reduce number of services on the local mode (#8563),"--- autogpt_platform/docker-compose.yml ---
@@ -150,8 +150,10 @@ services:
     image: busybox
     command: /bin/true
     depends_on:
+      - studio
       - kong
       - auth
+      - meta
       - analytics
       - db
       - vector",build
"build(platform/infra): Create prod service account and pool (#8383)

* ci with workload identity

* temp update

* update name

* wip

* update auth step

* update provider name

* remove audience

* temp set to false

* update registry naming

* update context

* update login

* revert temp updates

* add prod iam and pool","--- autogpt_platform/infra/terraform/environments/prod.tfvars ---
@@ -28,6 +28,11 @@ service_accounts = {
    ""prod-agpt-market-sa"" = {
     display_name = ""AutoGPT prod Market backend Account""
     description  = ""Service account for agpt prod market backend""
+  },
+  ""prod-github-actions-workload-identity"" = {
+    service_account_name = ""prod-github-actions-sa""
+    namespace            = ""prod-agpt""
+    ksa_name             = ""prod-github-actions-sa""
   }
 }
 
@@ -59,7 +64,8 @@ role_bindings = {
     ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
     ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
     ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
-    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
   ],
   ""roles/cloudsql.client"" = [
     ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
@@ -80,7 +86,8 @@ role_bindings = {
     ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
     ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
     ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
-    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+    ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com"",
+    ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
   ]
   ""roles/compute.networkUser"" = [
     ""serviceAccount:prod-agpt-backend-sa@agpt-prod.iam.gserviceaccount.com"",
@@ -93,6 +100,16 @@ role_bindings = {
     ""serviceAccount:prod-agpt-frontend-sa@agpt-prod.iam.gserviceaccount.com"",
     ""serviceAccount:prod-agpt-ws-backend-sa@agpt-prod.iam.gserviceaccount.com"",
     ""serviceAccount:prod-agpt-market-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/artifactregistry.writer"" = [
+    ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/container.viewer"" = [
+    ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
+  ],
+  ""roles/iam.serviceAccountTokenCreator"" = [
+    ""principalSet://iam.googleapis.com/projects/638488734936/locations/global/workloadIdentityPools/prod-pool/*"",
+    ""serviceAccount:prod-github-actions-sa@agpt-prod.iam.gserviceaccount.com""
   ]
 }
 
@@ -101,4 +118,25 @@ services_ip_cidr_range = ""10.2.0.0/20""
 
 public_bucket_names = [""website-artifacts""]
 standard_bucket_names = []
-bucket_admins = [""gcp-devops-agpt@agpt.co"", ""gcp-developers@agpt.co""]
\ No newline at end of file
+bucket_admins = [""gcp-devops-agpt@agpt.co"", ""gcp-developers@agpt.co""]
+
+workload_identity_pools = {
+  ""dev-pool"" = {
+    display_name = ""Production Identity Pool""
+    providers = {
+      ""github"" = {
+        issuer_uri = ""https://token.actions.githubusercontent.com""
+        attribute_mapping = {
+          ""google.subject"" = ""assertion.sub""
+          ""attribute.repository"" = ""assertion.repository""
+          ""attribute.repository_owner"" = ""assertion.repository_owner""
+        }
+      }
+    }
+    service_accounts = {
+      ""prod-github-actions-sa"" = [
+        ""Significant-Gravitas/AutoGPT""
+      ]
+    }
+  }
+}
\ No newline at end of file",build
"fix(platform): Always filter on user id (#8275)

* always filter on user id

* add user id to doc string

* fix linting

* fix imports function","--- autogpt_platform/backend/backend/data/graph.py ---
@@ -382,9 +382,9 @@ async def get_node(node_id: str) -> Node:
 
 
 async def get_graphs_meta(
+    user_id: str,
     include_executions: bool = False,
     filter_by: Literal[""active"", ""template""] | None = ""active"",
-    user_id: str | None = None,
 ) -> list[GraphMeta]:
     """"""
     Retrieves graph metadata objects.
@@ -393,6 +393,7 @@ async def get_graphs_meta(
     Args:
         include_executions: Whether to include executions in the graph metadata.
         filter_by: An optional filter to either select templates or active graphs.
+        user_id: The ID of the user that owns the graph.
 
     Returns:
         list[GraphMeta]: A list of objects representing the retrieved graph metadata.
@@ -404,8 +405,7 @@ async def get_graphs_meta(
     elif filter_by == ""template"":
         where_clause[""isTemplate""] = True
 
-    if user_id and filter_by != ""template"":
-        where_clause[""userId""] = user_id
+    where_clause[""userId""] = user_id
 
     graphs = await AgentGraph.prisma().find_many(
         where=where_clause,
@@ -585,7 +585,9 @@ async def __create_graph(tx, graph: Graph, user_id: str):
 
 
 async def import_packaged_templates() -> None:
-    templates_in_db = await get_graphs_meta(filter_by=""template"")
+    templates_in_db = await get_graphs_meta(
+        user_id=DEFAULT_USER_ID, filter_by=""template""
+    )
 
     logging.info(""Loading templates..."")
     for template_file in TEMPLATES_DIR.glob(""*.json""):",fix
"feat(builder): Block UI Types and StickyNote (#7994)

* Add Block UI Types and StickyNote Block

* Renamed StickyNote to Note

* Add comment",,feat
"build(deps-dev): bump @chromatic-com/storybook from 1.9.0 to 3.2.2 in /autogpt_platform/frontend (#8551)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- autogpt_platform/frontend/package.json ---
@@ -70,7 +70,7 @@
     ""zod"": ""^3.23.8""
   },
   ""devDependencies"": {
-    ""@chromatic-com/storybook"": ""^1.9.0"",
+    ""@chromatic-com/storybook"": ""^3.2.2"",
     ""@playwright/test"": ""^1.48.2"",
     ""@storybook/addon-essentials"": ""^8.4.1"",
     ""@storybook/addon-interactions"": ""^8.4.1"",

--- autogpt_platform/frontend/yarn.lock ---
@@ -1015,12 +1015,12 @@
   resolved ""https://registry.npmjs.org/@bcoe/v8-coverage/-/v8-coverage-0.2.3.tgz""
   integrity sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==
 
-""@chromatic-com/storybook@^1.9.0"":
-  version ""1.9.0""
-  resolved ""https://registry.npmjs.org/@chromatic-com/storybook/-/storybook-1.9.0.tgz""
-  integrity sha512-vYQ+TcfktEE3GHnLZXHCzXF/sN9dw+KivH8a5cmPyd9YtQs7fZtHrEgsIjWpYycXiweKMo1Lm1RZsjxk8DH3rA==
+""@chromatic-com/storybook@^3.2.2"":
+  version ""3.2.2""
+  resolved ""https://registry.yarnpkg.com/@chromatic-com/storybook/-/storybook-3.2.2.tgz#08754443de55618f802f88450c35266fd6d25db5""
+  integrity sha512-xmXt/GW0hAPbzNTrxYuVo43Adrtjue4DeVrsoIIEeJdGaPNNeNf+DHMlJKOBdlHmCnFUoe9R/0mLM9zUp5bKWw==
   dependencies:
-    chromatic ""^11.4.0""
+    chromatic ""^11.15.0""
     filesize ""^10.0.12""
     jsonfile ""^6.1.0""
     react-confetti ""^6.1.0""
@@ -4856,10 +4856,10 @@ chokidar@^3.5.3:
   optionalDependencies:
     fsevents ""~2.3.2""
 
-chromatic@^11.4.0:
-  version ""11.12.5""
-  resolved ""https://registry.npmjs.org/chromatic/-/chromatic-11.12.5.tgz""
-  integrity sha512-5z+BXQy3TMyXIzCdCDO9Psc8aMs9kIrCFHhMgYbwA6dTXxAL0oUjHZbICn5h4Ay/fM9cZQPaCH9T7a3myPA8Sw==
+chromatic@^11.15.0:
+  version ""11.16.5""
+  resolved ""https://registry.yarnpkg.com/chromatic/-/chromatic-11.16.5.tgz#edbc6e407f7d0158e8395896deab194fb0a5ff94""
+  integrity sha512-wUEKXyu3GYmUg6Jq13uyRE9iC8ph5gbfDHdyHH0vQathkGQrcjHHdoxI/GXKIjU6d+xupLon8sxRV9NuZKTWbA==
 
 chrome-trace-event@^1.0.2:
   version ""1.0.4""",build
feat(blocks): Add text to speech block and Unreal Speech API key (#8264),"--- autogpt_platform/backend/backend/blocks/text_to_speech_block.py ---
@@ -0,0 +1,79 @@
+from typing import Any
+
+import requests
+
+from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema
+from backend.data.model import BlockSecret, SchemaField, SecretField
+
+
+class UnrealTextToSpeechBlock(Block):
+    class Input(BlockSchema):
+        text: str = SchemaField(
+            description=""The text to be converted to speech"",
+            placeholder=""Enter the text you want to convert to speech"",
+        )
+        voice_id: str = SchemaField(
+            description=""The voice ID to use for text-to-speech conversion"",
+            placeholder=""Scarlett"",
+            default=""Scarlett"",
+        )
+        api_key: BlockSecret = SecretField(
+            key=""unreal_speech_api_key"", description=""Your Unreal Speech API key""
+        )
+
+    class Output(BlockSchema):
+        mp3_url: str = SchemaField(description=""The URL of the generated MP3 file"")
+        error: str = SchemaField(description=""Error message if the API call failed"")
+
+    def __init__(self):
+        super().__init__(
+            id=""4ff1ff6d-cc40-4caa-ae69-011daa20c378"",
+            description=""Converts text to speech using the Unreal Speech API"",
+            categories={BlockCategory.AI, BlockCategory.TEXT},
+            input_schema=UnrealTextToSpeechBlock.Input,
+            output_schema=UnrealTextToSpeechBlock.Output,
+            test_input={
+                ""text"": ""This is a test of the text to speech API."",
+                ""voice_id"": ""Scarlett"",
+                ""api_key"": ""test_api_key"",
+            },
+            test_output=[(""mp3_url"", ""https://example.com/test.mp3"")],
+            test_mock={
+                ""call_unreal_speech_api"": lambda *args, **kwargs: {
+                    ""OutputUri"": ""https://example.com/test.mp3""
+                }
+            },
+        )
+
+    @staticmethod
+    def call_unreal_speech_api(
+        api_key: str, text: str, voice_id: str
+    ) -> dict[str, Any]:
+        url = ""https://api.v7.unrealspeech.com/speech""
+        headers = {
+            ""Authorization"": f""Bearer {api_key}"",
+            ""Content-Type"": ""application/json"",
+        }
+        data = {
+            ""Text"": text,
+            ""VoiceId"": voice_id,
+            ""Bitrate"": ""192k"",
+            ""Speed"": ""0"",
+            ""Pitch"": ""1"",
+            ""TimestampType"": ""sentence"",
+        }
+
+        response = requests.post(url, headers=headers, json=data)
+        response.raise_for_status()
+        return response.json()
+
+    def run(self, input_data: Input, **kwargs) -> BlockOutput:
+        try:
+            api_response = self.call_unreal_speech_api(
+                input_data.api_key.get_secret_value(),
+                input_data.text,
+                input_data.voice_id,
+            )
+            yield ""mp3_url"", api_response[""OutputUri""]
+        except Exception as e:
+            yield ""error"", str(e)

--- autogpt_platform/backend/backend/util/settings.py ---
@@ -219,8 +219,9 @@ class Secrets(UpdateTrackingModel[""Secrets""], BaseSettings):
     google_maps_api_key: str = Field(default="""", description=""Google Maps API Key"")
 
     replicate_api_key: str = Field(default="""", description=""Replicate API Key"")
-
+    unreal_speech_api_key: str = Field(default="""", description=""Unreal Speech API Key"")
     ideogram_api_key: str = Field(default="""", description=""Ideogram API Key"")
+
     # Add more secret fields as needed
 
     model_config = SettingsConfigDict(",feat
fix(rnd): avoid duplicating name on input/output pin for blocks (#7979),"--- rnd/autogpt_server/autogpt_server/blocks/__init__.py ---
@@ -54,6 +54,15 @@ def all_subclasses(clz):
     if block.id in AVAILABLE_BLOCKS:
         raise ValueError(f""Block ID {block.name} error: {block.id} is already in use"")
 
+    # Prevent duplicate field name in input_schema and output_schema
+    duplicate_field_names = set(block.input_schema.__fields__.keys()) & set(
+        block.output_schema.__fields__.keys()
+    )
+    if duplicate_field_names:
+        raise ValueError(
+            f""{block.name} has duplicate field names in input_schema and output_schema: {duplicate_field_names}""
+        )
+
     for field in block.input_schema.__fields__.values():
         if field.annotation is bool and field.default not in (True, False):
             raise ValueError(f""{block.name} has a boolean field with no default value"")

--- rnd/autogpt_server/autogpt_server/blocks/basic.py ---
@@ -140,7 +140,7 @@ class InputOutputBlockInput(BlockSchema, Generic[T]):
 
 
 class InputOutputBlockOutput(BlockSchema, Generic[T]):
-    value: T = Field(description=""The value passed as input/output."")
+    result: T = Field(description=""The value passed as input/output."")
 
 
 class InputOutputBlockBase(Block, ABC, Generic[T]):
@@ -162,16 +162,16 @@ def __init__(self, *args, **kwargs):
                 {""value"": MockObject(value=""!!"", key=""key""), ""name"": ""input_2""},
             ],
             test_output=[
-                (""value"", {""apple"": 1, ""banana"": 2, ""cherry"": 3}),
-                (""value"", MockObject(value=""!!"", key=""key"")),
+                (""result"", {""apple"": 1, ""banana"": 2, ""cherry"": 3}),
+                (""result"", MockObject(value=""!!"", key=""key"")),
             ],
             static_output=True,
             *args,
             **kwargs,
         )
 
     def run(self, input_data: InputOutputBlockInput[T]) -> BlockOutput:
-        yield ""value"", input_data.value
+        yield ""result"", input_data.value
 
 
 class InputBlock(InputOutputBlockBase[Any]):

--- rnd/autogpt_server/autogpt_server/blocks/medium.py ---
@@ -57,7 +57,6 @@ class Input(BlockSchema):
     class Output(BlockSchema):
         post_id: str = SchemaField(description=""The ID of the created Medium post"")
         post_url: str = SchemaField(description=""The URL of the created Medium post"")
-        author_id: str = SchemaField(description=""The Medium user ID of the author"")
         published_at: int = SchemaField(
             description=""The timestamp when the post was published""
         )
@@ -85,7 +84,6 @@ def __init__(self):
             test_output=[
                 (""post_id"", ""e6f36a""),
                 (""post_url"", ""https://medium.com/@username/test-post-e6f36a""),
-                (""author_id"", ""1234567890abcdef""),
                 (""published_at"", 1626282600),
             ],
             test_mock={
@@ -156,7 +154,6 @@ def run(self, input_data: Input) -> BlockOutput:
             if ""data"" in response:
                 yield ""post_id"", response[""data""][""id""]
                 yield ""post_url"", response[""data""][""url""]
-                yield ""author_id"", response[""data""][""authorId""]
                 yield ""published_at"", response[""data""][""publishedAt""]
             else:
                 error_message = response.get(""errors"", [{}])[0].get(

--- rnd/autogpt_server/autogpt_server/blocks/time_blocks.py ---
@@ -103,14 +103,14 @@ def run(self, input_data: Input) -> BlockOutput:
 
 class CountdownTimerBlock(Block):
     class Input(BlockSchema):
-        message: Any = ""timer finished""
+        input_message: Any = ""timer finished""
         seconds: Union[int, str] = 0
         minutes: Union[int, str] = 0
         hours: Union[int, str] = 0
         days: Union[int, str] = 0
 
     class Output(BlockSchema):
-        message: str
+        output_message: str
 
     def __init__(self):
         super().__init__(
@@ -121,11 +121,11 @@ def __init__(self):
             output_schema=CountdownTimerBlock.Output,
             test_input=[
                 {""seconds"": 1},
-                {""message"": ""Custom message""},
+                {""input_message"": ""Custom message""},
             ],
             test_output=[
-                (""message"", ""timer finished""),
-                (""message"", ""Custom message""),
+                (""output_message"", ""timer finished""),
+                (""output_message"", ""Custom message""),
             ],
         )
 
@@ -139,4 +139,4 @@ def run(self, input_data: Input) -> BlockOutput:
         total_seconds = seconds + minutes * 60 + hours * 3600 + days * 86400
 
         time.sleep(total_seconds)
-        yield ""message"", input_data.message
+        yield ""output_message"", input_data.input_message

--- rnd/autogpt_server/autogpt_server/usecases/sample.py ---
@@ -48,13 +48,13 @@ def create_test_graph() -> graph.Graph:
         graph.Link(
             source_id=nodes[0].id,
             sink_id=nodes[2].id,
-            source_name=""value"",
+            source_name=""result"",
             sink_name=""values_#_a"",
         ),
         graph.Link(
             source_id=nodes[1].id,
             sink_id=nodes[2].id,
-            source_name=""value"",
+            source_name=""result"",
             sink_name=""values_#_b"",
         ),
         graph.Link(

--- rnd/autogpt_server/test/executor/test_manager.py ---
@@ -39,7 +39,7 @@ async def assert_sample_graph_executions(
         test_graph.id, graph_exec_id, test_user.id
     )
 
-    output_list = [{""value"": [""Hello""]}, {""value"": [""World""]}]
+    output_list = [{""result"": [""Hello""]}, {""result"": [""World""]}]
     input_list = [
         {""value"": ""Hello"", ""name"": ""input_1""},
         {""value"": ""World"", ""name"": ""input_2""},",fix
"feat(backend): add the capibility to disable llm models in the cloud env (#8285)

* feat(backend): logic to disable enums based on python logic

* feat(backend): add behave as setting and clarify its purpose and APP_ENV

APP_ENV is used for not cloud vs local but the application environment such as local/dev/prod so we need BehaveAs as well

* fix(backend): various uses of AppEnvironment without the Enum or incorrectly

AppEnv in the logging library will never be cloud due to the restrictions applied when loading settings in by pydantic settings. This commit fixes this error, however the code path for logging may now be incorrect

* feat(backend): use a metaclass to disable ollama in the cloud environment

* fix: formatting

* fix(backend): typing improvements

* fix(backend): more linting :sob:","--- autogpt_platform/backend/.env.example ---
@@ -12,7 +12,10 @@ REDIS_PORT=6379
 REDIS_PASSWORD=password
 
 ENABLE_CREDIT=false
-APP_ENV=""local""
+# What environment things should be logged under: local dev or prod
+APP_ENV=local
+# What environment to behave as: ""local"" or ""cloud""
+BEHAVE_AS=local
 PYRO_HOST=localhost
 SENTRY_DSN=
 
@@ -98,5 +101,3 @@ ENABLE_CLOUD_LOGGING=false
 ENABLE_FILE_LOGGING=false
 # Use to manually set the log directory
 # LOG_DIR=./logs
-
-APP_ENV=local

--- autogpt_platform/backend/backend/blocks/llm.py ---
@@ -1,8 +1,12 @@
 import ast
 import logging
-from enum import Enum
+from enum import Enum, EnumMeta
 from json import JSONDecodeError
-from typing import Any, List, NamedTuple
+from types import MappingProxyType
+from typing import TYPE_CHECKING, Any, List, NamedTuple
+
+if TYPE_CHECKING:
+    from enum import _EnumMemberT
 
 import anthropic
 import ollama
@@ -12,6 +16,7 @@
 from backend.data.block import Block, BlockCategory, BlockOutput, BlockSchema
 from backend.data.model import BlockSecret, SchemaField, SecretField
 from backend.util import json
+from backend.util.settings import BehaveAs, Settings
 
 logger = logging.getLogger(__name__)
 
@@ -29,7 +34,26 @@ class ModelMetadata(NamedTuple):
     cost_factor: int
 
 
-class LlmModel(str, Enum):
+class LlmModelMeta(EnumMeta):
+    @property
+    def __members__(
+        self: type[""_EnumMemberT""],
+    ) -> MappingProxyType[str, ""_EnumMemberT""]:
+        if Settings().config.behave_as == BehaveAs.LOCAL:
+            members = super().__members__
+            return members
+        else:
+            removed_providers = [""ollama""]
+            existing_members = super().__members__
+            members = {
+                name: member
+                for name, member in existing_members.items()
+                if LlmModel[name].provider not in removed_providers
+            }
+            return MappingProxyType(members)
+
+
+class LlmModel(str, Enum, metaclass=LlmModelMeta):
     # OpenAI models
     O1_PREVIEW = ""o1-preview""
     O1_MINI = ""o1-mini""
@@ -58,6 +82,18 @@ class LlmModel(str, Enum):
     def metadata(self) -> ModelMetadata:
         return MODEL_METADATA[self]
 
+    @property
+    def provider(self) -> str:
+        return self.metadata.provider
+
+    @property
+    def context_window(self) -> int:
+        return self.metadata.context_window
+
+    @property
+    def cost_factor(self) -> int:
+        return self.metadata.cost_factor
+
 
 MODEL_METADATA = {
     LlmModel.O1_PREVIEW: ModelMetadata(""openai"", 32000, cost_factor=60),

--- autogpt_platform/backend/backend/server/rest_api.py ---
@@ -23,7 +23,7 @@
 from backend.executor import ExecutionManager, ExecutionScheduler
 from backend.server.model import CreateGraph, SetGraphActiveVersion
 from backend.util.service import AppService, expose, get_service_client
-from backend.util.settings import Config, Settings
+from backend.util.settings import AppEnvironment, Config, Settings
 
 from .utils import get_user_id
 
@@ -52,7 +52,7 @@ async def lifespan(self, _: FastAPI):
         await db.disconnect()
 
     def run_service(self):
-        docs_url = ""/docs"" if settings.config.app_env == ""local"" else None
+        docs_url = ""/docs"" if settings.config.app_env == AppEnvironment.LOCAL else None
         app = FastAPI(
             title=""AutoGPT Agent Server"",
             description=(

--- autogpt_platform/backend/backend/server/ws_api.py ---
@@ -12,7 +12,7 @@
 from backend.server.conn_manager import ConnectionManager
 from backend.server.model import ExecutionSubscription, Methods, WsMessage
 from backend.util.service import AppProcess
-from backend.util.settings import Config, Settings
+from backend.util.settings import AppEnvironment, Config, Settings
 
 logger = logging.getLogger(__name__)
 settings = Settings()
@@ -28,7 +28,7 @@ async def lifespan(app: FastAPI):
     event_queue.close()
 
 
-docs_url = ""/docs"" if settings.config.app_env == ""local"" else None
+docs_url = ""/docs"" if settings.config.app_env == AppEnvironment.LOCAL else None
 app = FastAPI(lifespan=lifespan)
 event_queue = RedisEventQueue()
 _connection_manager = None

--- autogpt_platform/backend/backend/util/logging.py ---
@@ -1,12 +1,17 @@
-import os
+from backend.util.settings import AppEnvironment, BehaveAs, Settings
+
+settings = Settings()
 
 
 def configure_logging():
     import logging
 
     import autogpt_libs.logging.config
 
-    if os.getenv(""APP_ENV"") != ""cloud"":
+    if (
+        settings.config.behave_as == BehaveAs.LOCAL
+        or settings.config.app_env == AppEnvironment.LOCAL
+    ):
         autogpt_libs.logging.config.configure_logging(force_cloud_logging=False)
     else:
         autogpt_libs.logging.config.configure_logging(force_cloud_logging=True)

--- autogpt_platform/backend/backend/util/settings.py ---
@@ -22,6 +22,11 @@ class AppEnvironment(str, Enum):
     PRODUCTION = ""prod""
 
 
+class BehaveAs(str, Enum):
+    LOCAL = ""local""
+    CLOUD = ""cloud""
+
+
 class UpdateTrackingModel(BaseModel, Generic[T]):
     _updated_fields: Set[str] = PrivateAttr(default_factory=set)
 
@@ -130,7 +135,12 @@ class Config(UpdateTrackingModel[""Config""], BaseSettings):
 
     app_env: AppEnvironment = Field(
         default=AppEnvironment.LOCAL,
-        description=""The name of the app environment."",
+        description=""The name of the app environment: local or dev or prod"",
+    )
+
+    behave_as: BehaveAs = Field(
+        default=BehaveAs.LOCAL,
+        description=""What environment to behave as: local or cloud"",
     )
 
     backend_cors_allow_origins: List[str] = Field(default_factory=list)",feat
fix(frontend): Newly typed text in Input fields vanishes on scroll (#8657),"--- autogpt_platform/frontend/src/components/node-input-components.tsx ---
@@ -20,7 +20,7 @@ import {
   SelectTrigger,
   SelectValue,
 } from ""./ui/select"";
-import { Input } from ""./ui/input"";
+import { LocalValuedInput } from ""./ui/input"";
 import NodeHandle from ""./NodeHandle"";
 import { ConnectionData } from ""./CustomNode"";
 import { CredentialsInput } from ""./integrations/credentials-input"";
@@ -413,11 +413,11 @@ const NodeKeyValueInput: FC<{
             />
             {!isConnected(key) && (
               <div className=""nodrag mb-2 flex items-center space-x-2"">
-                <Input
+                <LocalValuedInput
                   type=""text""
                   placeholder=""Key""
-                  ref={InputRef(key ?? """")}
-                  onBlur={(e) =>
+                  value={key ?? """"}
+                  onChange={(e) =>
                     updateKeyValuePairs(
                       keyValuePairs.toSpliced(index, 1, {
                         key: e.target.value,
@@ -426,11 +426,11 @@ const NodeKeyValueInput: FC<{
                     )
                   }
                 />
-                <Input
+                <LocalValuedInput
                   type=""text""
                   placeholder=""Value""
-                  ref={InputRef(value ?? """")}
-                  onBlur={(e) =>
+                  value={value ?? """"}
+                  onChange={(e) =>
                     updateKeyValuePairs(
                       keyValuePairs.toSpliced(index, 1, {
                         key: key,
@@ -640,17 +640,15 @@ const NodeStringInput: FC<{
           className=""nodrag relative""
           onClick={schema.secret ? () => handleInputClick(selfKey) : undefined}
         >
-          <Input
+          <LocalValuedInput
             type=""text""
             id={selfKey}
-            ref={InputRef(
-              schema.secret && value ? ""*"".repeat(value.length) : value,
-            )}
+            value={schema.secret && value ? ""*"".repeat(value.length) : value}
+            onChange={(e) => handleInputChange(selfKey, e.target.value)}
             readOnly={schema.secret}
             placeholder={
               schema?.placeholder || `Enter ${beautifyString(displayName)}`
             }
-            onBlur={(e) => handleInputChange(selfKey, e.target.value)}
             className=""pr-8 read-only:cursor-pointer read-only:text-gray-500""
           />
           <Button
@@ -737,11 +735,13 @@ const NodeNumberInput: FC<{
   return (
     <div className={className}>
       <div className=""nodrag flex items-center justify-between space-x-3"">
-        <Input
+        <LocalValuedInput
           type=""number""
           id={selfKey}
-          ref={InputRef(value)}
-          onBlur={(e) => handleInputChange(selfKey, parseFloat(e.target.value))}
+          value={value}
+          onChange={(e) =>
+            handleInputChange(selfKey, parseFloat(e.target.value))
+          }
           placeholder={
             schema.placeholder || `Enter ${beautifyString(displayName)}`
           }

--- autogpt_platform/frontend/src/components/ui/input.tsx ---
@@ -23,4 +23,35 @@ const Input = React.forwardRef<HTMLInputElement, InputProps>(
 );
 Input.displayName = ""Input"";
 
-export { Input };
+const LocalValuedInput: React.FC<InputProps> = ({
+  value,
+  onChange,
+  ...props
+}) => {
+  /**
+   * Input component that manages its own value state.
+   * This component is useful when you want to control the value of the input
+   * from the parent component, but also want to allow the user to change the value.
+   */
+  const [inputValue, setInputValue] = React.useState(value ?? """");
+
+  React.useEffect(() => {
+    if (value !== undefined && value !== inputValue) {
+      setInputValue(value);
+    }
+    // Note:
+    // It's intended that the `inputValue` not being added to the dependency array,
+    // `inputValue` should only be updated from the outside only when `value` changes.
+    // eslint-disable-next-line react-hooks/exhaustive-deps
+  }, [value]);
+
+  const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
+    setInputValue(e.target.value);
+    if (onChange) onChange(e);
+  };
+
+  return <Input {...props} value={inputValue} onChange={handleChange} />;
+};
+LocalValuedInput.displayName = ""LocalValuedInput"";
+
+export { Input, LocalValuedInput };",fix
"fix(frontend): Allow importing agent file with empty description (#8670)

Check structure of agent file with `obj[key] != null` rather than `!!obj[key]` to allow empty strings","--- autogpt_platform/frontend/src/components/agent-import-form.tsx ---
@@ -145,7 +145,7 @@ export const AgentImportForm: React.FC<
                           );
                           if (
                             ![""name"", ""description"", ""nodes"", ""links""].every(
-                              (key) => !!obj[key],
+                              (key) => key in obj && obj[key] != null,
                             )
                           ) {
                             throw new Error(",fix
"fix(platform): Remove migrate and encrypt function (#8646)

remove migrate and encrypt function","--- autogpt_platform/backend/backend/data/user.py ---
@@ -94,43 +94,3 @@ async def update_user_integrations(user_id: str, data: UserIntegrations):
         where={""id"": user_id},
         data={""integrations"": encrypted_data},
     )
-
-
-async def migrate_and_encrypt_user_integrations():
-    """"""Migrate integration credentials and OAuth states from metadata to integrations column.""""""
-    users = await User.prisma().find_many(
-        where={
-            ""metadata"": {
-                ""path"": [""integration_credentials""],
-                ""not"": Json({""a"": ""yolo""}),  # bogus value works to check if key exists
-            }  # type: ignore
-        }
-    )
-    logger.info(f""Migrating integration credentials for {len(users)} users"")
-
-    for user in users:
-        raw_metadata = cast(UserMetadataRaw, user.metadata)
-        metadata = UserMetadata.model_validate(raw_metadata)
-
-        # Get existing integrations data
-        integrations = await get_user_integrations(user_id=user.id)
-
-        # Copy credentials and oauth states from metadata if they exist
-        if metadata.integration_credentials and not integrations.credentials:
-            integrations.credentials = metadata.integration_credentials
-        if metadata.integration_oauth_states:
-            integrations.oauth_states = metadata.integration_oauth_states
-
-        # Save to integrations column
-        await update_user_integrations(user_id=user.id, data=integrations)
-
-        # Remove from metadata
-        raw_metadata = dict(raw_metadata)
-        raw_metadata.pop(""integration_credentials"", None)
-        raw_metadata.pop(""integration_oauth_states"", None)
-
-        # Update metadata without integration data
-        await User.prisma().update(
-            where={""id"": user.id},
-            data={""metadata"": Json(raw_metadata)},
-        )

--- autogpt_platform/backend/backend/server/rest_api.py ---
@@ -22,7 +22,6 @@
 async def lifespan_context(app: fastapi.FastAPI):
     await backend.data.db.connect()
     await backend.data.block.initialize_blocks()
-    await backend.data.user.migrate_and_encrypt_user_integrations()
     yield
     await backend.data.db.disconnect()",fix
"fix(backend): Add migrations to fix credentials inputs with invalid provider ""llm"" (vol. 2)

Fix breaking SQL double-casting issue in the SQL migration","--- autogpt_platform/backend/migrations/20241115170707_fix_llm_provider_credentials/migration.sql ---
@@ -7,7 +7,7 @@ SET    ""constantInput"" = JSONB_SET(
            WHEN ""constantInput""::jsonb->'credentials'->>'id' = '53c25cb8-e3ee-465c-a4d1-e75a4c899c2a' THEN '""openai""'::jsonb
            WHEN ""constantInput""::jsonb->'credentials'->>'id' = '24e5d942-d9e3-4798-8151-90143ee55629' THEN '""anthropic""'::jsonb
            WHEN ""constantInput""::jsonb->'credentials'->>'id' = '4ec22295-8f97-4dd1-b42b-2c6957a02545' THEN '""groq""'::jsonb
-           ELSE (""constantInput""::jsonb->'credentials'->>'provider')::jsonb
+           ELSE ""constantInput""::jsonb->'credentials'->'provider'
          END
        )::text
 WHERE  ""constantInput""::jsonb->'credentials'->>'provider' = 'llm';",fix
"build(deps): bump the production-dependencies group in /autogpt_platform/backend with 2 updates (#8610)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Nicholas Tindle <nicholas.tindle@agpt.co>","--- autogpt_platform/backend/poetry.lock ---
@@ -1079,17 +1079,17 @@ requests = "">=2.20.0,<3.0""
 
 [[package]]
 name = ""gotrue""
-version = ""2.9.0""
+version = ""2.10.0""
 description = ""Python Client Library for Supabase Auth""
 optional = false
-python-versions = ""<4.0,>=3.8""
+python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""gotrue-2.9.0-py3-none-any.whl"", hash = ""sha256:9a6448479329771752cb93be65bc95f06f17d9262e814a95d03b218cf5dce87a""},
-    {file = ""gotrue-2.9.0.tar.gz"", hash = ""sha256:c50e75bd01b82a388eed6a921a1c373a7157fd405df2221a8532193a39df4159""},
+    {file = ""gotrue-2.10.0-py3-none-any.whl"", hash = ""sha256:768e58207488e5184ffbdc4351b7280d913daf97962f4e9f2cca05c80004b042""},
+    {file = ""gotrue-2.10.0.tar.gz"", hash = ""sha256:4edf4c251da3535f2b044e23deba221e848ca1210c17d0c7a9b19f79a1e3f3c0""},
 ]
 
 [package.dependencies]
-httpx = {version = "">=0.24,<0.28"", extras = [""http2""]}
+httpx = {version = "">=0.26,<0.28"", extras = [""http2""]}
 pydantic = "">=1.10,<3""
 
 [[package]]
@@ -1796,13 +1796,13 @@ httpx = "">=0.27.0,<0.28.0""
 
 [[package]]
 name = ""openai""
-version = ""1.54.1""
+version = ""1.54.3""
 description = ""The official Python library for the openai API""
 optional = false
 python-versions = "">=3.8""
 files = [
-    {file = ""openai-1.54.1-py3-none-any.whl"", hash = ""sha256:3cb49ccb6bfdc724ad01cc397d323ef8314fc7d45e19e9de2afdd6484a533324""},
-    {file = ""openai-1.54.1.tar.gz"", hash = ""sha256:5b832bf82002ba8c4f6e5e25c1c0f5d468c22f043711544c716eaffdb30dd6f1""},
+    {file = ""openai-1.54.3-py3-none-any.whl"", hash = ""sha256:f18dbaf09c50d70c4185b892a2a553f80681d1d866323a2da7f7be2f688615d5""},
+    {file = ""openai-1.54.3.tar.gz"", hash = ""sha256:7511b74eeb894ac0b0253dc71f087a15d2e4d71d22d0088767205143d880cca6""},
 ]
 
 [package.dependencies]
@@ -1984,13 +1984,13 @@ poetry-plugin = [""poetry (>=1.0,<2.0)""]
 
 [[package]]
 name = ""postgrest""
-version = ""0.17.2""
+version = ""0.18.0""
 description = ""PostgREST client for Python. This library provides an ORM interface to PostgREST.""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""postgrest-0.17.2-py3-none-any.whl"", hash = ""sha256:f7c4f448e5a5e2d4c1dcf192edae9d1007c4261e9a6fb5116783a0046846ece2""},
-    {file = ""postgrest-0.17.2.tar.gz"", hash = ""sha256:445cd4e4a191e279492549df0c4e827d32f9d01d0852599bb8a6efb0f07fcf78""},
+    {file = ""postgrest-0.18.0-py3-none-any.whl"", hash = ""sha256:200baad0d23fee986b3a0ffd3e07bfe0cdd40e09760f11e8e13a6c0c2376d5fa""},
+    {file = ""postgrest-0.18.0.tar.gz"", hash = ""sha256:29c1a94801a17eb9ad590189993fe5a7a6d8c1bfc11a3c9d0ce7ba146454ebb3""},
 ]
 
 [package.dependencies]
@@ -2933,19 +2933,18 @@ full = [""httpx (>=0.22.0)"", ""itsdangerous"", ""jinja2"", ""python-multipart (>=0.0.7
 
 [[package]]
 name = ""storage3""
-version = ""0.8.2""
+version = ""0.9.0""
 description = ""Supabase Storage client for Python.""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""storage3-0.8.2-py3-none-any.whl"", hash = ""sha256:f2e995b18c77a2a9265d1a33047d43e4d6abb11eb3ca5067959f68281c305de3""},
-    {file = ""storage3-0.8.2.tar.gz"", hash = ""sha256:db05d3fe8fb73bd30c814c4c4749664f37a5dfc78b629e8c058ef558c2b89f5a""},
+    {file = ""storage3-0.9.0-py3-none-any.whl"", hash = ""sha256:8b2fb91f0c61583a2f4eac74a8bae67e00d41ff38095c8a6cd3f2ce5e0ab76e7""},
+    {file = ""storage3-0.9.0.tar.gz"", hash = ""sha256:e16697f60894c94e1d9df0d2e4af783c1b3f7dd08c9013d61978825c624188c4""},
 ]
 
 [package.dependencies]
 httpx = {version = "">=0.26,<0.28"", extras = [""http2""]}
 python-dateutil = "">=2.8.2,<3.0.0""
-typing-extensions = "">=4.2.0,<5.0.0""
 
 [[package]]
 name = ""strenum""
@@ -2965,32 +2964,32 @@ test = [""pylint"", ""pytest"", ""pytest-black"", ""pytest-cov"", ""pytest-pylint""]
 
 [[package]]
 name = ""supabase""
-version = ""2.9.1""
+version = ""2.10.0""
 description = ""Supabase client for Python.""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""supabase-2.9.1-py3-none-any.whl"", hash = ""sha256:a96f857a465712cb551679c1df66ba772c834f861756ce4aa2aa4cb703f6aeb7""},
-    {file = ""supabase-2.9.1.tar.gz"", hash = ""sha256:51fce39c9eb50573126dabb342541ec5e1f13e7476938768f4b0ccfdb8c522cd""},
+    {file = ""supabase-2.10.0-py3-none-any.whl"", hash = ""sha256:183fb23c04528593f8f81c24ceb8178f3a56bff40fec7ed873b6c55ebc2e420a""},
+    {file = ""supabase-2.10.0.tar.gz"", hash = ""sha256:9ac095f8947bf60780e67c0edcbab53e2db3f6f3f022329397b093500bf2607c""},
 ]
 
 [package.dependencies]
-gotrue = "">=2.9.0,<3.0.0""
+gotrue = "">=2.10.0,<3.0.0""
 httpx = "">=0.26,<0.28""
-postgrest = "">=0.17.0,<0.18.0""
+postgrest = "">=0.18,<0.19""
 realtime = "">=2.0.0,<3.0.0""
-storage3 = "">=0.8.0,<0.9.0""
-supafunc = "">=0.6.0,<0.7.0""
+storage3 = "">=0.9.0,<0.10.0""
+supafunc = "">=0.7.0,<0.8.0""
 
 [[package]]
 name = ""supafunc""
-version = ""0.6.2""
+version = ""0.7.0""
 description = ""Library for Supabase Functions""
 optional = false
 python-versions = ""<4.0,>=3.9""
 files = [
-    {file = ""supafunc-0.6.2-py3-none-any.whl"", hash = ""sha256:101b30616b0a1ce8cf938eca1df362fa4cf1deacb0271f53ebbd674190fb0da5""},
-    {file = ""supafunc-0.6.2.tar.gz"", hash = ""sha256:c7dfa20db7182f7fe4ae436e94e05c06cd7ed98d697fed75d68c7b9792822adc""},
+    {file = ""supafunc-0.7.0-py3-none-any.whl"", hash = ""sha256:4160260dc02bdd906be1e2ffd7cb3ae8b74ae437c892bb475352b6a99d9ff8eb""},
+    {file = ""supafunc-0.7.0.tar.gz"", hash = ""sha256:5b1c415fba1395740b2b4eedd1d786384bd58b98f6333a11ba7889820a48b6a7""},
 ]
 
 [package.dependencies]
@@ -3677,4 +3676,4 @@ type = [""pytest-mypy""]
 [metadata]
 lock-version = ""2.0""
 python-versions = ""^3.10""
-content-hash = ""b761f200e8ad7560321fca7bbefbe79377740952ace5dcbecf0371bb8aa16df1""
+content-hash = ""e0e67fde376688bee3ef5e31712eb42a8a3f9a361dd21d0890db61492df6f4c3""

--- autogpt_platform/backend/pyproject.toml ---
@@ -26,7 +26,7 @@ jinja2 = ""^3.1.4""
 jsonref = ""^1.1.0""
 jsonschema = ""^4.22.0""
 ollama = ""^0.3.0""
-openai = ""^1.54.1""
+openai = ""^1.54.3""
 praw = ""~7.8.1""
 prisma = ""^0.15.0""
 psutil = ""^6.1.0""
@@ -38,7 +38,7 @@ pytest-asyncio = ""^0.24.0""
 python-dotenv = ""^1.0.1""
 redis = ""^5.2.0""
 sentry-sdk = ""2.18.0""
-supabase = ""^2.7.2""
+supabase = ""^2.10.0""
 tenacity = ""^9.0.0""
 uvicorn = { extras = [""standard""], version = ""^0.32.0"" }
 websockets = ""^13.1""",build
feat(builder): Added tooltips for blocks (#7793),"--- rnd/autogpt_builder/src/components/CustomNode.tsx ---
@@ -23,12 +23,14 @@ import { history } from ""./history"";
 import NodeHandle from ""./NodeHandle"";
 import { CustomEdgeData } from ""./CustomEdge"";
 import { NodeGenericInputField } from ""./node-input-components"";
+import SchemaTooltip from ""./SchemaTooltip"";
 
 type ParsedKey = { key: string; index?: number };
 
 export type CustomNodeData = {
   blockType: string;
   title: string;
+  description: string;
   inputSchema: BlockIORootSchema;
   outputSchema: BlockIORootSchema;
   hardcodedValues: { [key: string]: any };
@@ -282,8 +284,13 @@ const CustomNode: FC<NodeProps<CustomNodeData>> = ({ data, id }) => {
       onMouseLeave={handleMouseLeave}
     >
       <div className=""mb-2 p-3 bg-gray-300/[.7] rounded-t-xl"">
-        <div className=""p-3 text-lg font-semibold font-roboto"">
-          {beautifyString(data.blockType?.replace(/Block$/, """") || data.title)}
+        <div className=""flex items-center justify-between"">
+          <div className=""p-3 text-lg font-semibold font-roboto"">
+            {beautifyString(
+              data.blockType?.replace(/Block$/, """") || data.title,
+            )}
+          </div>
+          <SchemaTooltip description={data.description} />
         </div>
         <div className=""flex gap-[5px] "">
           {isHovered && (

--- rnd/autogpt_builder/src/components/Flow.tsx ---
@@ -380,6 +380,7 @@ const FlowEditor: React.FC<{
         data: {
           blockType: nodeType,
           title: `${nodeType} ${nodeId}`,
+          description: nodeSchema.description,
           inputSchema: nodeSchema.inputSchema,
           outputSchema: nodeSchema.outputSchema,
           hardcodedValues: {},
@@ -459,6 +460,7 @@ const FlowEditor: React.FC<{
           data: {
             block_id: block.id,
             blockType: block.name,
+            description: block.description,
             title: `${block.name} ${node.id}`,
             inputSchema: block.inputSchema,
             outputSchema: block.outputSchema,

--- rnd/autogpt_builder/src/components/NodeHandle.tsx ---
@@ -60,7 +60,7 @@ const NodeHandle: FC<HandleProps> = ({
             {label}
           </div>
         </Handle>
-        <SchemaTooltip schema={schema} />
+        <SchemaTooltip description={schema.description} />
       </div>
     );
   } else {

--- rnd/autogpt_builder/src/components/SchemaTooltip.tsx ---
@@ -4,12 +4,11 @@ import {
   TooltipProvider,
   TooltipTrigger,
 } from ""@/components/ui/tooltip"";
-import { BlockIOSubSchema } from ""@/lib/autogpt-server-api/types"";
 import { Info } from ""lucide-react"";
 import ReactMarkdown from ""react-markdown"";
 
-const SchemaTooltip: React.FC<{ schema: BlockIOSubSchema }> = ({ schema }) => {
-  if (!schema.description) return null;
+const SchemaTooltip: React.FC<{ description?: string }> = ({ description }) => {
+  if (!description) return null;
 
   return (
     <TooltipProvider delayDuration={400}>
@@ -25,7 +24,7 @@ const SchemaTooltip: React.FC<{ schema: BlockIOSubSchema }> = ({ schema }) => {
               ),
             }}
           >
-            {schema.description}
+            {description}
           </ReactMarkdown>
         </TooltipContent>
       </Tooltip>

--- rnd/autogpt_builder/src/components/edit/control/BlocksControl.tsx ---
@@ -14,6 +14,7 @@ import {
 import { Block } from ""@/lib/autogpt-server-api"";
 import { PlusIcon } from ""@radix-ui/react-icons"";
 import { IconToyBrick } from ""@/components/ui/icons"";
+import SchemaTooltip from ""@/components/SchemaTooltip"";
 
 interface BlocksControlProps {
   blocks: Block[];
@@ -80,6 +81,7 @@ export const BlocksControl: React.FC<BlocksControlProps> = ({
                         {beautifyString(block.name)}
                       </span>
                     </div>
+                    <SchemaTooltip description={block.description} />
                     <div className=""flex items-center gap-1 flex-shrink-0"">
                       <Button
                         variant=""ghost""",feat
"build(platform/ci): Run migrations in ci for dev (#8395)

* run migrations in ci

* update environment

* temp false

* add dev migrations

* remove code change step","--- .github/workflows/platform-autogpt-deploy.yaml ---
@@ -19,8 +19,42 @@ env:
   NAMESPACE: dev-agpt
 
 jobs:
+  migrate:
+    environment: develop
+    name: Run migrations for AutoGPT Platform
+    runs-on: ubuntu-latest
+
+    steps:
+      - name: Checkout code
+        uses: actions/checkout@v2
+
+      - name: Set up Python
+        uses: actions/setup-python@v4
+        with:
+          python-version: '3.11'
+
+      - name: Install Python dependencies
+        run: |
+          python -m pip install --upgrade pip
+          pip install prisma
+
+      - name: Run Backend Migrations
+        working-directory: ./autogpt_platform/backend
+        run: |
+          python -m prisma migrate deploy
+        env:
+          DATABASE_URL: ${{ secrets.BACKEND_DATABASE_URL }}
+
+      - name: Run Market Migrations
+        working-directory: ./autogpt_platform/market
+        run: |
+          python -m prisma migrate deploy
+        env:
+          DATABASE_URL: ${{ secrets.MARKET_DATABASE_URL }}
+
   build-push-deploy:
     name: Build, Push, and Deploy
+    needs: migrate
     runs-on: ubuntu-latest
 
     steps:",build
"docs(docs): add a few qol upgrades (#8176)

* feat(docs): add a few qol upgrades

* fix(docs): render favicon correctly

* feat(docs): pr comments","--- docs/mkdocs.yml ---
@@ -1,6 +1,8 @@
 site_name: AutoGPT Documentation
 site_url: https://docs.agpt.co/
 repo_url: https://github.com/Significant-Gravitas/AutoGPT
+repo_name: AutoGPT
+edit_uri: edit/master/docs/content
 docs_dir: content
 nav:
   - Home: index.md
@@ -10,7 +12,7 @@ nav:
     - Setup: server/setup.md
     - Advanced Setup: server/advanced_setup.md
     - Using Ollama: server/ollama.md
-    - Using D-ID: serveer/d_id.md
+    - Using D-ID: server/d_id.md
 
   - AutoGPT Agent:
       - Introduction: AutoGPT/index.md
@@ -69,14 +71,27 @@ nav:
 theme:
   name: material
   custom_dir: overrides
+  language: en
   icon:
+    repo: fontawesome/brands/github
     logo: material/book-open-variant
-  favicon: favicon.png
+    edit: material/pencil
+    view: material/eye
+  favicon: assets/favicon.png
   features:
     - navigation.sections
-    - toc.follow
+    - navigation.footer
     - navigation.top
+    - navigation.tracking
+    - navigation.tabs
+    # - navigation.path
+    - toc.follow
+    - toc.integrate
+    - content.action.edit
+    - content.action.view
     - content.code.copy
+    - content.code.annotate
+    - content.tabs.link
   palette:
     # Palette toggle for light mode
     - media: ""(prefers-color-scheme: light)""
@@ -137,6 +152,20 @@ markdown_extensions:
 plugins:
   - table-reader
   - search
+  - git-revision-date-localized:
+      enable_creation_date: true
+
+
+extra:
+  social:
+    - icon: fontawesome/brands/github
+      link: https://github.com/Significant-Gravitas/AutoGPT
+    - icon: fontawesome/brands/x-twitter
+      link: https://x.com/Auto_GPT
+    - icon: fontawesome/brands/instagram
+      link: https://www.instagram.com/autogpt/
+    - icon: fontawesome/brands/discord
+      link: https://discord.gg/autogpt
 
 extra_javascript:
   - https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js

--- docs/overrides/assets/favicon.png ---
No patch available

--- docs/requirements.txt ---
@@ -2,3 +2,4 @@ mkdocs
 mkdocs-material
 mkdocs-table-reader-plugin
 pymdown-extensions
+mkdocs-git-revision-date-localized-plugin",docs
"feat(build-page): make all content unselectable except flowEditor (#8534)

* docs(platform): Update frontend instructions (#8514)

update readme

* docs(platform): correct readme

* feat(build-page): make all content unselectable except flowEditor

* revert some changes

* revert some changes

---------

Co-authored-by: Swifty <craigswift13@gmail.com>
Co-authored-by: Nicholas Tindle <nicholas.tindle@agpt.co>
Co-authored-by: Aarushi <50577581+aarushik93@users.noreply.github.com>","--- autogpt_platform/frontend/src/components/NavBar.tsx ---
@@ -18,7 +18,7 @@ export async function NavBar() {
   const { user } = await getServerUser();
 
   return (
-    <header className=""sticky top-0 z-50 mx-4 flex h-16 items-center gap-4 border border-gray-300 bg-background p-3 md:rounded-b-2xl md:px-6 md:shadow"">
+    <header className=""sticky top-0 z-50 mx-4 flex h-16 select-none items-center gap-4 border border-gray-300 bg-background p-3 md:rounded-b-2xl md:px-6 md:shadow"">
       <div className=""flex flex-1 items-center gap-4"">
         <Sheet>
           <SheetTrigger asChild>

--- autogpt_platform/frontend/src/components/PrimaryActionButton.tsx ---
@@ -32,7 +32,7 @@ const PrimaryActionBar: React.FC<PrimaryActionBarProps> = ({
   const runButtonOnClick = !isRunning ? onClickRunAgent : requestStopRun;
 
   return (
-    <div className=""absolute bottom-0 left-1/2 z-50 flex w-fit -translate-x-1/2 transform items-center justify-center p-4"">
+    <div className=""absolute bottom-0 left-1/2 z-50 flex w-fit -translate-x-1/2 transform select-none items-center justify-center p-4"">
       <div className={`flex gap-4`}>
         <Tooltip key=""ViewOutputs"" delayDuration={500}>
           <TooltipTrigger asChild>

--- autogpt_platform/frontend/src/components/TallyPopup.tsx ---
@@ -48,7 +48,7 @@ const TallyPopupSimple = () => {
   };
 
   return (
-    <div className=""fixed bottom-1 right-6 z-50 hidden items-center gap-4 p-3 transition-all duration-300 ease-in-out md:flex"">
+    <div className=""fixed bottom-1 right-6 z-50 hidden select-none items-center gap-4 p-3 transition-all duration-300 ease-in-out md:flex"">
       <Button
         variant=""default""
         onClick={resetTutorial}",feat
"fix(frontend): Fix styling inconsistencies in input elements (#8337)

- Apply consistent border styling to `Input`, `Select`, and `Textarea`
   - Remove `rounded-xl` from node input elements

- Add `whitespace-nowrap` to `CustomNode` header category tags

---------

Co-authored-by: Zamil Majdy <zamil.majdy@agpt.co>","--- autogpt_platform/frontend/src/app/globals.css ---
@@ -27,7 +27,7 @@
     --destructive: 0 84.2% 60.2%;
     --destructive-foreground: 0 0% 98%;
     --border: 240 5.9% 90%;
-    --input: 240 5.9% 90%;
+    --input: 240 5.9% 85%;
     --ring: 240 5.9% 10%;
     --radius: 0.5rem;
     --chart-1: 12 76% 61%;
@@ -72,4 +72,12 @@
   body {
     @apply bg-background text-foreground;
   }
+
+  .agpt-border-input {
+    @apply border-input focus-visible:border-gray-400 focus-visible:outline-none;
+  }
+
+  .agpt-shadow-input {
+    @apply shadow-sm focus-visible:shadow-md;
+  }
 }

--- autogpt_platform/frontend/src/components/CustomNode.tsx ---
@@ -646,7 +646,7 @@ export function CustomNode({
           <Badge
             key={category.category}
             variant=""outline""
-            className={`mr-5 ${getPrimaryCategoryColor([category])} rounded-xl border border-gray-300 opacity-50`}
+            className={`mr-5 ${getPrimaryCategoryColor([category])} whitespace-nowrap rounded-xl border border-gray-300 opacity-50`}
           >
             {beautifyString(category.category.toLowerCase())}
           </Badge>

--- autogpt_platform/frontend/src/components/node-input-components.tsx ---
@@ -459,7 +459,7 @@ const NodeKeyValueInput: FC<{
           </div>
         ))}
         <Button
-          className=""rounded-xl bg-gray-200 font-normal text-black hover:text-white""
+          className=""bg-gray-200 font-normal text-black hover:text-white""
           disabled={
             keyValuePairs.length > 0 &&
             !keyValuePairs[keyValuePairs.length - 1].key
@@ -567,7 +567,7 @@ const NodeArrayInput: FC<{
         );
       })}
       <Button
-        className=""w-[183p] rounded-xl bg-gray-200 font-normal text-black hover:text-white""
+        className=""w-[183p] bg-gray-200 font-normal text-black hover:text-white""
         onClick={() =>
           handleInputChange(selfKey, [...entries, isItemObject ? {} : """"])
         }
@@ -633,7 +633,7 @@ const NodeStringInput: FC<{
               schema?.placeholder || `Enter ${beautifyString(displayName)}`
             }
             onBlur={(e) => handleInputChange(selfKey, e.target.value)}
-            className=""rounded-xl pr-8 read-only:cursor-pointer read-only:text-gray-500""
+            className=""pr-8 read-only:cursor-pointer read-only:text-gray-500""
           />
           <Button
             variant=""ghost""
@@ -685,7 +685,7 @@ export const NodeTextBoxInput: FC<{
             schema?.placeholder || `Enter ${beautifyString(displayName)}`
           }
           onChange={(e) => handleInputChange(selfKey, e.target.value)}
-          className=""h-full w-full resize-none overflow-hidden rounded-xl border-none bg-transparent text-lg text-black outline-none""
+          className=""h-full w-full resize-none overflow-hidden border-none bg-transparent text-lg text-black outline-none""
           style={{
             fontSize: ""min(1em, 16px)"",
             lineHeight: ""1.2"",

--- autogpt_platform/frontend/src/components/ui/input.tsx ---
@@ -11,7 +11,7 @@ const Input = React.forwardRef<HTMLInputElement, InputProps>(
       <input
         type={type}
         className={cn(
-          ""flex h-9 w-full rounded-md border border-gray-300 bg-transparent px-3 py-1 text-sm shadow-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-gray-500 focus-visible:border-gray-400 focus-visible:outline-none disabled:cursor-not-allowed disabled:opacity-50"",
+          ""agpt-border-input agpt-shadow-input flex h-9 w-full rounded-md border bg-transparent px-3 py-1 text-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-gray-500 disabled:cursor-not-allowed disabled:opacity-50 dark:placeholder:text-gray-400"",
           type == ""file"" ? ""pb-0.5 pt-1.5"" : """", // fix alignment
           className,
         )}

--- autogpt_platform/frontend/src/components/ui/select.tsx ---
@@ -24,7 +24,7 @@ const SelectTrigger = React.forwardRef<
   <SelectPrimitive.Trigger
     ref={ref}
     className={cn(
-      ""flex h-9 w-full items-center justify-between whitespace-nowrap rounded-md border border-neutral-200 bg-transparent px-3 py-2 text-sm shadow-sm ring-offset-white placeholder:text-neutral-500 focus:outline-none focus:ring-1 focus:ring-neutral-950 disabled:cursor-not-allowed disabled:opacity-50 dark:border-neutral-800 dark:ring-offset-neutral-950 dark:placeholder:text-neutral-400 dark:focus:ring-neutral-300 [&>span]:line-clamp-1"",
+      ""agpt-border-input agpt-shadow-input flex h-9 w-full items-center justify-between whitespace-nowrap rounded-md border bg-transparent px-3 py-2 text-sm ring-offset-white placeholder:text-neutral-500 focus:outline-none disabled:cursor-not-allowed disabled:opacity-50 data-[state=open]:border-gray-400 dark:placeholder:text-neutral-400 [&>span]:line-clamp-1"",
       className,
     )}
     {...props}

--- autogpt_platform/frontend/src/components/ui/textarea.tsx ---
@@ -10,7 +10,7 @@ const Textarea = React.forwardRef<HTMLTextAreaElement, TextareaProps>(
     return (
       <textarea
         className={cn(
-          ""flex min-h-[80px] w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50"",
+          ""agpt-border-input flex min-h-[80px] w-full rounded-md border bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50"",
           className,
         )}
         ref={ref}",fix
fix(rnd): Fix decorator function type hint (#8043),"--- rnd/autogpt_server/autogpt_server/util/decorator.py ---
@@ -2,7 +2,7 @@
 import logging
 import os
 import time
-from typing import Callable, Tuple, TypeVar
+from typing import Callable, ParamSpec, Tuple, TypeVar
 
 from pydantic import BaseModel
 
@@ -24,18 +24,19 @@ def _end_measurement(
     return end_wall_time - start_wall_time, end_cpu_time - start_cpu_time
 
 
+P = ParamSpec(""P"")
 T = TypeVar(""T"")
 
 logger = logging.getLogger(__name__)
 
 
-def time_measured(func: Callable[..., T]) -> Callable[..., Tuple[TimingInfo, T]]:
+def time_measured(func: Callable[P, T]) -> Callable[P, Tuple[TimingInfo, T]]:
     """"""
     Decorator to measure the time taken by a function to execute.
     """"""
 
     @functools.wraps(func)
-    def wrapper(*args, **kwargs) -> Tuple[TimingInfo, T]:
+    def wrapper(*args: P.args, **kwargs: P.kwargs) -> Tuple[TimingInfo, T]:
         start_wall_time, start_cpu_time = _start_measurement()
         try:
             result = func(*args, **kwargs)
@@ -49,13 +50,13 @@ def wrapper(*args, **kwargs) -> Tuple[TimingInfo, T]:
     return wrapper
 
 
-def error_logged(func: Callable[..., T]) -> Callable[..., T | None]:
+def error_logged(func: Callable[P, T]) -> Callable[P, T | None]:
     """"""
     Decorator to suppress and log any exceptions raised by a function.
     """"""
 
     @functools.wraps(func)
-    def wrapper(*args, **kwargs) -> T | None:
+    def wrapper(*args: P.args, **kwargs: P.kwargs) -> T | None:
         try:
             return func(*args, **kwargs)
         except Exception as e:",fix
docs(platform): correct readme,"--- autogpt_platform/README.md ---
@@ -28,9 +28,9 @@ To run the AutoGPT Platform, follow these steps:
 
 3. Run the following command:
    ```
-   cp supabase/docker/.env.example .env.local
+   cp supabase/docker/.env.example .env
    ```
-   This command will copy the `.env.example` file to `.env.local` in the `supabase/docker` directory. You can modify the `.env.local` file to add your own environment variables.
+   This command will copy the `.env.example` file to `.env` in the `supabase/docker` directory. You can modify the `.env` file to add your own environment variables.
 
 4. Run the following command:
    ```
@@ -46,9 +46,9 @@ To run the AutoGPT Platform, follow these steps:
 
 6. Run the following command: 
    ```
-   cp .env.example .env
+   cp .env.example .env.local
    ```
-   This command will copy the `.env.example` file to `.env` in the `frontend` directory. You can modify the `.env` within this folder to add your own environment variables for the frontend application.
+   This command will copy the `.env.example` file to `.env.local` in the `frontend` directory. You can modify the `.env.local` within this folder to add your own environment variables for the frontend application.
 
 7. Run the following command:
    ```",docs
"build(deps-dev): bump the development-dependencies group in /autogpt_platform/backend with 3 updates (#8611)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Nicholas Tindle <nicholas.tindle@agpt.co>","--- autogpt_platform/backend/poetry.lock ---
@@ -1965,13 +1965,13 @@ testing = [""pytest"", ""pytest-benchmark""]
 
 [[package]]
 name = ""poethepoet""
-version = ""0.29.0""
+version = ""0.30.0""
 description = ""A task runner that works well with poetry.""
 optional = false
 python-versions = "">=3.8""
 files = [
-    {file = ""poethepoet-0.29.0-py3-none-any.whl"", hash = ""sha256:f8dfe55006dcfb5cf31bcb1904e1262e1c642a4502fee3688cbf1bddfe5c7601""},
-    {file = ""poethepoet-0.29.0.tar.gz"", hash = ""sha256:676842302f2304a86b31ac56398dd672fae8471128d2086896393384dbafc095""},
+    {file = ""poethepoet-0.30.0-py3-none-any.whl"", hash = ""sha256:bf875741407a98da9e96f2f2d0b2c4c34f56d89939a7f53a4b6b3a64b546ec4e""},
+    {file = ""poethepoet-0.30.0.tar.gz"", hash = ""sha256:9f7ccda2d6525616ce989ca8ef973739fd668f50bef0b9d3631421d504d9ae4a""},
 ]
 
 [package.dependencies]
@@ -2370,13 +2370,13 @@ diagrams = [""jinja2"", ""railroad-diagrams""]
 
 [[package]]
 name = ""pyright""
-version = ""1.1.387""
+version = ""1.1.388""
 description = ""Command line wrapper for pyright""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""pyright-1.1.387-py3-none-any.whl"", hash = ""sha256:6a1f495a261a72e12ad17e20d1ae3df4511223c773b19407cfa006229b1b08a5""},
-    {file = ""pyright-1.1.387.tar.gz"", hash = ""sha256:577de60224f7fe36505d5b181231e3a395d427b7873be0bbcaa962a29ea93a60""},
+    {file = ""pyright-1.1.388-py3-none-any.whl"", hash = ""sha256:c7068e9f2c23539c6ac35fc9efac6c6c1b9aa5a0ce97a9a8a6cf0090d7cbf84c""},
+    {file = ""pyright-1.1.388.tar.gz"", hash = ""sha256:0166d19b716b77fd2d9055de29f71d844874dbc6b9d3472ccd22df91db3dfa34""},
 ]
 
 [package.dependencies]
@@ -2792,29 +2792,29 @@ pyasn1 = "">=0.1.3""
 
 [[package]]
 name = ""ruff""
-version = ""0.7.2""
+version = ""0.7.3""
 description = ""An extremely fast Python linter and code formatter, written in Rust.""
 optional = false
 python-versions = "">=3.7""
 files = [
-    {file = ""ruff-0.7.2-py3-none-linux_armv6l.whl"", hash = ""sha256:b73f873b5f52092e63ed540adefc3c36f1f803790ecf2590e1df8bf0a9f72cb8""},
-    {file = ""ruff-0.7.2-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:5b813ef26db1015953daf476202585512afd6a6862a02cde63f3bafb53d0b2d4""},
-    {file = ""ruff-0.7.2-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:853277dbd9675810c6826dad7a428d52a11760744508340e66bf46f8be9701d9""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:21aae53ab1490a52bf4e3bf520c10ce120987b047c494cacf4edad0ba0888da2""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:ccc7e0fc6e0cb3168443eeadb6445285abaae75142ee22b2b72c27d790ab60ba""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:fd77877a4e43b3a98e5ef4715ba3862105e299af0c48942cc6d51ba3d97dc859""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:e00163fb897d35523c70d71a46fbaa43bf7bf9af0f4534c53ea5b96b2e03397b""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:f3c54b538633482dc342e9b634d91168fe8cc56b30a4b4f99287f4e339103e88""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7b792468e9804a204be221b14257566669d1db5c00d6bb335996e5cd7004ba80""},
-    {file = ""ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:dba53ed84ac19ae4bfb4ea4bf0172550a2285fa27fbb13e3746f04c80f7fa088""},
-    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:b19fafe261bf741bca2764c14cbb4ee1819b67adb63ebc2db6401dcd652e3748""},
-    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:28bd8220f4d8f79d590db9e2f6a0674f75ddbc3847277dd44ac1f8d30684b828""},
-    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:9fd67094e77efbea932e62b5d2483006154794040abb3a5072e659096415ae1e""},
-    {file = ""ruff-0.7.2-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:576305393998b7bd6c46018f8104ea3a9cb3fa7908c21d8580e3274a3b04b691""},
-    {file = ""ruff-0.7.2-py3-none-win32.whl"", hash = ""sha256:fa993cfc9f0ff11187e82de874dfc3611df80852540331bc85c75809c93253a8""},
-    {file = ""ruff-0.7.2-py3-none-win_amd64.whl"", hash = ""sha256:dd8800cbe0254e06b8fec585e97554047fb82c894973f7ff18558eee33d1cb88""},
-    {file = ""ruff-0.7.2-py3-none-win_arm64.whl"", hash = ""sha256:bb8368cd45bba3f57bb29cbb8d64b4a33f8415d0149d2655c5c8539452ce7760""},
-    {file = ""ruff-0.7.2.tar.gz"", hash = ""sha256:2b14e77293380e475b4e3a7a368e14549288ed2931fce259a6f99978669e844f""},
+    {file = ""ruff-0.7.3-py3-none-linux_armv6l.whl"", hash = ""sha256:34f2339dc22687ec7e7002792d1f50712bf84a13d5152e75712ac08be565d344""},
+    {file = ""ruff-0.7.3-py3-none-macosx_10_12_x86_64.whl"", hash = ""sha256:fb397332a1879b9764a3455a0bb1087bda876c2db8aca3a3cbb67b3dbce8cda0""},
+    {file = ""ruff-0.7.3-py3-none-macosx_11_0_arm64.whl"", hash = ""sha256:37d0b619546103274e7f62643d14e1adcbccb242efda4e4bdb9544d7764782e9""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl"", hash = ""sha256:5d59f0c3ee4d1a6787614e7135b72e21024875266101142a09a61439cb6e38a5""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl"", hash = ""sha256:44eb93c2499a169d49fafd07bc62ac89b1bc800b197e50ff4633aed212569299""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl"", hash = ""sha256:6d0242ce53f3a576c35ee32d907475a8d569944c0407f91d207c8af5be5dae4e""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl"", hash = ""sha256:6b6224af8b5e09772c2ecb8dc9f3f344c1aa48201c7f07e7315367f6dd90ac29""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl"", hash = ""sha256:c50f95a82b94421c964fae4c27c0242890a20fe67d203d127e84fbb8013855f5""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl"", hash = ""sha256:7f3eff9961b5d2644bcf1616c606e93baa2d6b349e8aa8b035f654df252c8c67""},
+    {file = ""ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"", hash = ""sha256:b8963cab06d130c4df2fd52c84e9f10d297826d2e8169ae0c798b6221be1d1d2""},
+    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_aarch64.whl"", hash = ""sha256:61b46049d6edc0e4317fb14b33bd693245281a3007288b68a3f5b74a22a0746d""},
+    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_armv7l.whl"", hash = ""sha256:10ebce7696afe4644e8c1a23b3cf8c0f2193a310c18387c06e583ae9ef284de2""},
+    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_i686.whl"", hash = ""sha256:3f36d56326b3aef8eeee150b700e519880d1aab92f471eefdef656fd57492aa2""},
+    {file = ""ruff-0.7.3-py3-none-musllinux_1_2_x86_64.whl"", hash = ""sha256:5d024301109a0007b78d57ab0ba190087b43dce852e552734ebf0b0b85e4fb16""},
+    {file = ""ruff-0.7.3-py3-none-win32.whl"", hash = ""sha256:4ba81a5f0c5478aa61674c5a2194de8b02652f17addf8dfc40c8937e6e7d79fc""},
+    {file = ""ruff-0.7.3-py3-none-win_amd64.whl"", hash = ""sha256:588a9ff2fecf01025ed065fe28809cd5a53b43505f48b69a1ac7707b1b7e4088""},
+    {file = ""ruff-0.7.3-py3-none-win_arm64.whl"", hash = ""sha256:1713e2c5545863cdbfe2cbce21f69ffaf37b813bfd1fb3b90dc9a6f1963f5a8c""},
+    {file = ""ruff-0.7.3.tar.gz"", hash = ""sha256:e1d1ba2e40b6e71a61b063354d04be669ab0d39c352461f3d789cac68b54a313""},
 ]
 
 [[package]]
@@ -3676,4 +3676,4 @@ type = [""pytest-mypy""]
 [metadata]
 lock-version = ""2.0""
 python-versions = ""^3.10""
-content-hash = ""e0e67fde376688bee3ef5e31712eb42a8a3f9a361dd21d0890db61492df6f4c3""
+content-hash = ""03327de6fcc1d05795769eb3724f4815140e7ce984907190939f5f019e37f5fc""

--- autogpt_platform/backend/pyproject.toml ---
@@ -48,12 +48,12 @@ replicate = ""^1.0.3""
 pinecone = ""^5.3.1""
 cryptography = ""^43.0.3""
 [tool.poetry.group.dev.dependencies]
-poethepoet = ""^0.29.0""
+poethepoet = ""^0.30.0""
 httpx = ""^0.27.0""
 pytest-watcher = ""^0.4.2""
 requests = ""^2.32.3""
-ruff = ""^0.7.2""
-pyright = ""^1.1.387""
+ruff = ""^0.7.3""
+pyright = ""^1.1.388""
 isort = ""^5.13.2""
 black = ""^24.10.0""
 aiohappyeyeballs = ""^2.4.3""",build
"build(deps): bump google-github-actions/get-gke-credentials from 1 to 2 (#8437)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","--- .github/workflows/platform-autgpt-deploy-prod.yml ---
@@ -97,7 +97,7 @@ jobs:
         echo ""market_changed=$MARKET_CHANGED"" >> $GITHUB_OUTPUT
 
     - name: Get GKE credentials
-      uses: 'google-github-actions/get-gke-credentials@v1'
+      uses: 'google-github-actions/get-gke-credentials@v2'
       with:
         cluster_name: ${{ env.GKE_CLUSTER }}
         location: ${{ env.GKE_ZONE }}

--- .github/workflows/platform-autogpt-deploy.yaml ---
@@ -101,7 +101,7 @@ jobs:
         echo ""market_changed=$MARKET_CHANGED"" >> $GITHUB_OUTPUT
 
     - name: Get GKE credentials
-      uses: 'google-github-actions/get-gke-credentials@v1'
+      uses: 'google-github-actions/get-gke-credentials@v2'
       with:
         cluster_name: ${{ env.GKE_CLUSTER }}
         location: ${{ env.GKE_ZONE }}",build
"refactor(frontend): Remove unnecessary keywords in `BaseAutoGPTServerAPI` (#8242)

Co-authored-by: Reinier van der Leer <pwuts@agpt.co>
Co-authored-by: Toran Bruce Richards <toran.richards@gmail.com>
Co-authored-by: Zamil Majdy <zamil.majdy@agpt.co>","--- autogpt_platform/frontend/src/lib/autogpt-server-api/baseClient.ts ---
@@ -45,19 +45,19 @@ export default class BaseAutoGPTServerAPI {
     return session != null;
   }
 
-  async createUser(): Promise<User> {
+  createUser(): Promise<User> {
     return this._request(""POST"", ""/auth/user"", {});
   }
 
-  async getUserCredit(): Promise<{ credits: number }> {
+  getUserCredit(): Promise<{ credits: number }> {
     return this._get(`/credits`);
   }
 
-  async getBlocks(): Promise<Block[]> {
-    return await this._get(""/blocks"");
+  getBlocks(): Promise<Block[]> {
+    return this._get(""/blocks"");
   }
 
-  async listGraphs(): Promise<GraphMeta[]> {
+  listGraphs(): Promise<GraphMeta[]> {
     return this._get(`/graphs`);
   }
 
@@ -66,34 +66,31 @@ export default class BaseAutoGPTServerAPI {
     return graphs.map(parseGraphMetaWithRuns);
   }
 
-  async listTemplates(): Promise<GraphMeta[]> {
+  listTemplates(): Promise<GraphMeta[]> {
     return this._get(""/templates"");
   }
 
-  async getGraph(id: string, version?: number): Promise<Graph> {
+  getGraph(id: string, version?: number): Promise<Graph> {
     const query = version !== undefined ? `?version=${version}` : """";
     return this._get(`/graphs/${id}` + query);
   }
 
-  async getTemplate(id: string, version?: number): Promise<Graph> {
+  getTemplate(id: string, version?: number): Promise<Graph> {
     const query = version !== undefined ? `?version=${version}` : """";
     return this._get(`/templates/${id}` + query);
   }
 
-  async getGraphAllVersions(id: string): Promise<Graph[]> {
+  getGraphAllVersions(id: string): Promise<Graph[]> {
     return this._get(`/graphs/${id}/versions`);
   }
 
-  async getTemplateAllVersions(id: string): Promise<Graph[]> {
+  getTemplateAllVersions(id: string): Promise<Graph[]> {
     return this._get(`/templates/${id}/versions`);
   }
 
-  async createGraph(graphCreateBody: GraphCreatable): Promise<Graph>;
-  async createGraph(
-    fromTemplateID: string,
-    templateVersion: number,
-  ): Promise<Graph>;
-  async createGraph(
+  createGraph(graphCreateBody: GraphCreatable): Promise<Graph>;
+  createGraph(fromTemplateID: string, templateVersion: number): Promise<Graph>;
+  createGraph(
     graphOrTemplateID: GraphCreatable | string,
     templateVersion?: number,
   ): Promise<Graph> {
@@ -114,36 +111,33 @@ export default class BaseAutoGPTServerAPI {
     return this._request(""POST"", ""/graphs"", requestBody);
   }
 
-  async createTemplate(templateCreateBody: GraphCreatable): Promise<Graph> {
+  createTemplate(templateCreateBody: GraphCreatable): Promise<Graph> {
     const requestBody: GraphCreateRequestBody = { graph: templateCreateBody };
     return this._request(""POST"", ""/templates"", requestBody);
   }
 
-  async updateGraph(id: string, graph: GraphUpdateable): Promise<Graph> {
-    return await this._request(""PUT"", `/graphs/${id}`, graph);
+  updateGraph(id: string, graph: GraphUpdateable): Promise<Graph> {
+    return this._request(""PUT"", `/graphs/${id}`, graph);
   }
 
-  async updateTemplate(id: string, template: GraphUpdateable): Promise<Graph> {
-    return await this._request(""PUT"", `/templates/${id}`, template);
+  updateTemplate(id: string, template: GraphUpdateable): Promise<Graph> {
+    return this._request(""PUT"", `/templates/${id}`, template);
   }
 
-  async setGraphActiveVersion(id: string, version: number): Promise<Graph> {
+  setGraphActiveVersion(id: string, version: number): Promise<Graph> {
     return this._request(""PUT"", `/graphs/${id}/versions/active`, {
       active_graph_version: version,
     });
   }
 
-  async executeGraph(
+  executeGraph(
     id: string,
     inputData: { [key: string]: any } = {},
   ): Promise<GraphExecuteResponse> {
     return this._request(""POST"", `/graphs/${id}/execute`, inputData);
   }
 
-  async listGraphRunIDs(
-    graphID: string,
-    graphVersion?: number,
-  ): Promise<string[]> {
+  listGraphRunIDs(graphID: string, graphVersion?: number): Promise<string[]> {
     const query =
       graphVersion !== undefined ? `?graph_version=${graphVersion}` : """";
     return this._get(`/graphs/${graphID}/executions` + query);
@@ -167,15 +161,15 @@ export default class BaseAutoGPTServerAPI {
     ).map(parseNodeExecutionResultTimestamps);
   }
 
-  async oAuthLogin(
+  oAuthLogin(
     provider: string,
     scopes?: string[],
   ): Promise<{ login_url: string; state_token: string }> {
     const query = scopes ? { scopes: scopes.join("","") } : undefined;
-    return await this._get(`/integrations/${provider}/login`, query);
+    return this._get(`/integrations/${provider}/login`, query);
   }
 
-  async oAuthCallback(
+  oAuthCallback(
     provider: string,
     code: string,
     state_token: string,
@@ -186,7 +180,7 @@ export default class BaseAutoGPTServerAPI {
     });
   }
 
-  async createAPIKeyCredentials(
+  createAPIKeyCredentials(
     credentials: Omit<APIKeyCredentials, ""id"" | ""type"">,
   ): Promise<APIKeyCredentials> {
     return this._request(
@@ -196,29 +190,29 @@ export default class BaseAutoGPTServerAPI {
     );
   }
 
-  async listCredentials(provider: string): Promise<CredentialsMetaResponse[]> {
+  listCredentials(provider: string): Promise<CredentialsMetaResponse[]> {
     return this._get(`/integrations/${provider}/credentials`);
   }
 
-  async getCredentials(
+  getCredentials(
     provider: string,
     id: string,
   ): Promise<APIKeyCredentials | OAuth2Credentials> {
     return this._get(`/integrations/${provider}/credentials/${id}`);
   }
 
-  async deleteCredentials(provider: string, id: string): Promise<void> {
+  deleteCredentials(provider: string, id: string): Promise<void> {
     return this._request(
       ""DELETE"",
       `/integrations/${provider}/credentials/${id}`,
     );
   }
 
-  async logMetric(metric: AnalyticsMetrics) {
+  logMetric(metric: AnalyticsMetrics) {
     return this._request(""POST"", ""/analytics/log_raw_metric"", metric);
   }
 
-  async logAnalytic(analytic: AnalyticsDetails) {
+  logAnalytic(analytic: AnalyticsDetails) {
     return this._request(""POST"", ""/analytics/log_raw_analytics"", analytic);
   }",refactor
"docs(platform): Update frontend instructions (#8514)

update readme","--- autogpt_platform/README.md ---
@@ -28,9 +28,9 @@ To run the AutoGPT Platform, follow these steps:
 
 3. Run the following command:
    ```
-   cp supabase/docker/.env.example .env
+   cp supabase/docker/.env.example .env.local
    ```
-   This command will copy the `.env.example` file to `.env` in the `supabase/docker` directory. You can modify the `.env` file to add your own environment variables.
+   This command will copy the `.env.example` file to `.env.local` in the `supabase/docker` directory. You can modify the `.env.local` file to add your own environment variables.
 
 4. Run the following command:
    ```",docs
"fix(frontend/login): Hide sign in with Google/GitHub/Discord for now (#8318)

hide sign in with Google/GitHub/Discord for now","--- autogpt_platform/frontend/src/app/login/page.tsx ---
@@ -114,7 +114,7 @@ export default function LoginPage() {
   return (
     <div className=""flex h-[80vh] items-center justify-center"">
       <div className=""w-full max-w-md space-y-6 rounded-lg p-8 shadow-md"">
-        <div className=""mb-6 space-y-2"">
+        {/* <div className=""mb-6 space-y-2"">
           <Button
             className=""w-full""
             onClick={() => handleSignInWithProvider(""google"")}
@@ -145,7 +145,7 @@ export default function LoginPage() {
             <FaDiscord className=""mr-2 h-4 w-4"" />
             Sign in with Discord
           </Button>
-        </div>
+        </div> */}
         <Form {...form}>
           <form onSubmit={form.handleSubmit(onLogin)}>
             <FormField",fix
"fix(backend): Add migrations to fix credentials inputs with invalid provider ""llm"" (vol. 4)

Another attempt at unbreaking this raw Prisma query","--- autogpt_platform/backend/backend/data/graph.py ---
@@ -550,10 +550,10 @@ async def fix_llm_provider_credentials():
         SELECT    ""User"".id            user_id,
                   node.id              node_id,
                   node.""constantInput"" node_preset_input
-        FROM      platform.""AgentGraph"" graph
-        LEFT JOIN platform.""AgentNode""  node
+        FROM      ""AgentNode""  node
+        LEFT JOIN ""AgentGraph"" graph
         ON        node.""agentGraphId"" = graph.id
-        LEFT JOIN platform.""User""
+        LEFT JOIN ""User""
         ON        graph.""userId"" = ""User"".id
         WHERE     node.""constantInput""::jsonb->'credentials'->>'provider' = 'llm'
         ORDER BY  user_id;",fix
"chore(infra): Add websockets IP (#7905)

tf changes from original branch to unblock other work","--- rnd/infra/terraform/environments/dev.tfvars ---
@@ -9,7 +9,7 @@ node_count      = 3
 node_pool_name  = ""dev-main-pool""
 machine_type    = ""e2-medium""
 disk_size_gb    = 100
-static_ip_names = [""agpt-server-ip"", ""agpt-builder-ip"", ""auth-ip""]
+static_ip_names = [""agpt-server-ip"", ""agpt-builder-ip"", ""agpt-ws-server-ip""]
 
 
 service_accounts = {",chore
"build(.dockerignore) Put dockerignore back (#8136)

* put dockerignore back

* add classic prefix","--- .dockerignore ---
@@ -0,0 +1,40 @@
+# Ignore everything by default, selectively add things to context
+classic/run
+
+# AutoGPT
+!classic/original_autogpt/autogpt/
+!classic/original_autogpt/pyproject.toml
+!classic/original_autogpt/poetry.lock
+!classic/original_autogpt/README.md
+!classic/original_autogpt/tests/
+
+# Benchmark
+!classic/benchmark/agbenchmark/
+!classic/benchmark/pyproject.toml
+!classic/benchmark/poetry.lock
+!classic/benchmark/README.md
+
+# Forge
+!classic/forge/
+!classic/forge/pyproject.toml
+!classic/forge/poetry.lock
+!classic/forge/README.md
+
+# Frontend
+!classic/frontend/build/web/
+
+# Platform
+!autogpt_platform/
+
+# Explicitly re-ignore some folders
+.*
+**/__pycache__
+
+autogpt_platform/frontend/.next/
+autogpt_platform/frontend/node_modules
+autogpt_platform/frontend/.env.example
+autogpt_platform/frontend/.env.local
+autogpt_platform/backend/.env
+autogpt_platform/backend/.venv/
+
+autogpt_platform/market/.env

--- classic/.dockerignore ---
@@ -1,28 +0,0 @@
-# Ignore everything by default, selectively add things to context
-*
-
-# AutoGPT
-!original_autogpt/autogpt/
-!original_autogpt/pyproject.toml
-!original_autogpt/poetry.lock
-!original_autogpt/README.md
-!original_autogpt/tests/
-
-# Benchmark
-!benchmark/agbenchmark/
-!benchmark/pyproject.toml
-!benchmark/poetry.lock
-!benchmark/README.md
-
-# Forge
-!forge/
-!forge/pyproject.toml
-!forge/poetry.lock
-!forge/README.md
-
-# Frontend
-!frontend/build/web/
-
-# Explicitly re-ignore some folders
-.*
-**/__pycache__",build
"fix(platform): UI fixes; Fix disabled Run/Stop button (#8171)

* fix(platform): UI fixes; Fix disabled Run/Stop button

* fix(platform): UI fixes; Fix disabled Run/Stop button

---------

Co-authored-by: Swifty <craigswift13@gmail.com>","--- autogpt_platform/frontend/src/components/Flow.tsx ---
@@ -34,21 +34,16 @@ import ConnectionLine from ""./ConnectionLine"";
 import { Control, ControlPanel } from ""@/components/edit/control/ControlPanel"";
 import { SaveControl } from ""@/components/edit/control/SaveControl"";
 import { BlocksControl } from ""@/components/edit/control/BlocksControl"";
-import {
-  IconPlay,
-  IconUndo2,
-  IconRedo2,
-  IconSquare,
-} from ""@/components/ui/icons"";
+import { IconUndo2, IconRedo2 } from ""@/components/ui/icons"";
 import { startTutorial } from ""./tutorial"";
 import useAgentGraph from ""@/hooks/useAgentGraph"";
 import { v4 as uuidv4 } from ""uuid"";
-import { useRouter, usePathname, useSearchParams } from ""next/navigation"";
-import { LogOut } from ""lucide-react"";
+import { useRouter, usePathname } from ""next/navigation"";
 import RunnerUIWrapper, {
   RunnerUIWrapperRef,
 } from ""@/components/RunnerUIWrapper"";
 import PrimaryActionBar from ""@/components/PrimaryActionButton"";
+import { useToast } from ""@/components/ui/use-toast"";
 
 // This is for the history, this is the minimum distance a block must move before it is logged
 // It helps to prevent spamming the history with small movements especially when pressing on a input in a block
@@ -108,6 +103,8 @@ const FlowEditor: React.FC<{
 
   const runnerUIRef = useRef<RunnerUIWrapperRef>(null);
 
+  const { toast } = useToast();
+
   useEffect(() => {
     const params = new URLSearchParams(window.location.search);
 
@@ -601,9 +598,10 @@ const FlowEditor: React.FC<{
             onClickAgentOutputs={() => runnerUIRef.current?.openRunnerOutput()}
             onClickRunAgent={() => {
               if (!savedAgent) {
-                alert(
-                  ""Please save the agent to run, by clicking the save button in the left sidebar."",
-                );
+                toast({
+                  title: `Please save the agent using the button in the left sidebar before running it.`,
+                  duration: 2000,
+                });
                 return;
               }
               if (!isRunning) {
@@ -612,15 +610,10 @@ const FlowEditor: React.FC<{
                 requestStopRun();
               }
             }}
+            isDisabled={!savedAgent}
             isRunning={isRunning}
             requestStopRun={requestStopRun}
-            runAgentTooltip={
-              !savedAgent
-                ? ""Please save the agent to run""
-                : !isRunning
-                  ? ""Run Agent""
-                  : ""Stop Agent""
-            }
+            runAgentTooltip={!isRunning ? ""Run Agent"" : ""Stop Agent""}
           />
         </ReactFlow>
       </div>

--- autogpt_platform/frontend/src/components/PrimaryActionButton.tsx ---
@@ -12,6 +12,7 @@ interface PrimaryActionBarProps {
   onClickAgentOutputs: () => void;
   onClickRunAgent: () => void;
   isRunning: boolean;
+  isDisabled: boolean;
   requestStopRun: () => void;
   runAgentTooltip: string;
 }
@@ -20,6 +21,7 @@ const PrimaryActionBar: React.FC<PrimaryActionBarProps> = ({
   onClickAgentOutputs,
   onClickRunAgent,
   isRunning,
+  isDisabled,
   requestStopRun,
   runAgentTooltip,
 }) => {
@@ -56,7 +58,7 @@ const PrimaryActionBar: React.FC<PrimaryActionBarProps> = ({
               size=""primary""
               style={{
                 background: isRunning ? ""#FFB3BA"" : ""#7544DF"",
-                opacity: 1,
+                opacity: isDisabled ? 0.5 : 1,
               }}
             >
               {runButtonIcon}",fix
docs(backend): Add `--build` to docker command in Getting Started guide (#8762),"--- docs/content/platform/advanced_setup.md ---
@@ -55,7 +55,7 @@ This will generate the Prisma client for PostgreSQL. You will also need to run t
 
 ```bash
 cd autogpt_platform/
-docker compose up -d
+docker compose up -d --build
 ```
 
 You can then run the migrations from the `backend` directory.

--- docs/content/platform/getting-started.md ---
@@ -90,7 +90,7 @@ To run the backend services, follow these steps:
 
 * Run the backend services:
   ```
-   docker compose up -d
+   docker compose up -d --build
   ```
   This command will start all the necessary backend services defined in the `docker-compose.combined.yml` file in detached mode.",docs
